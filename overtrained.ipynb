{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2860) tensor(0.3530)\n",
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "mean_std_data = datasets.FashionMNIST('./FashionMNIST_data', train=True, download=True, transform=transforms.ToTensor()).train_data.float() / 255\n",
    "mean = torch.mean(mean_std_data)\n",
    "std = torch.std(mean_std_data)\n",
    "print(mean, std)\n",
    "print(mean_std_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean,), (std,)),\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fashion_mnist(batch_size=50, valid=0, shuffle=True, transform=fashion_transform, path='./FashionMNIST_data'):\n",
    "    test_data = datasets.FashionMNIST(path, train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    train_data = datasets.FashionMNIST(path, train=True, download=True, transform=transform)\n",
    "    train_data.train_data = train_data.train_data[:30000, :, :]\n",
    "    if valid > 0:\n",
    "        num_train = len(train_data)\n",
    "        indices = list(range(num_train))\n",
    "        split = num_train-valid\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        train_idx, valid_idx = indices[:split], indices[split:]\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "        valid_loader = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
    "    \n",
    "        return train_loader, valid_loader, test_loader\n",
    "    else:\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 100\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = fashion_mnist(valid=5000)\n",
    "print(len(train_loader), len(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, batchnorm=False, dropout=False, lr=1e-4, l2=0.):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 10)\n",
    "        if batchnorm:\n",
    "            self.bn = nn.BatchNorm1d(256)\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.optim = optim.Adam(self.parameters(), lr=lr, weight_decay=l2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        if self.batchnorm:\n",
    "            x = self.bn(x)\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, 0.5)\n",
    "        x = self.fc4(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, output, target, **kwargs):\n",
    "        self._loss = F.nll_loss(output, target, **kwargs)\n",
    "        return self._loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'default': Net(False, False), 'bn': Net(True, False), 'drop': Net(False, True), 'both': Net(True, True)}\n",
    "train_log = {k: [] for k in models}\n",
    "test_log = {k: [] for k in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, models, log=None):\n",
    "    train_size = len(train_loader.sampler)\n",
    "    \n",
    "    train_loss = {k: 0. for k in models}\n",
    "    correct_train = {k: 0. for k in models}\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        for k, model in models.items():\n",
    "            model.optim.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = model.loss(output, target)\n",
    "            loss.backward()\n",
    "            model.optim.step()\n",
    "            \n",
    "            train_loss[k] += loss.item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct_train[k] += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "            \n",
    "        if batch_idx % 200 == 0:\n",
    "            line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "                epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "            losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "            print(line + losses)\n",
    "            \n",
    "    else:\n",
    "        batch_idx += 1\n",
    "        line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "            epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "        losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "        print(line + losses)\n",
    "        \n",
    "    if log is not None:\n",
    "        for k in models:\n",
    "            train_loss[k] /= train_size\n",
    "        correct_pct = {k: 100. * correct_train[k] / train_size for k in correct_train}\n",
    "        for k in models:\n",
    "            log[k].append((train_loss[k], correct_pct[k])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, loader, log=None):\n",
    "    test_size = len(loader.sampler)\n",
    "    avg_lambda = lambda l: 'Loss: {:.4f}'.format(l)\n",
    "    acc_lambda = lambda c, p: 'Accuracy: {}/{} ({:.0f}%)'.format(c, test_size, p)\n",
    "    line = lambda i, l, c, p: '{}: '.format(i) + avg_lambda(l) + '\\t' + acc_lambda(c, p)\n",
    "\n",
    "    test_loss = {k: 0. for k in models}\n",
    "    correct = {k: 0. for k in models}\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            # output = {k: m(data) for m in models}\n",
    "            for k, m in models.items():\n",
    "                output = m(data)\n",
    "                test_loss[k] += m.loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "                pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                correct[k] += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "    \n",
    "    for k in models:\n",
    "        test_loss[k] /= test_size\n",
    "    correct_pct = {k: 100. * correct[k] / test_size for k in correct}\n",
    "    lines = '\\n'.join([line(k, test_loss[k], correct[k], correct_pct[k]) for k in models]) + '\\n'\n",
    "    report = 'Test set:\\n' + lines\n",
    "    \n",
    "    if log is not None:\n",
    "        for k in models:\n",
    "            log[k].append((test_loss[k], correct_pct[k]))\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/25000 (0%)]\tLosses default: 0.000015 bn: 0.000029 drop: 0.000022 both: 0.000129\n",
      "Train Epoch: 1 [10000/25000 (40%)]\tLosses default: 0.000019 bn: 0.005871 drop: 0.000009 both: 0.000553\n",
      "Train Epoch: 1 [20000/25000 (80%)]\tLosses default: 0.000037 bn: 0.000021 drop: 0.000922 both: 0.000165\n",
      "Train Epoch: 1 [25000/25000 (100%)]\tLosses default: 0.000015 bn: 0.001342 drop: 0.146922 both: 0.001089\n",
      "Test set:\n",
      "default: Loss: 1.1583\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0117\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0112\tAccuracy: 4341.0/5000 (87%)\n",
      "both: Loss: 0.9572\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 2 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.001297 drop: 0.057938 both: 0.000909\n",
      "Train Epoch: 2 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.036394 both: 0.000036\n",
      "Train Epoch: 2 [20000/25000 (80%)]\tLosses default: 0.000019 bn: 0.000026 drop: 0.003478 both: 0.000055\n",
      "Train Epoch: 2 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.005183 drop: 0.000865 both: 0.005515\n",
      "Test set:\n",
      "default: Loss: 1.1659\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0199\tAccuracy: 4401.0/5000 (88%)\n",
      "drop: Loss: 0.9655\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 0.9715\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 3 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.001734 drop: 0.000439 both: 0.003147\n",
      "Train Epoch: 3 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000003 drop: 0.005477 both: 0.000018\n",
      "Train Epoch: 3 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000158 drop: 0.000010 both: 0.000016\n",
      "Train Epoch: 3 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000159 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.1740\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 0.9933\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 0.9586\tAccuracy: 4360.0/5000 (87%)\n",
      "both: Loss: 0.9772\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 4 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.000019 drop: 0.000579 both: 0.000128\n",
      "Train Epoch: 4 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000044 drop: 0.000567 both: 0.000354\n",
      "Train Epoch: 4 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000941 drop: 0.000282 both: 0.010399\n",
      "Train Epoch: 4 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000039 drop: 0.000184 both: 0.005513\n",
      "Test set:\n",
      "default: Loss: 1.1817\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 0.9774\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 0.9580\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 0.9795\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 5 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.000102 drop: 0.000286 both: 0.000301\n",
      "Train Epoch: 5 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000041 drop: 0.000070 both: 0.002151\n",
      "Train Epoch: 5 [20000/25000 (80%)]\tLosses default: 0.000013 bn: 0.000928 drop: 0.000128 both: 0.007753\n",
      "Train Epoch: 5 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000050 drop: 0.000452 both: 0.001218\n",
      "Test set:\n",
      "default: Loss: 1.1886\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0068\tAccuracy: 4400.0/5000 (88%)\n",
      "drop: Loss: 0.9568\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 0.9812\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 6 [0/25000 (0%)]\tLosses default: 0.000018 bn: 0.000944 drop: 0.001152 both: 0.000176\n",
      "Train Epoch: 6 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000069 drop: 0.000168 both: 0.006584\n",
      "Train Epoch: 6 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.080169 drop: 0.000213 both: 0.039290\n",
      "Train Epoch: 6 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000085 drop: 0.003175 both: 0.000477\n",
      "Test set:\n",
      "default: Loss: 1.1961\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 0.9794\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 0.9696\tAccuracy: 4372.0/5000 (87%)\n",
      "both: Loss: 0.9828\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 7 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000100 drop: 0.000037 both: 0.000004\n",
      "Train Epoch: 7 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000073 drop: 0.000989 both: 0.004098\n",
      "Train Epoch: 7 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.001754 drop: 0.000055 both: 0.000024\n",
      "Train Epoch: 7 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000947 both: 0.014246\n",
      "Test set:\n",
      "default: Loss: 1.2057\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 0.9609\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 0.9817\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 0.9941\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 8 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000334 drop: 0.000242 both: 0.000094\n",
      "Train Epoch: 8 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000891 drop: 0.000022 both: 0.000337\n",
      "Train Epoch: 8 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000141 both: 0.001924\n",
      "Train Epoch: 8 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.005746 drop: 0.000041 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.2112\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9782\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 0.9789\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 0.9889\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 9 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.007367 drop: 0.000006 both: 0.000101\n",
      "Train Epoch: 9 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000402 drop: 0.000006 both: 0.000051\n",
      "Train Epoch: 9 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000028 drop: 0.000107 both: 0.002828\n",
      "Train Epoch: 9 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000481 drop: 0.000031 both: 0.005722\n",
      "Test set:\n",
      "default: Loss: 1.2177\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 0.9971\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 0.9808\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 0.9998\tAccuracy: 4366.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 10 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.004183 drop: 0.000051 both: 0.000366\n",
      "Train Epoch: 10 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000016 drop: 0.000083 both: 0.000446\n",
      "Train Epoch: 10 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000035 drop: 0.000060 both: 0.000318\n",
      "Train Epoch: 10 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000105 drop: 0.000253 both: 0.021395\n",
      "Test set:\n",
      "default: Loss: 1.2226\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 0.9729\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 0.9858\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 0.9806\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 11 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000021 drop: 0.000020 both: 0.000871\n",
      "Train Epoch: 11 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000157 drop: 0.155747 both: 0.000469\n",
      "Train Epoch: 11 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.005631 drop: 0.005194 both: 0.010142\n",
      "Train Epoch: 11 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000052 drop: 0.001742 both: 0.005391\n",
      "Test set:\n",
      "default: Loss: 1.2294\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 0.9958\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 0.8912\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0206\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 12 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000032 drop: 0.000211 both: 0.000179\n",
      "Train Epoch: 12 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.002416 drop: 0.000753 both: 0.000038\n",
      "Train Epoch: 12 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000027 both: 0.001301\n",
      "Train Epoch: 12 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.006218 drop: 0.000315 both: 0.010910\n",
      "Test set:\n",
      "default: Loss: 1.2334\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0460\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 0.9002\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 0.9845\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 13 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.005098 drop: 0.000354 both: 0.005886\n",
      "Train Epoch: 13 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000109 drop: 0.000083 both: 0.000215\n",
      "Train Epoch: 13 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000244 drop: 0.000061 both: 0.001617\n",
      "Train Epoch: 13 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.007184 drop: 0.000855 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.2408\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0492\tAccuracy: 4393.0/5000 (88%)\n",
      "drop: Loss: 0.9209\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 0.9632\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 14 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000095 drop: 0.000040 both: 0.002235\n",
      "Train Epoch: 14 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000020 drop: 0.000468 both: 0.000304\n",
      "Train Epoch: 14 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000089 drop: 0.000079 both: 0.000746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000035 both: 0.000113\n",
      "Test set:\n",
      "default: Loss: 1.2472\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0057\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 0.9320\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 0.9843\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 15 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000096 drop: 0.000091 both: 0.000503\n",
      "Train Epoch: 15 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000029 drop: 0.000037 both: 0.000069\n",
      "Train Epoch: 15 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000172 drop: 0.000050 both: 0.000050\n",
      "Train Epoch: 15 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000036 drop: 0.000082 both: 0.000300\n",
      "Test set:\n",
      "default: Loss: 1.2508\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0237\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 0.9310\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 0.9718\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 16 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000575 drop: 0.000026 both: 0.001172\n",
      "Train Epoch: 16 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000722 drop: 0.000124 both: 0.111224\n",
      "Train Epoch: 16 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000134 drop: 0.000053 both: 0.000168\n",
      "Train Epoch: 16 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.029662 drop: 0.000020 both: 0.010496\n",
      "Test set:\n",
      "default: Loss: 1.2577\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0190\tAccuracy: 4394.0/5000 (88%)\n",
      "drop: Loss: 0.9396\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0326\tAccuracy: 4343.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 17 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.020324 drop: 0.000004 both: 0.001371\n",
      "Train Epoch: 17 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000045 both: 0.027263\n",
      "Train Epoch: 17 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000062 both: 0.030935\n",
      "Train Epoch: 17 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.074946 drop: 0.000086 both: 0.002673\n",
      "Test set:\n",
      "default: Loss: 1.2611\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0684\tAccuracy: 4380.0/5000 (88%)\n",
      "drop: Loss: 0.9505\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 0.9942\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 18 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000197 drop: 0.000029 both: 0.000746\n",
      "Train Epoch: 18 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000011 both: 0.000341\n",
      "Train Epoch: 18 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000182 drop: 0.000162 both: 0.006992\n",
      "Train Epoch: 18 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000372 drop: 0.000044 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2675\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0295\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 0.9636\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 0.9739\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 19 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000010 both: 0.000310\n",
      "Train Epoch: 19 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000278 both: 0.000769\n",
      "Train Epoch: 19 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000013 both: 0.000423\n",
      "Train Epoch: 19 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000976 drop: 0.000145 both: 0.000228\n",
      "Test set:\n",
      "default: Loss: 1.2746\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0133\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 0.9610\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 0.9686\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 20 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000109 drop: 0.000076 both: 0.000301\n",
      "Train Epoch: 20 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000074 drop: 0.000040 both: 0.000507\n",
      "Train Epoch: 20 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000075 drop: 0.000007 both: 0.000972\n",
      "Train Epoch: 20 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000067 drop: 0.000003 both: 0.000502\n",
      "Test set:\n",
      "default: Loss: 1.2776\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0422\tAccuracy: 4404.0/5000 (88%)\n",
      "drop: Loss: 0.9700\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 0.9320\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 21 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.011364 drop: 0.000015 both: 0.001874\n",
      "Train Epoch: 21 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000474 drop: 0.000076 both: 0.002164\n",
      "Train Epoch: 21 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.019037 drop: 0.000054 both: 0.000071\n",
      "Train Epoch: 21 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000186 drop: 0.000029 both: 0.000042\n",
      "Test set:\n",
      "default: Loss: 1.2839\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0205\tAccuracy: 4379.0/5000 (88%)\n",
      "drop: Loss: 0.9666\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 0.9738\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 22 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000111 drop: 0.000097 both: 0.000036\n",
      "Train Epoch: 22 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000141 drop: 0.000030 both: 0.000053\n",
      "Train Epoch: 22 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000035 drop: 0.000003 both: 0.004398\n",
      "Train Epoch: 22 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000099 drop: 0.000085 both: 0.000052\n",
      "Test set:\n",
      "default: Loss: 1.2912\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 0.9729\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 0.9988\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 0.9610\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 23 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000042 both: 0.008224\n",
      "Train Epoch: 23 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000018 both: 0.000132\n",
      "Train Epoch: 23 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000398 drop: 0.000012 both: 0.000366\n",
      "Train Epoch: 23 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000054 drop: 0.000021 both: 0.000205\n",
      "Test set:\n",
      "default: Loss: 1.2959\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 0.9841\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.0010\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 0.9472\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 24 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000006 both: 0.000078\n",
      "Train Epoch: 24 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000012 both: 0.000084\n",
      "Train Epoch: 24 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000122 drop: 0.000121 both: 0.000740\n",
      "Train Epoch: 24 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000263 drop: 0.000040 both: 0.001546\n",
      "Test set:\n",
      "default: Loss: 1.3035\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 0.9945\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.0025\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 0.9673\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 25 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000154 drop: 0.000009 both: 0.000238\n",
      "Train Epoch: 25 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000013 both: 0.000012\n",
      "Train Epoch: 25 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000269 drop: 0.044532 both: 0.000614\n",
      "Train Epoch: 25 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.030539 both: 0.000060\n",
      "Test set:\n",
      "default: Loss: 1.3101\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 0.9800\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 0.9614\tAccuracy: 4350.0/5000 (87%)\n",
      "both: Loss: 0.9872\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 26 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.006241 both: 0.002825\n",
      "Train Epoch: 26 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000310 both: 0.000028\n",
      "Train Epoch: 26 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000070 drop: 0.000910 both: 0.000053\n",
      "Train Epoch: 26 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000269 drop: 0.119663 both: 0.000218\n",
      "Test set:\n",
      "default: Loss: 1.3179\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0133\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.0739\tAccuracy: 4337.0/5000 (87%)\n",
      "both: Loss: 0.9862\tAccuracy: 4367.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 27 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.170310 both: 0.001905\n",
      "Train Epoch: 27 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.002339 drop: 0.001008 both: 0.000116\n",
      "Train Epoch: 27 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.197488 drop: 0.000066 both: 0.000026\n",
      "Train Epoch: 27 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000843 drop: 0.000109 both: 0.000045\n",
      "Test set:\n",
      "default: Loss: 1.3243\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0613\tAccuracy: 4389.0/5000 (88%)\n",
      "drop: Loss: 0.9701\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 0.9768\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 28 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001567 drop: 0.000022 both: 0.000055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [10000/25000 (40%)]\tLosses default: 0.128984 bn: 0.004832 drop: 0.000103 both: 0.000131\n",
      "Train Epoch: 28 [20000/25000 (80%)]\tLosses default: 0.003190 bn: 0.000165 drop: 0.000052 both: 0.001576\n",
      "Train Epoch: 28 [25000/25000 (100%)]\tLosses default: 0.000951 bn: 0.000554 drop: 0.000054 both: 0.000183\n",
      "Test set:\n",
      "default: Loss: 1.0491\tAccuracy: 4411.0/5000 (88%)\n",
      "bn: Loss: 1.0081\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 0.9790\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 0.9491\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 29 [0/25000 (0%)]\tLosses default: 0.000217 bn: 0.000065 drop: 0.000011 both: 0.000017\n",
      "Train Epoch: 29 [10000/25000 (40%)]\tLosses default: 0.000016 bn: 0.000200 drop: 0.000170 both: 0.000352\n",
      "Train Epoch: 29 [20000/25000 (80%)]\tLosses default: 0.000171 bn: 0.000023 drop: 0.000006 both: 0.000034\n",
      "Train Epoch: 29 [25000/25000 (100%)]\tLosses default: 0.010617 bn: 0.000010 drop: 0.000018 both: 0.000028\n",
      "Test set:\n",
      "default: Loss: 1.0859\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 0.9802\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 0.9846\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 0.9764\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 30 [0/25000 (0%)]\tLosses default: 0.000186 bn: 0.000005 drop: 0.000129 both: 0.000008\n",
      "Train Epoch: 30 [10000/25000 (40%)]\tLosses default: 0.000094 bn: 0.000054 drop: 0.000044 both: 0.020045\n",
      "Train Epoch: 30 [20000/25000 (80%)]\tLosses default: 0.000096 bn: 0.000020 drop: 0.000108 both: 0.000218\n",
      "Train Epoch: 30 [25000/25000 (100%)]\tLosses default: 0.000411 bn: 0.000030 drop: 0.000048 both: 0.001199\n",
      "Test set:\n",
      "default: Loss: 1.0947\tAccuracy: 4400.0/5000 (88%)\n",
      "bn: Loss: 0.9980\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 0.9779\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 0.9799\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 31 [0/25000 (0%)]\tLosses default: 0.000137 bn: 0.013937 drop: 0.000110 both: 0.000188\n",
      "Train Epoch: 31 [10000/25000 (40%)]\tLosses default: 0.031976 bn: 0.000052 drop: 0.000221 both: 0.000510\n",
      "Train Epoch: 31 [20000/25000 (80%)]\tLosses default: 0.004974 bn: 0.000162 drop: 0.000153 both: 0.001223\n",
      "Train Epoch: 31 [25000/25000 (100%)]\tLosses default: 0.002116 bn: 0.000010 drop: 0.000010 both: 0.000104\n",
      "Test set:\n",
      "default: Loss: 1.1042\tAccuracy: 4387.0/5000 (88%)\n",
      "bn: Loss: 0.9888\tAccuracy: 4404.0/5000 (88%)\n",
      "drop: Loss: 0.9765\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 0.9511\tAccuracy: 4416.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 32 [0/25000 (0%)]\tLosses default: 0.000269 bn: 0.000008 drop: 0.000229 both: 0.000232\n",
      "Train Epoch: 32 [10000/25000 (40%)]\tLosses default: 0.000015 bn: 0.000133 drop: 0.000007 both: 0.001188\n",
      "Train Epoch: 32 [20000/25000 (80%)]\tLosses default: 0.000766 bn: 0.000084 drop: 0.000054 both: 0.000016\n",
      "Train Epoch: 32 [25000/25000 (100%)]\tLosses default: 0.000023 bn: 0.000755 drop: 0.000026 both: 0.005658\n",
      "Test set:\n",
      "default: Loss: 1.0645\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 0.9986\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 0.9902\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 0.9796\tAccuracy: 4368.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 33 [0/25000 (0%)]\tLosses default: 0.000090 bn: 0.096710 drop: 0.000039 both: 0.000094\n",
      "Train Epoch: 33 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.003585 drop: 0.000025 both: 0.000019\n",
      "Train Epoch: 33 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000058 drop: 0.000007 both: 0.000025\n",
      "Train Epoch: 33 [25000/25000 (100%)]\tLosses default: 0.000172 bn: 0.000058 drop: 0.000037 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.0765\tAccuracy: 4409.0/5000 (88%)\n",
      "bn: Loss: 0.9928\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 0.9911\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 0.9672\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 34 [0/25000 (0%)]\tLosses default: 0.000097 bn: 0.000014 drop: 0.000294 both: 0.000018\n",
      "Train Epoch: 34 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000071 drop: 0.000012 both: 0.000206\n",
      "Train Epoch: 34 [20000/25000 (80%)]\tLosses default: 0.000082 bn: 0.000150 drop: 0.000035 both: 0.000209\n",
      "Train Epoch: 34 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000004 drop: 0.000008 both: 0.071767\n",
      "Test set:\n",
      "default: Loss: 1.0912\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0043\tAccuracy: 4396.0/5000 (88%)\n",
      "drop: Loss: 1.0025\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 0.9739\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 35 [0/25000 (0%)]\tLosses default: 0.000085 bn: 0.000717 drop: 0.000029 both: 0.000295\n",
      "Train Epoch: 35 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000024 drop: 0.000016 both: 0.001793\n",
      "Train Epoch: 35 [20000/25000 (80%)]\tLosses default: 0.000021 bn: 0.000027 drop: 0.000041 both: 0.000245\n",
      "Train Epoch: 35 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000270 drop: 0.000010 both: 0.000506\n",
      "Test set:\n",
      "default: Loss: 1.0948\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9714\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 0.9905\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 0.9791\tAccuracy: 4370.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 36 [0/25000 (0%)]\tLosses default: 0.000042 bn: 0.000024 drop: 0.000036 both: 0.000731\n",
      "Train Epoch: 36 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000011 drop: 0.000038 both: 0.000019\n",
      "Train Epoch: 36 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000140 drop: 0.000008 both: 0.001904\n",
      "Train Epoch: 36 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.021767 drop: 0.000071 both: 0.000236\n",
      "Test set:\n",
      "default: Loss: 1.1009\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0091\tAccuracy: 4393.0/5000 (88%)\n",
      "drop: Loss: 1.0097\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 0.9609\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 37 [0/25000 (0%)]\tLosses default: 0.000011 bn: 0.000022 drop: 0.000046 both: 0.000328\n",
      "Train Epoch: 37 [10000/25000 (40%)]\tLosses default: 0.000077 bn: 0.001182 drop: 0.000014 both: 0.000038\n",
      "Train Epoch: 37 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000006 both: 0.000015\n",
      "Train Epoch: 37 [25000/25000 (100%)]\tLosses default: 0.000017 bn: 0.002324 drop: 0.000009 both: 0.000272\n",
      "Test set:\n",
      "default: Loss: 1.1078\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9871\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.0200\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 0.9789\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 38 [0/25000 (0%)]\tLosses default: 0.000046 bn: 0.012022 drop: 0.000026 both: 0.003499\n",
      "Train Epoch: 38 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000012 both: 0.000021\n",
      "Train Epoch: 38 [20000/25000 (80%)]\tLosses default: 0.000011 bn: 0.000095 drop: 0.000007 both: 0.000023\n",
      "Train Epoch: 38 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000099 drop: 0.000003 both: 0.000035\n",
      "Test set:\n",
      "default: Loss: 1.1158\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0001\tAccuracy: 4395.0/5000 (88%)\n",
      "drop: Loss: 1.0164\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 0.9963\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 39 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.262817 drop: 0.000011 both: 0.000206\n",
      "Train Epoch: 39 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000183 drop: 0.000029 both: 0.000016\n",
      "Train Epoch: 39 [20000/25000 (80%)]\tLosses default: 0.000027 bn: 0.000002 drop: 0.000007 both: 0.000006\n",
      "Train Epoch: 39 [25000/25000 (100%)]\tLosses default: 0.000016 bn: 0.000037 drop: 0.000072 both: 0.000117\n",
      "Test set:\n",
      "default: Loss: 1.1226\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 0.9562\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0399\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 0.9759\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 40 [0/25000 (0%)]\tLosses default: 0.000028 bn: 0.000047 drop: 0.000008 both: 0.000050\n",
      "Train Epoch: 40 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000033 drop: 0.039391 both: 0.000673\n",
      "Train Epoch: 40 [20000/25000 (80%)]\tLosses default: 0.000014 bn: 0.000213 drop: 0.033554 both: 0.000007\n",
      "Train Epoch: 40 [25000/25000 (100%)]\tLosses default: 0.000012 bn: 0.111166 drop: 0.018166 both: 0.000906\n",
      "Test set:\n",
      "default: Loss: 1.1291\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9722\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 0.9310\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 0.9891\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 41 [0/25000 (0%)]\tLosses default: 0.000017 bn: 0.022377 drop: 0.000344 both: 0.004996\n",
      "Train Epoch: 41 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000018 drop: 0.000375 both: 0.000029\n",
      "Train Epoch: 41 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000194 drop: 0.000044 both: 0.000011\n",
      "Train Epoch: 41 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.095699 drop: 0.000135 both: 0.000116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "default: Loss: 1.1382\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0162\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 0.9300\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 0.9672\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 42 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000804 drop: 0.000015 both: 0.000047\n",
      "Train Epoch: 42 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000122 drop: 0.000060 both: 0.014735\n",
      "Train Epoch: 42 [20000/25000 (80%)]\tLosses default: 0.000010 bn: 0.000026 drop: 0.000166 both: 0.000356\n",
      "Train Epoch: 42 [25000/25000 (100%)]\tLosses default: 0.000034 bn: 0.000016 drop: 0.000259 both: 0.000065\n",
      "Test set:\n",
      "default: Loss: 1.1443\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 0.9596\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 0.9226\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 0.9803\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 43 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000044 drop: 0.000007 both: 0.000041\n",
      "Train Epoch: 43 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.002681 drop: 0.000220 both: 0.000010\n",
      "Train Epoch: 43 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000051 both: 0.000035\n",
      "Train Epoch: 43 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000364 drop: 0.000020 both: 0.000142\n",
      "Test set:\n",
      "default: Loss: 1.1529\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 0.9776\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 0.9299\tAccuracy: 4415.0/5000 (88%)\n",
      "both: Loss: 0.9780\tAccuracy: 4361.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 44 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000198 drop: 0.000060 both: 0.000372\n",
      "Train Epoch: 44 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.002370 drop: 0.000056 both: 0.000290\n",
      "Train Epoch: 44 [20000/25000 (80%)]\tLosses default: 0.000017 bn: 0.000047 drop: 0.000229 both: 0.000767\n",
      "Train Epoch: 44 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000037 drop: 0.000077 both: 0.087602\n",
      "Test set:\n",
      "default: Loss: 1.1586\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 0.9670\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 0.9513\tAccuracy: 4407.0/5000 (88%)\n",
      "both: Loss: 0.9545\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 45 [0/25000 (0%)]\tLosses default: 0.000015 bn: 0.000110 drop: 0.000023 both: 0.000085\n",
      "Train Epoch: 45 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.000093 drop: 0.000141 both: 0.000021\n",
      "Train Epoch: 45 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000029 drop: 0.000139 both: 0.001016\n",
      "Train Epoch: 45 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000057 drop: 0.000015 both: 0.000038\n",
      "Test set:\n",
      "default: Loss: 1.1672\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 0.9983\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 0.9462\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 0.9930\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 46 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000053 drop: 0.000071 both: 0.000017\n",
      "Train Epoch: 46 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.002131 drop: 0.000158 both: 0.000025\n",
      "Train Epoch: 46 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000021 drop: 0.000020 both: 0.000048\n",
      "Train Epoch: 46 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000351 drop: 0.000038 both: 0.000057\n",
      "Test set:\n",
      "default: Loss: 1.1752\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 0.9853\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 0.9502\tAccuracy: 4413.0/5000 (88%)\n",
      "both: Loss: 0.9628\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 47 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.002030 drop: 0.000050 both: 0.000045\n",
      "Train Epoch: 47 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000028 drop: 0.000134 both: 0.000063\n",
      "Train Epoch: 47 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000121 drop: 0.000007 both: 0.000036\n",
      "Train Epoch: 47 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000180 drop: 0.000028 both: 0.000208\n",
      "Test set:\n",
      "default: Loss: 1.1825\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 0.9793\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 0.9685\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 0.9632\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 48 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000002 drop: 0.000033 both: 0.002000\n",
      "Train Epoch: 48 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.008333 drop: 0.000019 both: 0.000071\n",
      "Train Epoch: 48 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000087 drop: 0.000093 both: 0.000751\n",
      "Train Epoch: 48 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000042 drop: 0.000009 both: 0.000064\n",
      "Test set:\n",
      "default: Loss: 1.1882\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 0.9499\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 0.9780\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 0.9939\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 49 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000775 drop: 0.000077 both: 0.000098\n",
      "Train Epoch: 49 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.004505 drop: 0.000026 both: 0.000135\n",
      "Train Epoch: 49 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000493 drop: 0.000243 both: 0.000082\n",
      "Train Epoch: 49 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000546 drop: 0.000030 both: 0.000307\n",
      "Test set:\n",
      "default: Loss: 1.1962\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0050\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 0.9716\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 0.9870\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 50 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000919 drop: 0.000048 both: 0.001589\n",
      "Train Epoch: 50 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000061 drop: 0.000015 both: 0.000083\n",
      "Train Epoch: 50 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.002951 drop: 0.000042 both: 0.001298\n",
      "Train Epoch: 50 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000105 drop: 0.000041 both: 0.000057\n",
      "Test set:\n",
      "default: Loss: 1.2043\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 0.9780\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0012\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 0.9600\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 51 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000377 drop: 0.000047 both: 0.000225\n",
      "Train Epoch: 51 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.063684 drop: 0.000015 both: 0.006361\n",
      "Train Epoch: 51 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.013860 drop: 0.000210 both: 0.000620\n",
      "Train Epoch: 51 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.011381 drop: 0.017072 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.2111\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 0.9533\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 0.9516\tAccuracy: 4350.0/5000 (87%)\n",
      "both: Loss: 0.9584\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 52 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000017 drop: 0.114529 both: 0.002758\n",
      "Train Epoch: 52 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000183 drop: 0.003026 both: 0.000912\n",
      "Train Epoch: 52 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000089 drop: 0.000225 both: 0.000333\n",
      "Train Epoch: 52 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.001119 drop: 0.000162 both: 0.000168\n",
      "Test set:\n",
      "default: Loss: 1.2191\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 0.9737\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 0.9779\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 0.9684\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 53 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000072 both: 0.000506\n",
      "Train Epoch: 53 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000023 drop: 0.001960 both: 0.006067\n",
      "Train Epoch: 53 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000321 drop: 0.000022 both: 0.000021\n",
      "Train Epoch: 53 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000777 drop: 0.001032 both: 0.000041\n",
      "Test set:\n",
      "default: Loss: 1.2245\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9976\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 0.9531\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 0.9780\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 54 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000113 drop: 0.000467 both: 0.000057\n",
      "Train Epoch: 54 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.003079 drop: 0.000643 both: 0.000536\n",
      "Train Epoch: 54 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000904 drop: 0.000138 both: 0.003468\n",
      "Train Epoch: 54 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.002896 drop: 0.000070 both: 0.000105\n",
      "Test set:\n",
      "default: Loss: 1.2300\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 0.9594\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 0.9228\tAccuracy: 4416.0/5000 (88%)\n",
      "both: Loss: 0.9810\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 55 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001809 drop: 0.000534 both: 0.000752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 55 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.006926 drop: 0.000037 both: 0.000044\n",
      "Train Epoch: 55 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000045 drop: 0.000022 both: 0.000273\n",
      "Train Epoch: 55 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000052 both: 0.000064\n",
      "Test set:\n",
      "default: Loss: 1.2393\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9796\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 0.9599\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 0.9826\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 56 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.008380 drop: 0.000084 both: 0.009381\n",
      "Train Epoch: 56 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000272 drop: 0.000182 both: 0.000216\n",
      "Train Epoch: 56 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000046 both: 0.014169\n",
      "Train Epoch: 56 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000287 drop: 0.000030 both: 0.000032\n",
      "Test set:\n",
      "default: Loss: 1.2463\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9665\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 0.9528\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 0.9354\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 57 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000305 drop: 0.000510 both: 0.000690\n",
      "Train Epoch: 57 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.005755 drop: 0.000246 both: 0.000164\n",
      "Train Epoch: 57 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000594 drop: 0.000013 both: 0.001376\n",
      "Train Epoch: 57 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.002028 both: 0.000034\n",
      "Test set:\n",
      "default: Loss: 1.2490\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 0.9686\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.0374\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 0.9957\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 58 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000149 drop: 0.004424 both: 0.001457\n",
      "Train Epoch: 58 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000050 drop: 0.028527 both: 0.000027\n",
      "Train Epoch: 58 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.002819 drop: 0.002695 both: 0.000022\n",
      "Train Epoch: 58 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000050 drop: 0.000318 both: 0.002477\n",
      "Test set:\n",
      "default: Loss: 1.2592\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 0.9827\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.0038\tAccuracy: 4359.0/5000 (87%)\n",
      "both: Loss: 0.9905\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 59 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000045 drop: 0.016197 both: 0.005544\n",
      "Train Epoch: 59 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000183 drop: 0.004193 both: 0.000266\n",
      "Train Epoch: 59 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000837 drop: 0.000232 both: 0.000155\n",
      "Train Epoch: 59 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000046 drop: 0.000052 both: 0.000058\n",
      "Test set:\n",
      "default: Loss: 1.2670\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0116\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 0.9811\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 0.9679\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 60 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000321 drop: 0.000199 both: 0.000056\n",
      "Train Epoch: 60 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000136 both: 0.001482\n",
      "Train Epoch: 60 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001688 drop: 0.001242 both: 0.000045\n",
      "Train Epoch: 60 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000082 drop: 0.000119 both: 0.000071\n",
      "Test set:\n",
      "default: Loss: 1.2712\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 0.9791\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 0.9815\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 0.9635\tAccuracy: 4419.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 61 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.016009 drop: 0.000052 both: 0.000053\n",
      "Train Epoch: 61 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.006475 drop: 0.000012 both: 0.001997\n",
      "Train Epoch: 61 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000082 drop: 0.000019 both: 0.000834\n",
      "Train Epoch: 61 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.002867 drop: 0.000038 both: 0.000053\n",
      "Test set:\n",
      "default: Loss: 1.2792\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 0.9989\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 0.9865\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0218\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 62 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.003705 drop: 0.000029 both: 0.009086\n",
      "Train Epoch: 62 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000082 drop: 0.000218 both: 0.038877\n",
      "Train Epoch: 62 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.057681 drop: 0.000048 both: 0.000908\n",
      "Train Epoch: 62 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000998 drop: 0.000179 both: 0.000161\n",
      "Test set:\n",
      "default: Loss: 1.2848\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0014\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 0.9784\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0340\tAccuracy: 4348.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 63 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000108 both: 0.000126\n",
      "Train Epoch: 63 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000925 drop: 0.000049 both: 0.002080\n",
      "Train Epoch: 63 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001524 drop: 0.000064 both: 0.000084\n",
      "Train Epoch: 63 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.002507 drop: 0.000048 both: 0.000041\n",
      "Test set:\n",
      "default: Loss: 1.2936\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 0.9850\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 0.9950\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 0.9989\tAccuracy: 4362.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 64 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000061 both: 0.000015\n",
      "Train Epoch: 64 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.004501 drop: 0.000085 both: 0.000160\n",
      "Train Epoch: 64 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001361 drop: 0.000026 both: 0.000285\n",
      "Train Epoch: 64 [25000/25000 (100%)]\tLosses default: 0.548516 bn: 0.000037 drop: 0.000007 both: 0.001612\n",
      "Test set:\n",
      "default: Loss: 1.5088\tAccuracy: 4326.0/5000 (87%)\n",
      "bn: Loss: 0.9861\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.0142\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 0.9843\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 65 [0/25000 (0%)]\tLosses default: 0.481528 bn: 0.000060 drop: 0.000049 both: 0.000271\n",
      "Train Epoch: 65 [10000/25000 (40%)]\tLosses default: 0.025809 bn: 0.000123 drop: 0.000287 both: 0.000688\n",
      "Train Epoch: 65 [20000/25000 (80%)]\tLosses default: 0.000353 bn: 0.000041 drop: 0.000088 both: 0.001027\n",
      "Train Epoch: 65 [25000/25000 (100%)]\tLosses default: 0.002775 bn: 0.000058 drop: 0.000013 both: 0.073248\n",
      "Test set:\n",
      "default: Loss: 1.0895\tAccuracy: 4410.0/5000 (88%)\n",
      "bn: Loss: 0.9628\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 0.9857\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 0.9969\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 66 [0/25000 (0%)]\tLosses default: 0.001315 bn: 0.000079 drop: 0.000072 both: 0.003552\n",
      "Train Epoch: 66 [10000/25000 (40%)]\tLosses default: 0.002979 bn: 0.000044 drop: 0.000097 both: 0.000579\n",
      "Train Epoch: 66 [20000/25000 (80%)]\tLosses default: 0.000212 bn: 0.000085 drop: 0.000011 both: 0.001027\n",
      "Train Epoch: 66 [25000/25000 (100%)]\tLosses default: 0.000178 bn: 0.000420 drop: 0.002368 both: 0.000239\n",
      "Test set:\n",
      "default: Loss: 1.0949\tAccuracy: 4402.0/5000 (88%)\n",
      "bn: Loss: 1.0433\tAccuracy: 4396.0/5000 (88%)\n",
      "drop: Loss: 1.2690\tAccuracy: 4300.0/5000 (86%)\n",
      "both: Loss: 1.0197\tAccuracy: 4359.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 67 [0/25000 (0%)]\tLosses default: 0.000207 bn: 0.000443 drop: 0.007370 both: 0.117569\n",
      "Train Epoch: 67 [10000/25000 (40%)]\tLosses default: 0.000122 bn: 0.000034 drop: 0.031232 both: 0.000042\n",
      "Train Epoch: 67 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.004382 drop: 0.002302 both: 0.000080\n",
      "Train Epoch: 67 [25000/25000 (100%)]\tLosses default: 0.000381 bn: 0.000226 drop: 0.000140 both: 0.000140\n",
      "Test set:\n",
      "default: Loss: 1.0942\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0106\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 0.9641\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 0.9306\tAccuracy: 4423.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 68 [0/25000 (0%)]\tLosses default: 0.000040 bn: 0.000034 drop: 0.000376 both: 0.000508\n",
      "Train Epoch: 68 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000164 drop: 0.000327 both: 0.000804\n",
      "Train Epoch: 68 [20000/25000 (80%)]\tLosses default: 0.000013 bn: 0.001737 drop: 0.000058 both: 0.000014\n",
      "Train Epoch: 68 [25000/25000 (100%)]\tLosses default: 0.000023 bn: 0.000250 drop: 0.000136 both: 0.005543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "default: Loss: 1.1045\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0202\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 0.9833\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 0.9868\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 69 [0/25000 (0%)]\tLosses default: 0.000099 bn: 0.000481 drop: 0.027790 both: 0.003037\n",
      "Train Epoch: 69 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000411 drop: 0.000097 both: 0.000147\n",
      "Train Epoch: 69 [20000/25000 (80%)]\tLosses default: 0.000047 bn: 0.000038 drop: 0.000217 both: 0.000040\n",
      "Train Epoch: 69 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000042 drop: 0.000032 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.1126\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 0.9840\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 0.9803\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 0.9719\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 70 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.000112 drop: 0.000378 both: 0.000017\n",
      "Train Epoch: 70 [10000/25000 (40%)]\tLosses default: 0.000033 bn: 0.000362 drop: 0.000012 both: 0.000525\n",
      "Train Epoch: 70 [20000/25000 (80%)]\tLosses default: 0.000039 bn: 0.000011 drop: 0.000070 both: 0.000162\n",
      "Train Epoch: 70 [25000/25000 (100%)]\tLosses default: 0.000042 bn: 0.000643 drop: 0.000205 both: 0.025559\n",
      "Test set:\n",
      "default: Loss: 1.1223\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 0.9858\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 0.9660\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0073\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 71 [0/25000 (0%)]\tLosses default: 0.000024 bn: 0.008512 drop: 0.000057 both: 0.000111\n",
      "Train Epoch: 71 [10000/25000 (40%)]\tLosses default: 0.000046 bn: 0.000888 drop: 0.000032 both: 0.000205\n",
      "Train Epoch: 71 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000024 both: 0.000081\n",
      "Train Epoch: 71 [25000/25000 (100%)]\tLosses default: 0.000044 bn: 0.000095 drop: 0.000159 both: 0.000304\n",
      "Test set:\n",
      "default: Loss: 1.1313\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 0.9867\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 0.9756\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 0.9643\tAccuracy: 4363.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 72 [0/25000 (0%)]\tLosses default: 0.000013 bn: 0.000012 drop: 0.000125 both: 0.000042\n",
      "Train Epoch: 72 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000005 drop: 0.000098 both: 0.001590\n",
      "Train Epoch: 72 [20000/25000 (80%)]\tLosses default: 0.000045 bn: 0.002594 drop: 0.000100 both: 0.001921\n",
      "Train Epoch: 72 [25000/25000 (100%)]\tLosses default: 0.000020 bn: 0.000025 drop: 0.056712 both: 0.006130\n",
      "Test set:\n",
      "default: Loss: 1.1389\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0106\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 0.9599\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0230\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 73 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000050 drop: 0.000035 both: 0.007536\n",
      "Train Epoch: 73 [10000/25000 (40%)]\tLosses default: 0.000042 bn: 0.000102 drop: 0.000119 both: 0.020785\n",
      "Train Epoch: 73 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000024 drop: 0.000128 both: 0.000196\n",
      "Train Epoch: 73 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000014 drop: 0.023298 both: 0.000041\n",
      "Test set:\n",
      "default: Loss: 1.1470\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.0063\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 0.9587\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 0.9467\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 74 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000018 drop: 0.000069 both: 0.000519\n",
      "Train Epoch: 74 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000018 drop: 0.000029 both: 0.000028\n",
      "Train Epoch: 74 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000225 drop: 0.000056 both: 0.000328\n",
      "Train Epoch: 74 [25000/25000 (100%)]\tLosses default: 0.000011 bn: 0.000796 drop: 0.000056 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1569\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0183\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 0.9642\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 0.9604\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 75 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000011 drop: 0.000186 both: 0.001265\n",
      "Train Epoch: 75 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000190 drop: 0.000216 both: 0.000612\n",
      "Train Epoch: 75 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000076 drop: 0.000539 both: 0.117989\n",
      "Train Epoch: 75 [25000/25000 (100%)]\tLosses default: 0.000012 bn: 0.004088 drop: 0.000089 both: 0.017175\n",
      "Test set:\n",
      "default: Loss: 1.1637\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0156\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 0.9648\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 0.9613\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 76 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000066 drop: 0.000167 both: 0.000044\n",
      "Train Epoch: 76 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000345 drop: 0.001369 both: 0.000101\n",
      "Train Epoch: 76 [20000/25000 (80%)]\tLosses default: 0.000026 bn: 0.000467 drop: 0.000028 both: 0.000254\n",
      "Train Epoch: 76 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.175957 drop: 0.000063 both: 0.000149\n",
      "Test set:\n",
      "default: Loss: 1.1714\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0021\tAccuracy: 4400.0/5000 (88%)\n",
      "drop: Loss: 0.9608\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 0.9321\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 77 [0/25000 (0%)]\tLosses default: 0.000039 bn: 0.004426 drop: 0.000094 both: 0.030661\n",
      "Train Epoch: 77 [10000/25000 (40%)]\tLosses default: 0.000018 bn: 0.002272 drop: 0.000058 both: 0.006244\n",
      "Train Epoch: 77 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000050 both: 0.000278\n",
      "Train Epoch: 77 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000536 drop: 0.003058 both: 0.000579\n",
      "Test set:\n",
      "default: Loss: 1.1792\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 0.9863\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 0.9587\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 0.9335\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 78 [0/25000 (0%)]\tLosses default: 0.000016 bn: 0.000030 drop: 0.000045 both: 0.000165\n",
      "Train Epoch: 78 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000293 drop: 0.000079 both: 0.000024\n",
      "Train Epoch: 78 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000014 both: 0.000097\n",
      "Train Epoch: 78 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000013 drop: 0.000007 both: 0.000420\n",
      "Test set:\n",
      "default: Loss: 1.1861\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 0.9814\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 0.9735\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 0.9325\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 79 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000219 drop: 0.000067 both: 0.000181\n",
      "Train Epoch: 79 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000932 drop: 0.000028 both: 0.000061\n",
      "Train Epoch: 79 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000046 drop: 0.000041 both: 0.067823\n",
      "Train Epoch: 79 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000007 drop: 0.000020 both: 0.021094\n",
      "Test set:\n",
      "default: Loss: 1.1925\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 0.9869\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 0.9749\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 0.9825\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 80 [0/25000 (0%)]\tLosses default: 0.000008 bn: 0.000194 drop: 0.000205 both: 0.013845\n",
      "Train Epoch: 80 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000029 both: 0.000483\n",
      "Train Epoch: 80 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000100 drop: 0.000017 both: 0.000076\n",
      "Train Epoch: 80 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000178 drop: 0.000054 both: 0.000902\n",
      "Test set:\n",
      "default: Loss: 1.2003\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 0.9608\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 0.9914\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 0.9930\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 81 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000023 drop: 0.003553 both: 0.004813\n",
      "Train Epoch: 81 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000026 drop: 0.000389 both: 0.000606\n",
      "Train Epoch: 81 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000131 drop: 0.176136 both: 0.000118\n",
      "Train Epoch: 81 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000041 drop: 0.034203 both: 0.003062\n",
      "Test set:\n",
      "default: Loss: 1.2062\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 0.9954\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 0.9015\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 0.9624\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 82 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000696 drop: 0.000361 both: 0.021875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 82 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000009 drop: 0.000125 both: 0.000202\n",
      "Train Epoch: 82 [20000/25000 (80%)]\tLosses default: 0.000011 bn: 0.002181 drop: 0.000903 both: 0.000058\n",
      "Train Epoch: 82 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.001085 drop: 0.000322 both: 0.000152\n",
      "Test set:\n",
      "default: Loss: 1.2123\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9917\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 0.9010\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 0.9954\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 83 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000011 drop: 0.000152 both: 0.000044\n",
      "Train Epoch: 83 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000312 drop: 0.000151 both: 0.000031\n",
      "Train Epoch: 83 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000021 drop: 0.000231 both: 0.011914\n",
      "Train Epoch: 83 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000463 drop: 0.000021 both: 0.000093\n",
      "Test set:\n",
      "default: Loss: 1.2181\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 0.9933\tAccuracy: 4393.0/5000 (88%)\n",
      "drop: Loss: 0.9314\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 0.9723\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 84 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000010 drop: 0.000019 both: 0.000172\n",
      "Train Epoch: 84 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000135 drop: 0.000216 both: 0.000207\n",
      "Train Epoch: 84 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000030 both: 0.000168\n",
      "Train Epoch: 84 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000002 drop: 0.000116 both: 0.000183\n",
      "Test set:\n",
      "default: Loss: 1.2240\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9920\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 0.9171\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 0.9603\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 85 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000048 both: 0.000299\n",
      "Train Epoch: 85 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000069 both: 0.000023\n",
      "Train Epoch: 85 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000054 drop: 0.000026 both: 0.000051\n",
      "Train Epoch: 85 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.000237 both: 0.001202\n",
      "Test set:\n",
      "default: Loss: 1.2300\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9933\tAccuracy: 4401.0/5000 (88%)\n",
      "drop: Loss: 0.9302\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0280\tAccuracy: 4362.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 86 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.001235 both: 0.153859\n",
      "Train Epoch: 86 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.001166 drop: 0.000066 both: 0.000811\n",
      "Train Epoch: 86 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000056 drop: 0.000132 both: 0.006232\n",
      "Train Epoch: 86 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.003519 drop: 0.000009 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.2369\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0067\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 0.9468\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0003\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 87 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000821 drop: 0.000034 both: 0.004188\n",
      "Train Epoch: 87 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000220 drop: 0.000206 both: 0.000709\n",
      "Train Epoch: 87 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000061 drop: 0.000026 both: 0.000070\n",
      "Train Epoch: 87 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000119 drop: 0.000061 both: 0.000069\n",
      "Test set:\n",
      "default: Loss: 1.2422\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9878\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 0.9344\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 0.9834\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 88 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000681 drop: 0.000091 both: 0.023808\n",
      "Train Epoch: 88 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000026 drop: 0.000181 both: 0.001080\n",
      "Train Epoch: 88 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000040 drop: 0.065396 both: 0.000905\n",
      "Train Epoch: 88 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000053 drop: 0.040555 both: 0.072531\n",
      "Test set:\n",
      "default: Loss: 1.2483\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 0.9755\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 0.9759\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 0.9674\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 89 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000083 drop: 0.080199 both: 0.000089\n",
      "Train Epoch: 89 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.011238 drop: 0.005406 both: 0.006916\n",
      "Train Epoch: 89 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000262 drop: 0.002224 both: 0.000011\n",
      "Train Epoch: 89 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000875 drop: 0.000031 both: 0.000121\n",
      "Test set:\n",
      "default: Loss: 1.2533\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 0.9999\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 0.9543\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 0.9630\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 90 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000073 drop: 0.001722 both: 0.000139\n",
      "Train Epoch: 90 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000061 drop: 0.001065 both: 0.001567\n",
      "Train Epoch: 90 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000135 drop: 0.001611 both: 0.000008\n",
      "Train Epoch: 90 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.002919 both: 0.000056\n",
      "Test set:\n",
      "default: Loss: 1.2601\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9957\tAccuracy: 4401.0/5000 (88%)\n",
      "drop: Loss: 0.9569\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 0.9759\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 91 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000274 drop: 0.000446 both: 0.000024\n",
      "Train Epoch: 91 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.062083 drop: 0.000011 both: 0.000035\n",
      "Train Epoch: 91 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000026 both: 0.000577\n",
      "Train Epoch: 91 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000535 drop: 0.001321 both: 0.000093\n",
      "Test set:\n",
      "default: Loss: 1.2638\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0030\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 0.9761\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 0.9761\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 92 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.004812 drop: 0.000130 both: 0.000019\n",
      "Train Epoch: 92 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000298 drop: 0.000113 both: 0.000050\n",
      "Train Epoch: 92 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000038 drop: 0.000290 both: 0.000109\n",
      "Train Epoch: 92 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000443 drop: 0.000013 both: 0.000114\n",
      "Test set:\n",
      "default: Loss: 1.2684\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0460\tAccuracy: 4381.0/5000 (88%)\n",
      "drop: Loss: 0.9597\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0203\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 93 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000612 drop: 0.000019 both: 0.000180\n",
      "Train Epoch: 93 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000094 drop: 0.069563 both: 0.000005\n",
      "Train Epoch: 93 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001384 drop: 0.000122 both: 0.000796\n",
      "Train Epoch: 93 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000020 drop: 0.000035 both: 0.001273\n",
      "Test set:\n",
      "default: Loss: 1.2753\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0019\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 0.9496\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0485\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 94 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000022 both: 0.006989\n",
      "Train Epoch: 94 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000216 drop: 0.000035 both: 0.000656\n",
      "Train Epoch: 94 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000164 drop: 0.000191 both: 0.000220\n",
      "Train Epoch: 94 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000118 drop: 0.008662 both: 0.000560\n",
      "Test set:\n",
      "default: Loss: 1.2804\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0302\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 0.9821\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 0.9606\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 95 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.005103 drop: 0.000152 both: 0.000030\n",
      "Train Epoch: 95 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000344 drop: 0.017125 both: 0.000130\n",
      "Train Epoch: 95 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.004886 both: 0.000276\n",
      "Train Epoch: 95 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000701 drop: 0.000126 both: 0.000065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "default: Loss: 1.2875\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0207\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 1.1625\tAccuracy: 4250.0/5000 (85%)\n",
      "both: Loss: 0.9676\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 96 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000377 drop: 0.003932 both: 0.000030\n",
      "Train Epoch: 96 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.012539 both: 0.000508\n",
      "Train Epoch: 96 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000059 drop: 0.000073 both: 0.000191\n",
      "Train Epoch: 96 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000019 drop: 0.000107 both: 0.000746\n",
      "Test set:\n",
      "default: Loss: 1.2912\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0197\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 0.9817\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0022\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 97 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000080 drop: 0.000026 both: 0.000207\n",
      "Train Epoch: 97 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000065 drop: 0.000093 both: 0.000065\n",
      "Train Epoch: 97 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000148 drop: 0.000058 both: 0.000177\n",
      "Train Epoch: 97 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.006078 drop: 0.000238 both: 0.000109\n",
      "Test set:\n",
      "default: Loss: 1.2962\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0110\tAccuracy: 4404.0/5000 (88%)\n",
      "drop: Loss: 0.9842\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 0.9684\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 98 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000096 both: 0.000134\n",
      "Train Epoch: 98 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000197 drop: 0.000157 both: 0.000011\n",
      "Train Epoch: 98 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.003239 drop: 0.002406 both: 0.000518\n",
      "Train Epoch: 98 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.005037 drop: 0.000018 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.3032\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 0.9775\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 0.9744\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 0.9870\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 99 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000099 drop: 0.000059 both: 0.002207\n",
      "Train Epoch: 99 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000047 drop: 0.000040 both: 0.000326\n",
      "Train Epoch: 99 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000034 both: 0.001036\n",
      "Train Epoch: 99 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000144 both: 0.000032\n",
      "Test set:\n",
      "default: Loss: 1.3091\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 0.9741\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 0.9643\tAccuracy: 4410.0/5000 (88%)\n",
      "both: Loss: 1.0448\tAccuracy: 4361.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 100 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000036 both: 0.004349\n",
      "Train Epoch: 100 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000021 both: 0.000045\n",
      "Train Epoch: 100 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000092 drop: 0.000348 both: 0.000336\n",
      "Train Epoch: 100 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000537 drop: 0.000015 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.3152\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0058\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 0.9872\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 0.9550\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 101 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000041 both: 0.000055\n",
      "Train Epoch: 101 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.008032 drop: 0.000008 both: 0.031096\n",
      "Train Epoch: 101 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000064 drop: 0.000052 both: 0.000019\n",
      "Train Epoch: 101 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.029374 drop: 0.000022 both: 0.000066\n",
      "Test set:\n",
      "default: Loss: 1.3242\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9858\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 0.9982\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 0.9598\tAccuracy: 4417.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 102 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000920 drop: 0.000024 both: 0.000946\n",
      "Train Epoch: 102 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000068 drop: 0.000118 both: 0.000102\n",
      "Train Epoch: 102 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000019 both: 0.000044\n",
      "Train Epoch: 102 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000022 both: 0.000278\n",
      "Test set:\n",
      "default: Loss: 1.3270\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 0.9934\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 0.9747\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 0.9681\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 103 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000109 drop: 0.000009 both: 0.000367\n",
      "Train Epoch: 103 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000016 both: 0.000036\n",
      "Train Epoch: 103 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000002 both: 0.000099\n",
      "Train Epoch: 103 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000020 both: 0.000212\n",
      "Test set:\n",
      "default: Loss: 1.3380\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 0.9888\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 0.9812\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 0.9941\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 104 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000044 both: 0.000014\n",
      "Train Epoch: 104 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000114 drop: 0.000042 both: 0.007733\n",
      "Train Epoch: 104 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000023 both: 0.000301\n",
      "Train Epoch: 104 [25000/25000 (100%)]\tLosses default: 0.528260 bn: 0.000007 drop: 0.000115 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.7283\tAccuracy: 4278.0/5000 (86%)\n",
      "bn: Loss: 1.0064\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0010\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 0.9669\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 105 [0/25000 (0%)]\tLosses default: 0.618217 bn: 0.000109 drop: 0.000048 both: 0.000887\n",
      "Train Epoch: 105 [10000/25000 (40%)]\tLosses default: 0.000345 bn: 0.000091 drop: 0.000205 both: 0.000064\n",
      "Train Epoch: 105 [20000/25000 (80%)]\tLosses default: 0.002467 bn: 0.000042 drop: 0.000022 both: 0.000024\n",
      "Train Epoch: 105 [25000/25000 (100%)]\tLosses default: 0.054536 bn: 0.000299 drop: 0.000005 both: 0.002822\n",
      "Test set:\n",
      "default: Loss: 1.1802\tAccuracy: 4386.0/5000 (88%)\n",
      "bn: Loss: 0.9799\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0019\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 0.9962\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 106 [0/25000 (0%)]\tLosses default: 0.000753 bn: 0.000041 drop: 0.000030 both: 0.002972\n",
      "Train Epoch: 106 [10000/25000 (40%)]\tLosses default: 0.000504 bn: 0.000486 drop: 0.000046 both: 0.000033\n",
      "Train Epoch: 106 [20000/25000 (80%)]\tLosses default: 0.001264 bn: 0.000018 drop: 0.000042 both: 0.000045\n",
      "Train Epoch: 106 [25000/25000 (100%)]\tLosses default: 0.000327 bn: 0.000022 drop: 0.000009 both: 0.000095\n",
      "Test set:\n",
      "default: Loss: 1.1214\tAccuracy: 4414.0/5000 (88%)\n",
      "bn: Loss: 1.0041\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 0.9999\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0107\tAccuracy: 4358.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 107 [0/25000 (0%)]\tLosses default: 0.000014 bn: 0.000187 drop: 0.000037 both: 0.000378\n",
      "Train Epoch: 107 [10000/25000 (40%)]\tLosses default: 0.000829 bn: 0.000228 drop: 0.000052 both: 0.000341\n",
      "Train Epoch: 107 [20000/25000 (80%)]\tLosses default: 0.000015 bn: 0.000047 drop: 0.000029 both: 0.000273\n",
      "Train Epoch: 107 [25000/25000 (100%)]\tLosses default: 0.000108 bn: 0.177810 drop: 0.000036 both: 0.000325\n",
      "Test set:\n",
      "default: Loss: 1.1212\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.0385\tAccuracy: 4390.0/5000 (88%)\n",
      "drop: Loss: 1.0140\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0258\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 108 [0/25000 (0%)]\tLosses default: 0.000026 bn: 0.000112 drop: 0.000046 both: 0.000013\n",
      "Train Epoch: 108 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000305 drop: 0.000008 both: 0.000073\n",
      "Train Epoch: 108 [20000/25000 (80%)]\tLosses default: 0.000033 bn: 0.000118 drop: 0.000006 both: 0.000023\n",
      "Train Epoch: 108 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000138 drop: 0.140807 both: 0.000341\n",
      "Test set:\n",
      "default: Loss: 1.1265\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 0.9954\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0838\tAccuracy: 4349.0/5000 (87%)\n",
      "both: Loss: 1.0550\tAccuracy: 4352.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 109 [0/25000 (0%)]\tLosses default: 0.000215 bn: 0.000039 drop: 0.211243 both: 0.000040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 109 [10000/25000 (40%)]\tLosses default: 0.000022 bn: 0.001149 drop: 0.000352 both: 0.000133\n",
      "Train Epoch: 109 [20000/25000 (80%)]\tLosses default: 0.000046 bn: 0.000612 drop: 0.000167 both: 0.000158\n",
      "Train Epoch: 109 [25000/25000 (100%)]\tLosses default: 0.000043 bn: 0.000015 drop: 0.000328 both: 0.000340\n",
      "Test set:\n",
      "default: Loss: 1.1302\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0033\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 0.9793\tAccuracy: 4372.0/5000 (87%)\n",
      "both: Loss: 0.9780\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 110 [0/25000 (0%)]\tLosses default: 0.000062 bn: 0.000038 drop: 0.000064 both: 0.000143\n",
      "Train Epoch: 110 [10000/25000 (40%)]\tLosses default: 0.000037 bn: 0.001310 drop: 0.000047 both: 0.000054\n",
      "Train Epoch: 110 [20000/25000 (80%)]\tLosses default: 0.000068 bn: 0.000081 drop: 0.000087 both: 0.000034\n",
      "Train Epoch: 110 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.002327 drop: 0.000023 both: 0.000161\n",
      "Test set:\n",
      "default: Loss: 1.1340\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9925\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 0.9721\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0071\tAccuracy: 4361.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 111 [0/25000 (0%)]\tLosses default: 0.000042 bn: 0.006872 drop: 0.000082 both: 0.001343\n",
      "Train Epoch: 111 [10000/25000 (40%)]\tLosses default: 0.000015 bn: 0.000037 drop: 0.000038 both: 0.000158\n",
      "Train Epoch: 111 [20000/25000 (80%)]\tLosses default: 0.000054 bn: 0.000942 drop: 0.004837 both: 0.000387\n",
      "Train Epoch: 111 [25000/25000 (100%)]\tLosses default: 0.000153 bn: 0.000141 drop: 0.000205 both: 0.003786\n",
      "Test set:\n",
      "default: Loss: 1.1383\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9834\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 0.9607\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0032\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 112 [0/25000 (0%)]\tLosses default: 0.000034 bn: 0.000363 drop: 0.000096 both: 0.000280\n",
      "Train Epoch: 112 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000120 drop: 0.000034 both: 0.000036\n",
      "Train Epoch: 112 [20000/25000 (80%)]\tLosses default: 0.000012 bn: 0.000224 drop: 0.000515 both: 0.001020\n",
      "Train Epoch: 112 [25000/25000 (100%)]\tLosses default: 0.000103 bn: 0.000020 drop: 0.000031 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.1426\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9932\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 0.9930\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 0.9893\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 113 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000002 drop: 0.000057 both: 0.000015\n",
      "Train Epoch: 113 [10000/25000 (40%)]\tLosses default: 0.000080 bn: 0.000006 drop: 0.000177 both: 0.000049\n",
      "Train Epoch: 113 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000001 drop: 0.000015 both: 0.000057\n",
      "Train Epoch: 113 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.016122 drop: 0.020118 both: 0.000161\n",
      "Test set:\n",
      "default: Loss: 1.1477\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 0.9929\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0230\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0443\tAccuracy: 4360.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 114 [0/25000 (0%)]\tLosses default: 0.000014 bn: 0.000011 drop: 0.000028 both: 0.001690\n",
      "Train Epoch: 114 [10000/25000 (40%)]\tLosses default: 0.000028 bn: 0.000009 drop: 0.000035 both: 0.000022\n",
      "Train Epoch: 114 [20000/25000 (80%)]\tLosses default: 0.000019 bn: 0.000003 drop: 0.000405 both: 0.000930\n",
      "Train Epoch: 114 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000131 both: 0.000674\n",
      "Test set:\n",
      "default: Loss: 1.1521\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0114\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 0.9923\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0081\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 115 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000008 drop: 0.000020 both: 0.000019\n",
      "Train Epoch: 115 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.002147 drop: 0.000092 both: 0.009535\n",
      "Train Epoch: 115 [20000/25000 (80%)]\tLosses default: 0.000010 bn: 0.000050 drop: 0.000058 both: 0.000009\n",
      "Train Epoch: 115 [25000/25000 (100%)]\tLosses default: 0.000016 bn: 0.000185 drop: 0.000032 both: 0.000358\n",
      "Test set:\n",
      "default: Loss: 1.1577\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.0086\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0015\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0308\tAccuracy: 4358.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 116 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000003 drop: 0.000011 both: 0.005623\n",
      "Train Epoch: 116 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.004078 drop: 0.000174 both: 0.002007\n",
      "Train Epoch: 116 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000007 both: 0.000419\n",
      "Train Epoch: 116 [25000/25000 (100%)]\tLosses default: 0.000020 bn: 0.001104 drop: 0.000041 both: 0.001083\n",
      "Test set:\n",
      "default: Loss: 1.1635\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0160\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0043\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0073\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 117 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000033 drop: 0.000172 both: 0.022171\n",
      "Train Epoch: 117 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000010 drop: 0.000021 both: 0.032579\n",
      "Train Epoch: 117 [20000/25000 (80%)]\tLosses default: 0.000018 bn: 0.000039 drop: 0.000009 both: 0.000014\n",
      "Train Epoch: 117 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000054 drop: 0.000039 both: 0.000030\n",
      "Test set:\n",
      "default: Loss: 1.1693\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 0.9835\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 0.9969\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 0.9979\tAccuracy: 4357.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 118 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000008 drop: 0.000050 both: 0.000074\n",
      "Train Epoch: 118 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000079 drop: 0.000020 both: 0.035985\n",
      "Train Epoch: 118 [20000/25000 (80%)]\tLosses default: 0.000011 bn: 0.000006 drop: 0.033487 both: 0.000075\n",
      "Train Epoch: 118 [25000/25000 (100%)]\tLosses default: 0.000022 bn: 0.000365 drop: 0.023653 both: 0.000156\n",
      "Test set:\n",
      "default: Loss: 1.1750\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.0067\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 0.9851\tAccuracy: 4331.0/5000 (87%)\n",
      "both: Loss: 0.9810\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 119 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000004 drop: 0.025628 both: 0.005072\n",
      "Train Epoch: 119 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000006 drop: 0.008097 both: 0.000002\n",
      "Train Epoch: 119 [20000/25000 (80%)]\tLosses default: 0.000014 bn: 0.000081 drop: 0.000068 both: 0.000508\n",
      "Train Epoch: 119 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000092 drop: 0.000343 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.1806\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0142\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 0.9445\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 0.9681\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 120 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000568 drop: 0.001882 both: 0.000052\n",
      "Train Epoch: 120 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.006594 drop: 0.000076 both: 0.000058\n",
      "Train Epoch: 120 [20000/25000 (80%)]\tLosses default: 0.000011 bn: 0.000009 drop: 0.000057 both: 0.000008\n",
      "Train Epoch: 120 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000073 drop: 0.000122 both: 0.000153\n",
      "Test set:\n",
      "default: Loss: 1.1870\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.0373\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 0.9530\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 0.9832\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 121 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000130 both: 0.000114\n",
      "Train Epoch: 121 [10000/25000 (40%)]\tLosses default: 0.000015 bn: 0.001971 drop: 0.000096 both: 0.000069\n",
      "Train Epoch: 121 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000189 drop: 0.000052 both: 0.000260\n",
      "Train Epoch: 121 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000042 drop: 0.011840 both: 0.001538\n",
      "Test set:\n",
      "default: Loss: 1.1925\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0268\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 0.9813\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0379\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 122 [0/25000 (0%)]\tLosses default: 0.000008 bn: 0.000248 drop: 0.002106 both: 0.000094\n",
      "Train Epoch: 122 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.001579 both: 0.000097\n",
      "Train Epoch: 122 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000399 drop: 0.000019 both: 0.002449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 122 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000218 drop: 0.000070 both: 0.000868\n",
      "Test set:\n",
      "default: Loss: 1.1980\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0466\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 0.9317\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 0.9875\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 123 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.029359 drop: 0.000025 both: 0.000027\n",
      "Train Epoch: 123 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000564 drop: 0.000105 both: 0.000091\n",
      "Train Epoch: 123 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000013 drop: 0.001700 both: 0.000027\n",
      "Train Epoch: 123 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000019 drop: 0.000017 both: 0.001236\n",
      "Test set:\n",
      "default: Loss: 1.2041\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0031\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 0.9621\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 0.9735\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 124 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000011 both: 0.000014\n",
      "Train Epoch: 124 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000006 drop: 0.000066 both: 0.000045\n",
      "Train Epoch: 124 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.001377 drop: 0.000079 both: 0.000816\n",
      "Train Epoch: 124 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000042 drop: 0.001278 both: 0.003074\n",
      "Test set:\n",
      "default: Loss: 1.2101\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0011\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 0.9887\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 0.9680\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 125 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000245 drop: 0.002228 both: 0.000017\n",
      "Train Epoch: 125 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.001916 both: 0.000184\n",
      "Train Epoch: 125 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.005157 drop: 0.000203 both: 0.067203\n",
      "Train Epoch: 125 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000006 drop: 0.001333 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.2164\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0294\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0268\tAccuracy: 4334.0/5000 (87%)\n",
      "both: Loss: 0.9879\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 126 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000037 drop: 0.003218 both: 0.000125\n",
      "Train Epoch: 126 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000220 drop: 0.000410 both: 0.001864\n",
      "Train Epoch: 126 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000554 drop: 0.000016 both: 0.014885\n",
      "Train Epoch: 126 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000029 both: 0.000384\n",
      "Test set:\n",
      "default: Loss: 1.2229\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0250\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 0.9637\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0068\tAccuracy: 4352.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 127 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000087 drop: 0.005836 both: 0.000956\n",
      "Train Epoch: 127 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000009 drop: 0.000858 both: 0.000224\n",
      "Train Epoch: 127 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000428 drop: 0.000219 both: 0.000035\n",
      "Train Epoch: 127 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000700 drop: 0.000330 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 1.2296\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 0.9524\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0200\tAccuracy: 4365.0/5000 (87%)\n",
      "both: Loss: 0.9474\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 128 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000240 both: 0.000013\n",
      "Train Epoch: 128 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000025 drop: 0.000135 both: 0.000050\n",
      "Train Epoch: 128 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000046 both: 0.000011\n",
      "Train Epoch: 128 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000146 drop: 0.000317 both: 0.000062\n",
      "Test set:\n",
      "default: Loss: 1.2335\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9527\tAccuracy: 4446.0/5000 (89%)\n",
      "drop: Loss: 1.0046\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 0.9529\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 129 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000284 drop: 0.000052 both: 0.000020\n",
      "Train Epoch: 129 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000320 drop: 0.000069 both: 0.000056\n",
      "Train Epoch: 129 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000026 both: 0.000061\n",
      "Train Epoch: 129 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000134 drop: 0.000036 both: 0.002475\n",
      "Test set:\n",
      "default: Loss: 1.2400\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 0.9739\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.0033\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 0.9735\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 130 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000124 both: 0.000029\n",
      "Train Epoch: 130 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000053 drop: 0.000320 both: 0.062963\n",
      "Train Epoch: 130 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000022 both: 0.003969\n",
      "Train Epoch: 130 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000039 drop: 0.000008 both: 0.022476\n",
      "Test set:\n",
      "default: Loss: 1.2474\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9758\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 0.9751\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 0.9904\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 131 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000450 drop: 0.000177 both: 0.000069\n",
      "Train Epoch: 131 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000150 drop: 0.000016 both: 0.000574\n",
      "Train Epoch: 131 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000024 both: 0.000024\n",
      "Train Epoch: 131 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000090 drop: 0.000165 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.2520\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 0.9757\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0003\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 0.9974\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 132 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000016 both: 0.000016\n",
      "Train Epoch: 132 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000033 drop: 0.000083 both: 0.001130\n",
      "Train Epoch: 132 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000025 both: 0.000026\n",
      "Train Epoch: 132 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.062632 drop: 0.000008 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2593\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0082\tAccuracy: 4400.0/5000 (88%)\n",
      "drop: Loss: 0.9977\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 0.9708\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 133 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.006168 drop: 0.000032 both: 0.000131\n",
      "Train Epoch: 133 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.009589 drop: 0.000001 both: 0.000023\n",
      "Train Epoch: 133 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000054 drop: 0.000007 both: 0.000218\n",
      "Train Epoch: 133 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000099 both: 0.000216\n",
      "Test set:\n",
      "default: Loss: 1.2642\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9932\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.2155\tAccuracy: 4291.0/5000 (86%)\n",
      "both: Loss: 0.9802\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 134 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000021 drop: 0.041863 both: 0.000295\n",
      "Train Epoch: 134 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.014967 drop: 0.001608 both: 0.002586\n",
      "Train Epoch: 134 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000109 drop: 0.009199 both: 0.000013\n",
      "Train Epoch: 134 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000431 drop: 0.002442 both: 0.000152\n",
      "Test set:\n",
      "default: Loss: 1.2697\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 0.9628\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 0.9482\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 0.9476\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 135 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000035 drop: 0.000017 both: 0.000404\n",
      "Train Epoch: 135 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000060 drop: 0.000121 both: 0.000069\n",
      "Train Epoch: 135 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000164 drop: 0.000045 both: 0.000127\n",
      "Train Epoch: 135 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000135 both: 0.000261\n",
      "Test set:\n",
      "default: Loss: 1.2773\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 0.9773\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 0.9317\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0381\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 136 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.006714 drop: 0.000014 both: 0.003016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 136 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001244 drop: 0.000112 both: 0.007507\n",
      "Train Epoch: 136 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000062 both: 0.003208\n",
      "Train Epoch: 136 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000967 drop: 0.000434 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.2844\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 0.9485\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 0.9543\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 0.9800\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 137 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000322 drop: 0.000186 both: 0.009741\n",
      "Train Epoch: 137 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000139 both: 0.000008\n",
      "Train Epoch: 137 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000103 both: 0.000447\n",
      "Train Epoch: 137 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.013724 drop: 0.000028 both: 0.000119\n",
      "Test set:\n",
      "default: Loss: 1.2863\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 0.9802\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 0.9814\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0106\tAccuracy: 4365.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 138 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.005232 both: 0.000025\n",
      "Train Epoch: 138 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000067 both: 0.000170\n",
      "Train Epoch: 138 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000038 both: 0.000084\n",
      "Train Epoch: 138 [25000/25000 (100%)]\tLosses default: 0.512054 bn: 0.000353 drop: 0.000032 both: 0.000150\n",
      "Test set:\n",
      "default: Loss: 1.5146\tAccuracy: 4323.0/5000 (86%)\n",
      "bn: Loss: 0.9671\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 0.9763\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0154\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 139 [0/25000 (0%)]\tLosses default: 0.012729 bn: 0.000942 drop: 0.000021 both: 0.005172\n",
      "Train Epoch: 139 [10000/25000 (40%)]\tLosses default: 0.024967 bn: 0.000084 drop: 0.000008 both: 0.000057\n",
      "Train Epoch: 139 [20000/25000 (80%)]\tLosses default: 0.001082 bn: 0.000014 drop: 0.000014 both: 0.000144\n",
      "Train Epoch: 139 [25000/25000 (100%)]\tLosses default: 0.004870 bn: 0.000001 drop: 0.000059 both: 0.000293\n",
      "Test set:\n",
      "default: Loss: 1.0307\tAccuracy: 4412.0/5000 (88%)\n",
      "bn: Loss: 0.9824\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 0.9890\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 0.9864\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 140 [0/25000 (0%)]\tLosses default: 0.000866 bn: 0.000203 drop: 0.000212 both: 0.000201\n",
      "Train Epoch: 140 [10000/25000 (40%)]\tLosses default: 0.000121 bn: 0.000113 drop: 0.000047 both: 0.000140\n",
      "Train Epoch: 140 [20000/25000 (80%)]\tLosses default: 0.027368 bn: 0.000262 drop: 0.000015 both: 0.000643\n",
      "Train Epoch: 140 [25000/25000 (100%)]\tLosses default: 0.000730 bn: 0.000020 drop: 0.000023 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.0478\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9704\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 0.9808\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0191\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 141 [0/25000 (0%)]\tLosses default: 0.000329 bn: 0.001224 drop: 0.000010 both: 0.000175\n",
      "Train Epoch: 141 [10000/25000 (40%)]\tLosses default: 0.000031 bn: 0.000064 drop: 0.000022 both: 0.000030\n",
      "Train Epoch: 141 [20000/25000 (80%)]\tLosses default: 0.000029 bn: 0.000049 drop: 0.000030 both: 0.000002\n",
      "Train Epoch: 141 [25000/25000 (100%)]\tLosses default: 0.000032 bn: 0.000048 drop: 0.000011 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.0585\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 0.9577\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 0.9787\tAccuracy: 4420.0/5000 (88%)\n",
      "both: Loss: 0.9863\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 142 [0/25000 (0%)]\tLosses default: 0.000685 bn: 0.000056 drop: 0.000026 both: 0.000371\n",
      "Train Epoch: 142 [10000/25000 (40%)]\tLosses default: 0.000021 bn: 0.000005 drop: 0.000018 both: 0.000033\n",
      "Train Epoch: 142 [20000/25000 (80%)]\tLosses default: 0.000056 bn: 0.000041 drop: 0.000027 both: 0.000010\n",
      "Train Epoch: 142 [25000/25000 (100%)]\tLosses default: 0.000034 bn: 0.000400 drop: 0.000047 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.0720\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0192\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 0.9854\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0252\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 143 [0/25000 (0%)]\tLosses default: 0.000020 bn: 0.000030 drop: 0.000028 both: 0.000074\n",
      "Train Epoch: 143 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000123 drop: 0.000037 both: 0.000011\n",
      "Train Epoch: 143 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.081611 drop: 0.000033 both: 0.000041\n",
      "Train Epoch: 143 [25000/25000 (100%)]\tLosses default: 0.000052 bn: 0.000232 drop: 0.000012 both: 0.000262\n",
      "Test set:\n",
      "default: Loss: 1.0832\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 0.9548\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 0.9874\tAccuracy: 4416.0/5000 (88%)\n",
      "both: Loss: 0.9822\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 144 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.061229 drop: 0.000016 both: 0.000823\n",
      "Train Epoch: 144 [10000/25000 (40%)]\tLosses default: 0.000110 bn: 0.000070 drop: 0.000019 both: 0.000050\n",
      "Train Epoch: 144 [20000/25000 (80%)]\tLosses default: 0.000035 bn: 0.000011 drop: 0.000017 both: 0.000214\n",
      "Train Epoch: 144 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.013762 drop: 0.000013 both: 0.000034\n",
      "Test set:\n",
      "default: Loss: 1.0940\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9970\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 0.9995\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 0.9823\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 145 [0/25000 (0%)]\tLosses default: 0.000023 bn: 0.000085 drop: 0.000015 both: 0.000099\n",
      "Train Epoch: 145 [10000/25000 (40%)]\tLosses default: 0.000022 bn: 0.000206 drop: 0.115398 both: 0.000134\n",
      "Train Epoch: 145 [20000/25000 (80%)]\tLosses default: 0.000040 bn: 0.000024 drop: 0.000392 both: 0.000156\n",
      "Train Epoch: 145 [25000/25000 (100%)]\tLosses default: 0.000071 bn: 0.000027 drop: 0.000510 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1055\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 0.9794\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 0.9842\tAccuracy: 4348.0/5000 (87%)\n",
      "both: Loss: 0.9837\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 146 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000028 drop: 0.000446 both: 0.000103\n",
      "Train Epoch: 146 [10000/25000 (40%)]\tLosses default: 0.000030 bn: 0.000217 drop: 0.000247 both: 0.002936\n",
      "Train Epoch: 146 [20000/25000 (80%)]\tLosses default: 0.000022 bn: 0.000618 drop: 0.000801 both: 0.005844\n",
      "Train Epoch: 146 [25000/25000 (100%)]\tLosses default: 0.000015 bn: 0.000023 drop: 0.000037 both: 0.000039\n",
      "Test set:\n",
      "default: Loss: 1.1155\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0325\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 0.9630\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0044\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 147 [0/25000 (0%)]\tLosses default: 0.000085 bn: 0.114666 drop: 0.000131 both: 0.000030\n",
      "Train Epoch: 147 [10000/25000 (40%)]\tLosses default: 0.000026 bn: 0.000494 drop: 0.000063 both: 0.000042\n",
      "Train Epoch: 147 [20000/25000 (80%)]\tLosses default: 0.000018 bn: 0.000198 drop: 0.000179 both: 0.000257\n",
      "Train Epoch: 147 [25000/25000 (100%)]\tLosses default: 0.000025 bn: 0.000086 drop: 0.000342 both: 0.004128\n",
      "Test set:\n",
      "default: Loss: 1.1268\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9713\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0277\tAccuracy: 4357.0/5000 (87%)\n",
      "both: Loss: 1.0394\tAccuracy: 4358.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 148 [0/25000 (0%)]\tLosses default: 0.000012 bn: 0.001114 drop: 0.008186 both: 0.024084\n",
      "Train Epoch: 148 [10000/25000 (40%)]\tLosses default: 0.000042 bn: 0.000595 drop: 0.030512 both: 0.000023\n",
      "Train Epoch: 148 [20000/25000 (80%)]\tLosses default: 0.000016 bn: 0.000025 drop: 0.000116 both: 0.000072\n",
      "Train Epoch: 148 [25000/25000 (100%)]\tLosses default: 0.000018 bn: 0.027850 drop: 0.000661 both: 0.013286\n",
      "Test set:\n",
      "default: Loss: 1.1372\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 0.9846\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 0.9627\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0003\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 149 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000020 drop: 0.000008 both: 0.000012\n",
      "Train Epoch: 149 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000041 drop: 0.000397 both: 0.000019\n",
      "Train Epoch: 149 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000029 drop: 0.000057 both: 0.000733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 149 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.001293 drop: 0.000124 both: 0.000261\n",
      "Test set:\n",
      "default: Loss: 1.1470\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0068\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 0.9652\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0139\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 150 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000057 drop: 0.000034 both: 0.000019\n",
      "Train Epoch: 150 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000168 drop: 0.000510 both: 0.017132\n",
      "Train Epoch: 150 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000306 drop: 0.000074 both: 0.000016\n",
      "Train Epoch: 150 [25000/25000 (100%)]\tLosses default: 0.000045 bn: 0.000021 drop: 0.000020 both: 0.002842\n",
      "Test set:\n",
      "default: Loss: 1.1572\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0075\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 0.9739\tAccuracy: 4409.0/5000 (88%)\n",
      "both: Loss: 1.0166\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 151 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.002135 drop: 0.000008 both: 0.000155\n",
      "Train Epoch: 151 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000284 drop: 0.000029 both: 0.000050\n",
      "Train Epoch: 151 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000241 drop: 0.000046 both: 0.000035\n",
      "Train Epoch: 151 [25000/25000 (100%)]\tLosses default: 0.000014 bn: 0.000036 drop: 0.000030 both: 0.000119\n",
      "Test set:\n",
      "default: Loss: 1.1678\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9676\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 0.9819\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 0.9935\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 152 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.005140 drop: 0.000053 both: 0.000026\n",
      "Train Epoch: 152 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000076 drop: 0.000010 both: 0.000067\n",
      "Train Epoch: 152 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000112 drop: 0.000002 both: 0.000018\n",
      "Train Epoch: 152 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000029 drop: 0.000033 both: 0.000033\n",
      "Test set:\n",
      "default: Loss: 1.1766\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 0.9671\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 0.9932\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 0.9790\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 153 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000019 both: 0.000770\n",
      "Train Epoch: 153 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.002218 drop: 0.000053 both: 0.001042\n",
      "Train Epoch: 153 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000017 drop: 0.000009 both: 0.023026\n",
      "Train Epoch: 153 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000037 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.1863\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 0.9694\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 0.9960\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 0.9694\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 154 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000090 drop: 0.000008 both: 0.000030\n",
      "Train Epoch: 154 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.004194 drop: 0.000016 both: 0.000028\n",
      "Train Epoch: 154 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000120 drop: 0.000008 both: 0.000020\n",
      "Train Epoch: 154 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.005853 drop: 0.000013 both: 0.000033\n",
      "Test set:\n",
      "default: Loss: 1.1955\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0112\tAccuracy: 4390.0/5000 (88%)\n",
      "drop: Loss: 1.0009\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 0.9863\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 155 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000503 drop: 0.000018 both: 0.000594\n",
      "Train Epoch: 155 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000169 drop: 0.000051 both: 0.001665\n",
      "Train Epoch: 155 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000022 drop: 0.001864 both: 0.000006\n",
      "Train Epoch: 155 [25000/25000 (100%)]\tLosses default: 0.000013 bn: 0.000488 drop: 0.017020 both: 0.000120\n",
      "Test set:\n",
      "default: Loss: 1.2037\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0096\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.0495\tAccuracy: 4346.0/5000 (87%)\n",
      "both: Loss: 0.9814\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 156 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000017 drop: 0.004192 both: 0.000204\n",
      "Train Epoch: 156 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.007609 drop: 0.001930 both: 0.000024\n",
      "Train Epoch: 156 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001192 drop: 0.000068 both: 0.000079\n",
      "Train Epoch: 156 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.001322 drop: 0.000083 both: 0.059475\n",
      "Test set:\n",
      "default: Loss: 1.2132\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 0.9969\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 0.9818\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0231\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 157 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000095 drop: 0.005261 both: 0.000432\n",
      "Train Epoch: 157 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000039 drop: 0.000024 both: 0.000210\n",
      "Train Epoch: 157 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000037 drop: 0.000029 both: 0.000010\n",
      "Train Epoch: 157 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000012 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.2209\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 0.9665\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 0.9832\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 0.9808\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 158 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000316 drop: 0.000012 both: 0.000029\n",
      "Train Epoch: 158 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000041 drop: 0.000242 both: 0.000053\n",
      "Train Epoch: 158 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000636 drop: 0.000570 both: 0.000365\n",
      "Train Epoch: 158 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.008532 drop: 0.000453 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.2283\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0338\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 0.9897\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 0.9903\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 159 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001642 drop: 0.000038 both: 0.000115\n",
      "Train Epoch: 159 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000199 drop: 0.000027 both: 0.000013\n",
      "Train Epoch: 159 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000103 drop: 0.000084 both: 0.000075\n",
      "Train Epoch: 159 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000194 drop: 0.000041 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.2348\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 0.9916\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 0.9812\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 0.9598\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 160 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000490 drop: 0.000023 both: 0.000027\n",
      "Train Epoch: 160 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000019 drop: 0.000048 both: 0.000521\n",
      "Train Epoch: 160 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000164 drop: 0.000047 both: 0.000187\n",
      "Train Epoch: 160 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000709 drop: 0.000004 both: 0.090254\n",
      "Test set:\n",
      "default: Loss: 1.2430\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 0.9923\tAccuracy: 4393.0/5000 (88%)\n",
      "drop: Loss: 0.9922\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 0.9807\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 161 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.001035 drop: 0.000032 both: 0.023737\n",
      "Train Epoch: 161 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000376 drop: 0.000071 both: 0.000272\n",
      "Train Epoch: 161 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000062 drop: 0.000017 both: 0.000117\n",
      "Train Epoch: 161 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000095 drop: 0.000052 both: 0.000112\n",
      "Test set:\n",
      "default: Loss: 1.2506\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0219\tAccuracy: 4396.0/5000 (88%)\n",
      "drop: Loss: 0.9946\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 0.9584\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 162 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000011 both: 0.000015\n",
      "Train Epoch: 162 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001760 drop: 0.000009 both: 0.001289\n",
      "Train Epoch: 162 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000118 drop: 0.000065 both: 0.030953\n",
      "Train Epoch: 162 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001273 drop: 0.000003 both: 0.000101\n",
      "Test set:\n",
      "default: Loss: 1.2560\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 0.9819\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0106\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 0.9787\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 163 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000021 drop: 0.000011 both: 0.000183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 163 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000078 drop: 0.133500 both: 0.000396\n",
      "Train Epoch: 163 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.014450 both: 0.000016\n",
      "Train Epoch: 163 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.060111 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.2623\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 0.9999\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.0526\tAccuracy: 4320.0/5000 (86%)\n",
      "both: Loss: 0.9925\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 164 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000594 both: 0.003350\n",
      "Train Epoch: 164 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.001827 drop: 0.003854 both: 0.000217\n",
      "Train Epoch: 164 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000120 drop: 0.000277 both: 0.000089\n",
      "Train Epoch: 164 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000062 drop: 0.000763 both: 0.001017\n",
      "Test set:\n",
      "default: Loss: 1.2667\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0267\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 0.9627\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 0.9924\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 165 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000047 drop: 0.000086 both: 0.000062\n",
      "Train Epoch: 165 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000965 drop: 0.000241 both: 0.002160\n",
      "Train Epoch: 165 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000036 both: 0.000011\n",
      "Train Epoch: 165 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000058 drop: 0.000239 both: 0.014922\n",
      "Test set:\n",
      "default: Loss: 1.2749\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 0.9844\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 0.9464\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 0.9856\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 166 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000169 drop: 0.000102 both: 0.000257\n",
      "Train Epoch: 166 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000054 both: 0.000083\n",
      "Train Epoch: 166 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000040 both: 0.000009\n",
      "Train Epoch: 166 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000068 drop: 0.000030 both: 0.000217\n",
      "Test set:\n",
      "default: Loss: 1.2807\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 0.9813\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 0.9822\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 0.9738\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 167 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000223 both: 0.000601\n",
      "Train Epoch: 167 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000009 drop: 0.000046 both: 0.280028\n",
      "Train Epoch: 167 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000072 drop: 0.000009 both: 0.002813\n",
      "Train Epoch: 167 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000077 drop: 0.000123 both: 0.000084\n",
      "Test set:\n",
      "default: Loss: 1.2829\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0174\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 0.9815\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 0.9432\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 168 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000138 drop: 0.000713 both: 0.011250\n",
      "Train Epoch: 168 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000036 drop: 0.000090 both: 0.000025\n",
      "Train Epoch: 168 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001403 drop: 0.000022 both: 0.000014\n",
      "Train Epoch: 168 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000018 both: 0.000125\n",
      "Test set:\n",
      "default: Loss: 1.2930\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 0.9757\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 0.9833\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 0.9845\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 169 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000413 drop: 0.000034 both: 0.000011\n",
      "Train Epoch: 169 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.017520 drop: 0.000468 both: 0.011031\n",
      "Train Epoch: 169 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000099 drop: 0.010441 both: 0.000047\n",
      "Train Epoch: 169 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000147 drop: 0.000843 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.2954\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0673\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 1.0241\tAccuracy: 4332.0/5000 (87%)\n",
      "both: Loss: 0.9813\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 170 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000101 drop: 0.156011 both: 0.000011\n",
      "Train Epoch: 170 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000457 drop: 0.001440 both: 0.000318\n",
      "Train Epoch: 170 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.010064 drop: 0.000506 both: 0.005779\n",
      "Train Epoch: 170 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000060 both: 0.000161\n",
      "Test set:\n",
      "default: Loss: 1.3013\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0078\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 0.9446\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 1.0010\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 171 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000130 both: 0.000010\n",
      "Train Epoch: 171 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000203 both: 0.000078\n",
      "Train Epoch: 171 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000074 drop: 0.000020 both: 0.000011\n",
      "Train Epoch: 171 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000026 both: 0.010882\n",
      "Test set:\n",
      "default: Loss: 1.3056\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0039\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 0.9474\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 0.9611\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 172 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000070 drop: 0.000044 both: 0.000057\n",
      "Train Epoch: 172 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000768 both: 0.000277\n",
      "Train Epoch: 172 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000088 drop: 0.000053 both: 0.000230\n",
      "Train Epoch: 172 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.003609 drop: 0.000279 both: 0.000060\n",
      "Test set:\n",
      "default: Loss: 1.3126\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0458\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 0.9665\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0087\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 173 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000120 drop: 0.000134 both: 0.006192\n",
      "Train Epoch: 173 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.002689 drop: 0.000473 both: 0.000046\n",
      "Train Epoch: 173 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000029 both: 0.001873\n",
      "Train Epoch: 173 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000036 drop: 0.000032 both: 0.000809\n",
      "Test set:\n",
      "default: Loss: 1.3215\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0512\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 0.9565\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 0.9615\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 174 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000030 both: 0.000351\n",
      "Train Epoch: 174 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000061 drop: 0.000023 both: 0.000086\n",
      "Train Epoch: 174 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000050 drop: 0.000040 both: 0.000265\n",
      "Train Epoch: 174 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000036 drop: 0.000021 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.3246\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0040\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 0.9496\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 0.9732\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 175 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000302 drop: 0.000199 both: 0.000368\n",
      "Train Epoch: 175 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000020 both: 0.000016\n",
      "Train Epoch: 175 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000005 both: 0.000032\n",
      "Train Epoch: 175 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000035 both: 0.000162\n",
      "Test set:\n",
      "default: Loss: 1.3316\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 0.9869\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 0.9662\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 0.9860\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 176 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000036 drop: 0.000043 both: 0.001224\n",
      "Train Epoch: 176 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000091 drop: 0.000107 both: 0.004235\n",
      "Train Epoch: 176 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000878 drop: 0.000013 both: 0.000395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 176 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000046 both: 0.000052\n",
      "Test set:\n",
      "default: Loss: 1.3381\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 0.9707\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 0.9474\tAccuracy: 4409.0/5000 (88%)\n",
      "both: Loss: 0.9898\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 177 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000063 both: 0.000637\n",
      "Train Epoch: 177 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001619 drop: 0.000033 both: 0.000043\n",
      "Train Epoch: 177 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000085 drop: 0.000149 both: 0.000007\n",
      "Train Epoch: 177 [25000/25000 (100%)]\tLosses default: 0.425745 bn: 0.000044 drop: 0.000063 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.3887\tAccuracy: 4332.0/5000 (87%)\n",
      "bn: Loss: 1.0140\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 0.9733\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 0.9843\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 178 [0/25000 (0%)]\tLosses default: 0.176004 bn: 0.000077 drop: 0.000032 both: 0.000059\n",
      "Train Epoch: 178 [10000/25000 (40%)]\tLosses default: 0.001648 bn: 0.000095 drop: 0.000006 both: 0.000010\n",
      "Train Epoch: 178 [20000/25000 (80%)]\tLosses default: 0.015735 bn: 0.000015 drop: 0.000007 both: 0.000260\n",
      "Train Epoch: 178 [25000/25000 (100%)]\tLosses default: 0.017997 bn: 0.000864 drop: 0.000014 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.0887\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 0.9950\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 0.9802\tAccuracy: 4409.0/5000 (88%)\n",
      "both: Loss: 1.0179\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 179 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000011 drop: 0.000004 both: 0.000233\n",
      "Train Epoch: 179 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000038 drop: 0.000021 both: 0.000052\n",
      "Train Epoch: 179 [20000/25000 (80%)]\tLosses default: 0.000020 bn: 0.000247 drop: 0.045885 both: 0.000138\n",
      "Train Epoch: 179 [25000/25000 (100%)]\tLosses default: 0.000499 bn: 0.001192 drop: 0.125337 both: 0.006016\n",
      "Test set:\n",
      "default: Loss: 1.0923\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0141\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 0.9637\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 0.9882\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 180 [0/25000 (0%)]\tLosses default: 0.000146 bn: 0.001574 drop: 0.018411 both: 0.000831\n",
      "Train Epoch: 180 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.012625 drop: 0.000266 both: 0.000046\n",
      "Train Epoch: 180 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.057902 drop: 0.000237 both: 0.000174\n",
      "Train Epoch: 180 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000023 drop: 0.000089 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.0892\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0392\tAccuracy: 4401.0/5000 (88%)\n",
      "drop: Loss: 0.9605\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 0.9683\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 181 [0/25000 (0%)]\tLosses default: 0.000085 bn: 0.000034 drop: 0.000173 both: 0.000078\n",
      "Train Epoch: 181 [10000/25000 (40%)]\tLosses default: 0.000028 bn: 0.000679 drop: 0.000137 both: 0.000141\n",
      "Train Epoch: 181 [20000/25000 (80%)]\tLosses default: 0.000486 bn: 0.000967 drop: 0.000074 both: 0.000090\n",
      "Train Epoch: 181 [25000/25000 (100%)]\tLosses default: 0.000042 bn: 0.000032 drop: 0.000145 both: 0.000405\n",
      "Test set:\n",
      "default: Loss: 1.0977\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0367\tAccuracy: 4397.0/5000 (88%)\n",
      "drop: Loss: 0.9665\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 0.9915\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 182 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000011 drop: 0.000038 both: 0.000042\n",
      "Train Epoch: 182 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000035 drop: 0.000015 both: 0.000013\n",
      "Train Epoch: 182 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000014 drop: 0.000090 both: 0.002030\n",
      "Train Epoch: 182 [25000/25000 (100%)]\tLosses default: 0.000045 bn: 0.000059 drop: 0.000839 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.1050\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0134\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 0.9573\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 0.9914\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 183 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.000033 drop: 0.000273 both: 0.000157\n",
      "Train Epoch: 183 [10000/25000 (40%)]\tLosses default: 0.000052 bn: 0.011067 drop: 0.000250 both: 0.000347\n",
      "Train Epoch: 183 [20000/25000 (80%)]\tLosses default: 0.000014 bn: 0.000007 drop: 0.000027 both: 0.000045\n",
      "Train Epoch: 183 [25000/25000 (100%)]\tLosses default: 0.000022 bn: 0.000145 drop: 0.000100 both: 0.000241\n",
      "Test set:\n",
      "default: Loss: 1.1094\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 0.9909\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 0.9637\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 0.9679\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 184 [0/25000 (0%)]\tLosses default: 0.000012 bn: 0.000006 drop: 0.000027 both: 0.020469\n",
      "Train Epoch: 184 [10000/25000 (40%)]\tLosses default: 0.000018 bn: 0.003350 drop: 0.000099 both: 0.000144\n",
      "Train Epoch: 184 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.005014 drop: 0.000045 both: 0.016128\n",
      "Train Epoch: 184 [25000/25000 (100%)]\tLosses default: 0.000068 bn: 0.000054 drop: 0.000351 both: 0.000055\n",
      "Test set:\n",
      "default: Loss: 1.1175\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0138\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 0.9616\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0046\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 185 [0/25000 (0%)]\tLosses default: 0.000015 bn: 0.000778 drop: 0.000050 both: 0.000274\n",
      "Train Epoch: 185 [10000/25000 (40%)]\tLosses default: 0.000028 bn: 0.000045 drop: 0.000069 both: 0.001643\n",
      "Train Epoch: 185 [20000/25000 (80%)]\tLosses default: 0.000012 bn: 0.000198 drop: 0.000179 both: 0.000012\n",
      "Train Epoch: 185 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000339 drop: 0.000020 both: 0.001274\n",
      "Test set:\n",
      "default: Loss: 1.1246\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0171\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 0.9670\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 0.9933\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 186 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000115 drop: 0.000122 both: 0.000014\n",
      "Train Epoch: 186 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000008 drop: 0.000050 both: 0.000029\n",
      "Train Epoch: 186 [20000/25000 (80%)]\tLosses default: 0.000017 bn: 0.000021 drop: 0.000019 both: 0.000154\n",
      "Train Epoch: 186 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000410 drop: 0.000060 both: 0.001227\n",
      "Test set:\n",
      "default: Loss: 1.1328\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0099\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 0.9674\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0056\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 187 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000026 drop: 0.000540 both: 0.001326\n",
      "Train Epoch: 187 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000067 both: 0.000043\n",
      "Train Epoch: 187 [20000/25000 (80%)]\tLosses default: 0.000026 bn: 0.000412 drop: 0.000027 both: 0.002909\n",
      "Train Epoch: 187 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.039697 drop: 0.000048 both: 0.000482\n",
      "Test set:\n",
      "default: Loss: 1.1413\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 0.9728\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 0.9812\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 0.9631\tAccuracy: 4420.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 188 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000031 drop: 0.000012 both: 0.004011\n",
      "Train Epoch: 188 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000057 drop: 0.000071 both: 0.000037\n",
      "Train Epoch: 188 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.002774 drop: 0.000033 both: 0.000017\n",
      "Train Epoch: 188 [25000/25000 (100%)]\tLosses default: 0.000019 bn: 0.000046 drop: 0.000531 both: 0.000036\n",
      "Test set:\n",
      "default: Loss: 1.1489\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0086\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.0077\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 0.9595\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 189 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.001366 drop: 0.000086 both: 0.000024\n",
      "Train Epoch: 189 [10000/25000 (40%)]\tLosses default: 0.000011 bn: 0.000029 drop: 0.000015 both: 0.000195\n",
      "Train Epoch: 189 [20000/25000 (80%)]\tLosses default: 0.000009 bn: 0.000449 drop: 0.000050 both: 0.000027\n",
      "Train Epoch: 189 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000138 drop: 0.000012 both: 0.005715\n",
      "Test set:\n",
      "default: Loss: 1.1567\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 0.9906\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0089\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 0.9744\tAccuracy: 4368.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 190 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000062 drop: 0.000012 both: 0.000034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 190 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000771 drop: 0.000012 both: 0.000009\n",
      "Train Epoch: 190 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000415 drop: 0.000040 both: 0.002630\n",
      "Train Epoch: 190 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000036 both: 0.000289\n",
      "Test set:\n",
      "default: Loss: 1.1642\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 0.9838\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.0174\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0016\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 191 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.001298 drop: 0.000016 both: 0.000152\n",
      "Train Epoch: 191 [10000/25000 (40%)]\tLosses default: 0.000013 bn: 0.000013 drop: 0.000028 both: 0.014373\n",
      "Train Epoch: 191 [20000/25000 (80%)]\tLosses default: 0.000015 bn: 0.000037 drop: 0.000010 both: 0.001955\n",
      "Train Epoch: 191 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000548 drop: 0.000005 both: 0.027269\n",
      "Test set:\n",
      "default: Loss: 1.1736\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 0.9933\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.0238\tAccuracy: 4412.0/5000 (88%)\n",
      "both: Loss: 0.9892\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 192 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000035 drop: 0.000025 both: 0.001734\n",
      "Train Epoch: 192 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000041 drop: 0.000020 both: 0.002874\n",
      "Train Epoch: 192 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.000088 both: 0.000013\n",
      "Train Epoch: 192 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000014 drop: 0.000005 both: 0.000082\n",
      "Test set:\n",
      "default: Loss: 1.1806\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 0.9738\tAccuracy: 4444.0/5000 (89%)\n",
      "drop: Loss: 1.0400\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 0.9961\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 193 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000015 drop: 0.000003 both: 0.000016\n",
      "Train Epoch: 193 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000672 drop: 0.000012 both: 0.000264\n",
      "Train Epoch: 193 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000149 drop: 0.000008 both: 0.000553\n",
      "Train Epoch: 193 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.002160 drop: 0.000041 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.1887\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 0.9733\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 1.0437\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 0.9611\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 194 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000364 drop: 0.000012 both: 0.001632\n",
      "Train Epoch: 194 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000180 drop: 0.000008 both: 0.000047\n",
      "Train Epoch: 194 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.019540 drop: 0.003416 both: 0.000055\n",
      "Train Epoch: 194 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000473 both: 0.000033\n",
      "Test set:\n",
      "default: Loss: 1.1975\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 0.9712\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 0.9392\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 0.9674\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 195 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000267 drop: 0.000526 both: 0.002438\n",
      "Train Epoch: 195 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.001064 drop: 0.000619 both: 0.000560\n",
      "Train Epoch: 195 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.013311 drop: 0.000736 both: 0.001600\n",
      "Train Epoch: 195 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001106 drop: 0.000377 both: 0.000053\n",
      "Test set:\n",
      "default: Loss: 1.2049\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0318\tAccuracy: 4395.0/5000 (88%)\n",
      "drop: Loss: 0.9899\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 0.9649\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 196 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000004 drop: 0.000760 both: 0.000034\n",
      "Train Epoch: 196 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000024 both: 0.000014\n",
      "Train Epoch: 196 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000227 drop: 0.000041 both: 0.000096\n",
      "Train Epoch: 196 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.001264 drop: 0.000133 both: 0.000084\n",
      "Test set:\n",
      "default: Loss: 1.2128\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 0.9633\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 0.9853\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 0.9789\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 197 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000096 drop: 0.000992 both: 0.000017\n",
      "Train Epoch: 197 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000014 drop: 0.000559 both: 0.000174\n",
      "Train Epoch: 197 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001228 drop: 0.001307 both: 0.000041\n",
      "Train Epoch: 197 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000056 drop: 0.000301 both: 0.001734\n",
      "Test set:\n",
      "default: Loss: 1.2205\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 0.9851\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0119\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0264\tAccuracy: 4352.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 198 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000020 drop: 0.000054 both: 0.000850\n",
      "Train Epoch: 198 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000020 drop: 0.000074 both: 0.000008\n",
      "Train Epoch: 198 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000063 both: 0.000405\n",
      "Train Epoch: 198 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000043 drop: 0.000011 both: 0.000630\n",
      "Test set:\n",
      "default: Loss: 1.2272\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 0.9974\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 0.9850\tAccuracy: 4407.0/5000 (88%)\n",
      "both: Loss: 0.9706\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 199 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.111537 drop: 0.000025 both: 0.000196\n",
      "Train Epoch: 199 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000014 drop: 0.000012 both: 0.000062\n",
      "Train Epoch: 199 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000072 drop: 0.114322 both: 0.000079\n",
      "Train Epoch: 199 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000069 drop: 0.002452 both: 0.003294\n",
      "Test set:\n",
      "default: Loss: 1.2335\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 0.9916\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 0.9802\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 0.9705\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 200 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000027 drop: 0.000320 both: 0.000286\n",
      "Train Epoch: 200 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000091 drop: 0.000038 both: 0.000016\n",
      "Train Epoch: 200 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000210 drop: 0.000099 both: 0.006952\n",
      "Train Epoch: 200 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000842 drop: 0.051584 both: 0.030071\n",
      "Test set:\n",
      "default: Loss: 1.2403\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 0.9720\tAccuracy: 4446.0/5000 (89%)\n",
      "drop: Loss: 1.0503\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 0.9740\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 201 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000028 drop: 0.017066 both: 0.000052\n",
      "Train Epoch: 201 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000023 drop: 0.000390 both: 0.037461\n",
      "Train Epoch: 201 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000196 drop: 0.009963 both: 0.000053\n",
      "Train Epoch: 201 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000260 drop: 0.000064 both: 0.003040\n",
      "Test set:\n",
      "default: Loss: 1.2462\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0071\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 0.9954\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 0.9875\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 202 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.009647 both: 0.002388\n",
      "Train Epoch: 202 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000060 drop: 0.000101 both: 0.000032\n",
      "Train Epoch: 202 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000036 drop: 0.000387 both: 0.000069\n",
      "Train Epoch: 202 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000010 both: 0.000194\n",
      "Test set:\n",
      "default: Loss: 1.2527\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 0.9956\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.0040\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 0.9656\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 203 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.003570 drop: 0.000101 both: 0.000280\n",
      "Train Epoch: 203 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000073 drop: 0.000080 both: 0.000184\n",
      "Train Epoch: 203 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.047682 drop: 0.001197 both: 0.000023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 203 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000271 drop: 0.000301 both: 0.001052\n",
      "Test set:\n",
      "default: Loss: 1.2616\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0087\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.0039\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0018\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 204 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000100 drop: 0.000014 both: 0.000041\n",
      "Train Epoch: 204 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.190691 drop: 0.000724 both: 0.000018\n",
      "Train Epoch: 204 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000179 drop: 0.000059 both: 0.000017\n",
      "Train Epoch: 204 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000019 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 1.2648\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 0.9816\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 0.9952\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 0.9881\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 205 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000047 drop: 0.000127 both: 0.000081\n",
      "Train Epoch: 205 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000064 both: 0.000020\n",
      "Train Epoch: 205 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000039 both: 0.000017\n",
      "Train Epoch: 205 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000612 drop: 0.000003 both: 0.000073\n",
      "Test set:\n",
      "default: Loss: 1.2690\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 0.9960\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0129\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0135\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 206 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000013 both: 0.000061\n",
      "Train Epoch: 206 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000836 drop: 0.000033 both: 0.000015\n",
      "Train Epoch: 206 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000004 both: 0.000012\n",
      "Train Epoch: 206 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000023 both: 0.001145\n",
      "Test set:\n",
      "default: Loss: 1.2763\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0387\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.0208\tAccuracy: 4407.0/5000 (88%)\n",
      "both: Loss: 1.0077\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 207 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000007 both: 0.000034\n",
      "Train Epoch: 207 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.007826 drop: 0.000145 both: 0.000168\n",
      "Train Epoch: 207 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.003190 drop: 0.000036 both: 0.004725\n",
      "Train Epoch: 207 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000093 both: 0.000762\n",
      "Test set:\n",
      "default: Loss: 1.2824\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0263\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0228\tAccuracy: 4409.0/5000 (88%)\n",
      "both: Loss: 1.0139\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 208 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.005152 drop: 0.000039 both: 0.000051\n",
      "Train Epoch: 208 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000042 both: 0.000001\n",
      "Train Epoch: 208 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.004407 drop: 0.000004 both: 0.001187\n",
      "Train Epoch: 208 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000092 drop: 0.000031 both: 0.000364\n",
      "Test set:\n",
      "default: Loss: 1.2866\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 0.9939\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.0311\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0364\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 209 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000065 drop: 0.000023 both: 0.000345\n",
      "Train Epoch: 209 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000092 drop: 0.000012 both: 0.078966\n",
      "Train Epoch: 209 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000195 drop: 0.000008 both: 0.000041\n",
      "Train Epoch: 209 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.002988 drop: 0.000104 both: 0.000467\n",
      "Test set:\n",
      "default: Loss: 1.2954\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0420\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0244\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 0.9900\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 210 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000021 both: 0.000029\n",
      "Train Epoch: 210 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000029 both: 0.003131\n",
      "Train Epoch: 210 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000453 drop: 0.000004 both: 0.001261\n",
      "Train Epoch: 210 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.020555 drop: 0.000030 both: 0.000045\n",
      "Test set:\n",
      "default: Loss: 1.2990\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0527\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0237\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0155\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 211 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000333 drop: 0.000006 both: 0.000028\n",
      "Train Epoch: 211 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000099 drop: 0.000013 both: 0.000015\n",
      "Train Epoch: 211 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000168 both: 0.010120\n",
      "Train Epoch: 211 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000073 drop: 0.085653 both: 0.000035\n",
      "Test set:\n",
      "default: Loss: 1.3064\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0265\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0942\tAccuracy: 4338.0/5000 (87%)\n",
      "both: Loss: 0.9990\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 212 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000664 drop: 0.273493 both: 0.000015\n",
      "Train Epoch: 212 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000636 both: 0.001877\n",
      "Train Epoch: 212 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000047 drop: 0.003002 both: 0.000547\n",
      "Train Epoch: 212 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000067 both: 0.000088\n",
      "Test set:\n",
      "default: Loss: 1.3097\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0179\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0068\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 0.9796\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 213 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000122 both: 0.000143\n",
      "Train Epoch: 213 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.002706 drop: 0.000174 both: 0.000084\n",
      "Train Epoch: 213 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.092208 drop: 0.000113 both: 0.000253\n",
      "Train Epoch: 213 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000420 drop: 0.000199 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.3125\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0120\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0056\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 0.9612\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 214 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001446 drop: 0.000023 both: 0.000074\n",
      "Train Epoch: 214 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000891 drop: 0.000557 both: 0.000193\n",
      "Train Epoch: 214 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000046 drop: 0.000012 both: 0.000120\n",
      "Train Epoch: 214 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000293 drop: 0.000141 both: 0.000565\n",
      "Test set:\n",
      "default: Loss: 1.3171\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0475\tAccuracy: 4385.0/5000 (88%)\n",
      "drop: Loss: 0.9893\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 0.9725\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 215 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000320 drop: 0.000295 both: 0.000091\n",
      "Train Epoch: 215 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000507 drop: 0.000007 both: 0.000016\n",
      "Train Epoch: 215 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000046 drop: 0.000024 both: 0.000003\n",
      "Train Epoch: 215 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000022 both: 0.000360\n",
      "Test set:\n",
      "default: Loss: 1.3238\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 0.9999\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0153\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 0.9833\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 216 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000018 both: 0.000198\n",
      "Train Epoch: 216 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000242 both: 0.003596\n",
      "Train Epoch: 216 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001426 drop: 0.000035 both: 0.000022\n",
      "Train Epoch: 216 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000112 drop: 0.000016 both: 0.014320\n",
      "Test set:\n",
      "default: Loss: 1.3288\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0164\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 0.9915\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 0.9711\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 217 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000289 both: 0.000079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 217 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000112 drop: 0.000119 both: 0.000011\n",
      "Train Epoch: 217 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000522 drop: 0.000050 both: 0.000178\n",
      "Train Epoch: 217 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000021 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.3289\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0457\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 0.9995\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 0.9633\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 218 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.030832 drop: 0.000027 both: 0.000216\n",
      "Train Epoch: 218 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000050 drop: 0.000033 both: 0.000558\n",
      "Train Epoch: 218 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000187 drop: 0.000192 both: 0.001660\n",
      "Train Epoch: 218 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.002881 drop: 0.000068 both: 0.000259\n",
      "Test set:\n",
      "default: Loss: 1.3322\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.0149\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0216\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 0.9610\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 219 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000009 both: 0.000170\n",
      "Train Epoch: 219 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000015 both: 0.000446\n",
      "Train Epoch: 219 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.001066 both: 0.000029\n",
      "Train Epoch: 219 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.037260 drop: 0.000010 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.3370\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0134\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0320\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 0.9790\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 220 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000114 drop: 0.001842 both: 0.000023\n",
      "Train Epoch: 220 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001907 drop: 0.000035 both: 0.000026\n",
      "Train Epoch: 220 [20000/25000 (80%)]\tLosses default: 0.533708 bn: 0.000061 drop: 0.000049 both: 0.037549\n",
      "Train Epoch: 220 [25000/25000 (100%)]\tLosses default: 0.002134 bn: 0.000041 drop: 0.000003 both: 0.000047\n",
      "Test set:\n",
      "default: Loss: 1.1477\tAccuracy: 4373.0/5000 (87%)\n",
      "bn: Loss: 0.9985\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.0261\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 0.9590\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 221 [0/25000 (0%)]\tLosses default: 0.007193 bn: 0.000411 drop: 0.000035 both: 0.000409\n",
      "Train Epoch: 221 [10000/25000 (40%)]\tLosses default: 0.000860 bn: 0.000547 drop: 0.000029 both: 0.000013\n",
      "Train Epoch: 221 [20000/25000 (80%)]\tLosses default: 0.000026 bn: 0.000214 drop: 0.000009 both: 0.000088\n",
      "Train Epoch: 221 [25000/25000 (100%)]\tLosses default: 0.000014 bn: 0.000547 drop: 0.000021 both: 0.015430\n",
      "Test set:\n",
      "default: Loss: 1.0784\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0085\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.0335\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0080\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 222 [0/25000 (0%)]\tLosses default: 0.000283 bn: 0.000031 drop: 0.000009 both: 0.000068\n",
      "Train Epoch: 222 [10000/25000 (40%)]\tLosses default: 0.000038 bn: 0.000004 drop: 0.000015 both: 0.069328\n",
      "Train Epoch: 222 [20000/25000 (80%)]\tLosses default: 0.000025 bn: 0.000077 drop: 0.000010 both: 0.000140\n",
      "Train Epoch: 222 [25000/25000 (100%)]\tLosses default: 0.000353 bn: 0.000060 drop: 0.000008 both: 0.000132\n",
      "Test set:\n",
      "default: Loss: 1.1173\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0231\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0372\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 0.9837\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 223 [0/25000 (0%)]\tLosses default: 0.000175 bn: 0.000172 drop: 0.000008 both: 0.000444\n",
      "Train Epoch: 223 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000000 drop: 0.000004 both: 0.000007\n",
      "Train Epoch: 223 [20000/25000 (80%)]\tLosses default: 0.000009 bn: 0.000011 drop: 0.000023 both: 0.000195\n",
      "Train Epoch: 223 [25000/25000 (100%)]\tLosses default: 0.000196 bn: 0.000065 drop: 0.000012 both: 0.000046\n",
      "Test set:\n",
      "default: Loss: 1.1104\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0029\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0568\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0307\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 224 [0/25000 (0%)]\tLosses default: 0.000030 bn: 0.000323 drop: 0.000016 both: 0.000033\n",
      "Train Epoch: 224 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000186 drop: 0.000007 both: 0.000140\n",
      "Train Epoch: 224 [20000/25000 (80%)]\tLosses default: 0.000021 bn: 0.000182 drop: 0.000002 both: 0.212304\n",
      "Train Epoch: 224 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000006 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.1173\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0188\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0406\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 0.9523\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 225 [0/25000 (0%)]\tLosses default: 0.000044 bn: 0.000646 drop: 0.000043 both: 0.004667\n",
      "Train Epoch: 225 [10000/25000 (40%)]\tLosses default: 0.000023 bn: 0.000015 drop: 0.000060 both: 0.000140\n",
      "Train Epoch: 225 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000045 drop: 0.000002 both: 0.000010\n",
      "Train Epoch: 225 [25000/25000 (100%)]\tLosses default: 0.000025 bn: 0.000034 drop: 0.000376 both: 0.000110\n",
      "Test set:\n",
      "default: Loss: 1.1243\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0370\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0784\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 0.9833\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 226 [0/25000 (0%)]\tLosses default: 0.000051 bn: 0.000559 drop: 0.000030 both: 0.000140\n",
      "Train Epoch: 226 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000012 drop: 0.000065 both: 0.000007\n",
      "Train Epoch: 226 [20000/25000 (80%)]\tLosses default: 0.000020 bn: 0.000104 drop: 0.000017 both: 0.000028\n",
      "Train Epoch: 226 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000152 drop: 0.000005 both: 0.000122\n",
      "Test set:\n",
      "default: Loss: 1.1316\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0462\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0738\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 0.9810\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 227 [0/25000 (0%)]\tLosses default: 0.000022 bn: 0.000124 drop: 0.000014 both: 0.000208\n",
      "Train Epoch: 227 [10000/25000 (40%)]\tLosses default: 0.000020 bn: 0.000009 drop: 0.000012 both: 0.002285\n",
      "Train Epoch: 227 [20000/25000 (80%)]\tLosses default: 0.000025 bn: 0.001568 drop: 0.000031 both: 0.000010\n",
      "Train Epoch: 227 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.001503 drop: 0.000003 both: 0.000097\n",
      "Test set:\n",
      "default: Loss: 1.1386\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0345\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.0917\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0133\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 228 [0/25000 (0%)]\tLosses default: 0.000050 bn: 0.003060 drop: 0.000016 both: 0.000050\n",
      "Train Epoch: 228 [10000/25000 (40%)]\tLosses default: 0.000037 bn: 0.000101 drop: 0.000005 both: 0.000114\n",
      "Train Epoch: 228 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.014310 both: 0.000197\n",
      "Train Epoch: 228 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000022 drop: 0.001576 both: 0.000996\n",
      "Test set:\n",
      "default: Loss: 1.1467\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0160\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0641\tAccuracy: 4340.0/5000 (87%)\n",
      "both: Loss: 1.0378\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 229 [0/25000 (0%)]\tLosses default: 0.000017 bn: 0.000094 drop: 0.008270 both: 0.000050\n",
      "Train Epoch: 229 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.003984 both: 0.000249\n",
      "Train Epoch: 229 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000161 drop: 0.000081 both: 0.000056\n",
      "Train Epoch: 229 [25000/25000 (100%)]\tLosses default: 0.000033 bn: 0.000242 drop: 0.094538 both: 0.001871\n",
      "Test set:\n",
      "default: Loss: 1.1533\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0209\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0223\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 0.9596\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 230 [0/25000 (0%)]\tLosses default: 0.000030 bn: 0.000054 drop: 0.000027 both: 0.000040\n",
      "Train Epoch: 230 [10000/25000 (40%)]\tLosses default: 0.000027 bn: 0.000202 drop: 0.000189 both: 0.000033\n",
      "Train Epoch: 230 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000010 drop: 0.000060 both: 0.000587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 230 [25000/25000 (100%)]\tLosses default: 0.000019 bn: 0.000034 drop: 0.000015 both: 0.000833\n",
      "Test set:\n",
      "default: Loss: 1.1614\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0173\tAccuracy: 4387.0/5000 (88%)\n",
      "drop: Loss: 1.0056\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 0.9547\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 231 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000029 drop: 0.000401 both: 0.000023\n",
      "Train Epoch: 231 [10000/25000 (40%)]\tLosses default: 0.000019 bn: 0.000037 drop: 0.000015 both: 0.000158\n",
      "Train Epoch: 231 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000202 drop: 0.000081 both: 0.001396\n",
      "Train Epoch: 231 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000017 drop: 0.000060 both: 0.000053\n",
      "Test set:\n",
      "default: Loss: 1.1677\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0236\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.0050\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 0.9570\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 232 [0/25000 (0%)]\tLosses default: 0.000024 bn: 0.000020 drop: 0.000372 both: 0.000315\n",
      "Train Epoch: 232 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000006 drop: 0.000154 both: 0.000748\n",
      "Train Epoch: 232 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000028 drop: 0.000036 both: 0.078721\n",
      "Train Epoch: 232 [25000/25000 (100%)]\tLosses default: 0.000013 bn: 0.000681 drop: 0.000033 both: 0.000129\n",
      "Test set:\n",
      "default: Loss: 1.1762\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0376\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.0098\tAccuracy: 4411.0/5000 (88%)\n",
      "both: Loss: 0.9779\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 233 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.092566 drop: 0.000083 both: 0.000109\n",
      "Train Epoch: 233 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.008179 drop: 0.000533 both: 0.000018\n",
      "Train Epoch: 233 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000182 drop: 0.000030 both: 0.000166\n",
      "Train Epoch: 233 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000049 drop: 0.000009 both: 0.000776\n",
      "Test set:\n",
      "default: Loss: 1.1836\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0176\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0032\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0007\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 234 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000030 drop: 0.000050 both: 0.000067\n",
      "Train Epoch: 234 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.000029 drop: 0.000021 both: 0.000019\n",
      "Train Epoch: 234 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000014 drop: 0.000007 both: 0.000042\n",
      "Train Epoch: 234 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000023 drop: 0.000017 both: 0.002788\n",
      "Test set:\n",
      "default: Loss: 1.1912\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0050\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0048\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 0.9768\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 235 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000106 drop: 0.000012 both: 0.000161\n",
      "Train Epoch: 235 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000037 drop: 0.000031 both: 0.004557\n",
      "Train Epoch: 235 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000024 drop: 0.000005 both: 0.000016\n",
      "Train Epoch: 235 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000008 drop: 0.000014 both: 0.000107\n",
      "Test set:\n",
      "default: Loss: 1.1988\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0271\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0300\tAccuracy: 4407.0/5000 (88%)\n",
      "both: Loss: 1.0598\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 236 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000014 drop: 0.000025 both: 0.000599\n",
      "Train Epoch: 236 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000343 drop: 0.000009 both: 0.001748\n",
      "Train Epoch: 236 [20000/25000 (80%)]\tLosses default: 0.000009 bn: 0.004169 drop: 0.000049 both: 0.106644\n",
      "Train Epoch: 236 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000635 drop: 0.000042 both: 0.010597\n",
      "Test set:\n",
      "default: Loss: 1.2088\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0121\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0298\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0140\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 237 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000087 drop: 0.000043 both: 0.000577\n",
      "Train Epoch: 237 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000065 drop: 0.000002 both: 0.000166\n",
      "Train Epoch: 237 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000244 drop: 0.000003 both: 0.000015\n",
      "Train Epoch: 237 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.004854 drop: 0.000051 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.2147\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0543\tAccuracy: 4396.0/5000 (88%)\n",
      "drop: Loss: 1.0618\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0206\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 238 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000009 both: 0.000049\n",
      "Train Epoch: 238 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000053 drop: 0.001602 both: 0.000017\n",
      "Train Epoch: 238 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000258 drop: 0.004822 both: 0.000660\n",
      "Train Epoch: 238 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000058 drop: 0.000475 both: 0.000044\n",
      "Test set:\n",
      "default: Loss: 1.2220\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0051\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0360\tAccuracy: 4360.0/5000 (87%)\n",
      "both: Loss: 0.9906\tAccuracy: 4422.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 239 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000053 drop: 0.000069 both: 0.000015\n",
      "Train Epoch: 239 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000115 both: 0.000590\n",
      "Train Epoch: 239 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000050 drop: 0.000135 both: 0.000049\n",
      "Train Epoch: 239 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000016 drop: 0.000122 both: 0.000391\n",
      "Test set:\n",
      "default: Loss: 1.2300\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 0.9989\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0127\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 0.9578\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 240 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000145 drop: 0.000377 both: 0.000633\n",
      "Train Epoch: 240 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000150 drop: 0.000084 both: 0.000029\n",
      "Train Epoch: 240 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.002793 drop: 0.000065 both: 0.001541\n",
      "Train Epoch: 240 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.006222 drop: 0.000025 both: 0.000276\n",
      "Test set:\n",
      "default: Loss: 1.2354\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0497\tAccuracy: 4395.0/5000 (88%)\n",
      "drop: Loss: 1.0115\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 0.9608\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 241 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.001100 drop: 0.000094 both: 0.000500\n",
      "Train Epoch: 241 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.001013 drop: 0.000114 both: 0.000024\n",
      "Train Epoch: 241 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000233 drop: 0.000087 both: 0.000016\n",
      "Train Epoch: 241 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000002 both: 0.002156\n",
      "Test set:\n",
      "default: Loss: 1.2432\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0132\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0213\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 0.9955\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 242 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000021 drop: 0.000076 both: 0.000023\n",
      "Train Epoch: 242 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000028 both: 0.007498\n",
      "Train Epoch: 242 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000105 drop: 0.001199 both: 0.001035\n",
      "Train Epoch: 242 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000035 drop: 0.000051 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2501\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0171\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0034\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 0.9976\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 243 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000007 both: 0.000535\n",
      "Train Epoch: 243 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000554 drop: 0.000138 both: 0.002177\n",
      "Train Epoch: 243 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.007348 drop: 0.000078 both: 0.000149\n",
      "Train Epoch: 243 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.004995 drop: 0.000015 both: 0.000402\n",
      "Test set:\n",
      "default: Loss: 1.2552\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0653\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0153\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 0.9972\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 244 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000093 both: 0.000121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 244 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.001534 drop: 0.000005 both: 0.000196\n",
      "Train Epoch: 244 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001865 drop: 0.000026 both: 0.000016\n",
      "Train Epoch: 244 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000590 drop: 0.000031 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.2610\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0258\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0145\tAccuracy: 4411.0/5000 (88%)\n",
      "both: Loss: 0.9871\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 245 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.052730 drop: 0.000017 both: 0.000021\n",
      "Train Epoch: 245 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000102 drop: 0.000020 both: 0.000165\n",
      "Train Epoch: 245 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000020 both: 0.000010\n",
      "Train Epoch: 245 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000660 drop: 0.000026 both: 0.000687\n",
      "Test set:\n",
      "default: Loss: 1.2688\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0343\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.0191\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 0.9759\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 246 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.002446 drop: 0.000207 both: 0.000539\n",
      "Train Epoch: 246 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000086 drop: 0.000211 both: 0.000348\n",
      "Train Epoch: 246 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000801 drop: 0.000011 both: 0.028181\n",
      "Train Epoch: 246 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000022 both: 0.000228\n",
      "Test set:\n",
      "default: Loss: 1.2744\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0283\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0249\tAccuracy: 4415.0/5000 (88%)\n",
      "both: Loss: 1.0350\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 247 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000037 both: 0.014160\n",
      "Train Epoch: 247 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000021 both: 0.000462\n",
      "Train Epoch: 247 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000016 drop: 0.000024 both: 0.001379\n",
      "Train Epoch: 247 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000015 both: 0.000035\n",
      "Test set:\n",
      "default: Loss: 1.2806\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 0.9848\tAccuracy: 4449.0/5000 (89%)\n",
      "drop: Loss: 1.0216\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 0.9908\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 248 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000071 drop: 0.000018 both: 0.000023\n",
      "Train Epoch: 248 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.004530 drop: 0.000010 both: 0.000004\n",
      "Train Epoch: 248 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000005 both: 0.000005\n",
      "Train Epoch: 248 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000013 both: 0.000119\n",
      "Test set:\n",
      "default: Loss: 1.2850\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0051\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.0285\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0048\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 249 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000064 both: 0.000008\n",
      "Train Epoch: 249 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000052 drop: 0.000016 both: 0.000060\n",
      "Train Epoch: 249 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000204 drop: 0.000014 both: 0.001023\n",
      "Train Epoch: 249 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000011 both: 0.000496\n",
      "Test set:\n",
      "default: Loss: 1.2908\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 0.9992\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0293\tAccuracy: 4410.0/5000 (88%)\n",
      "both: Loss: 1.0371\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 250 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000053 drop: 0.000007 both: 0.000201\n",
      "Train Epoch: 250 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.065570 drop: 0.000005 both: 0.000073\n",
      "Train Epoch: 250 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.090004 drop: 0.000003 both: 0.000090\n",
      "Train Epoch: 250 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000904 drop: 0.000023 both: 0.010337\n",
      "Test set:\n",
      "default: Loss: 1.2976\tAccuracy: 4448.0/5000 (89%)\n",
      "bn: Loss: 0.9869\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.0594\tAccuracy: 4407.0/5000 (88%)\n",
      "both: Loss: 1.0258\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 251 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.003173 drop: 0.000075 both: 0.000026\n",
      "Train Epoch: 251 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000107 drop: 0.000015 both: 0.000413\n",
      "Train Epoch: 251 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000951 drop: 0.000021 both: 0.000039\n",
      "Train Epoch: 251 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000173 drop: 0.000010 both: 0.000245\n",
      "Test set:\n",
      "default: Loss: 1.3021\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0238\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.0379\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 0.9942\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 252 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000547 drop: 0.000006 both: 0.000030\n",
      "Train Epoch: 252 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000059 drop: 0.000006 both: 0.000256\n",
      "Train Epoch: 252 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000076 drop: 0.000002 both: 0.002570\n",
      "Train Epoch: 252 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000018 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.3070\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0390\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0826\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 0.9965\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 253 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000130 drop: 0.000027 both: 0.000519\n",
      "Train Epoch: 253 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000106 drop: 0.041894 both: 0.000042\n",
      "Train Epoch: 253 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000645 drop: 0.021105 both: 0.000443\n",
      "Train Epoch: 253 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000180 drop: 0.000136 both: 0.000100\n",
      "Test set:\n",
      "default: Loss: 1.3119\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0243\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.0139\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 0.9989\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 254 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000275 drop: 0.000154 both: 0.000009\n",
      "Train Epoch: 254 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000391 drop: 0.000479 both: 0.000187\n",
      "Train Epoch: 254 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000105 both: 0.023618\n",
      "Train Epoch: 254 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000119 both: 0.000038\n",
      "Test set:\n",
      "default: Loss: 1.3147\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0081\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0005\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0153\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 255 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000106 both: 0.000010\n",
      "Train Epoch: 255 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000275 drop: 0.000047 both: 0.000026\n",
      "Train Epoch: 255 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000052 drop: 0.000211 both: 0.000033\n",
      "Train Epoch: 255 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000065 drop: 0.000032 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.3221\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0280\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 0.9881\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0041\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 256 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.004104 drop: 0.000018 both: 0.000188\n",
      "Train Epoch: 256 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000044 both: 0.000015\n",
      "Train Epoch: 256 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.043649 drop: 0.000076 both: 0.000163\n",
      "Train Epoch: 256 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.002641 drop: 0.000204 both: 0.000698\n",
      "Test set:\n",
      "default: Loss: 1.3266\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0815\tAccuracy: 4389.0/5000 (88%)\n",
      "drop: Loss: 1.0208\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0108\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 257 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000256 drop: 0.000151 both: 0.000132\n",
      "Train Epoch: 257 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000022 both: 0.021230\n",
      "Train Epoch: 257 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000032 drop: 0.000104 both: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 257 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.003125 both: 0.000256\n",
      "Test set:\n",
      "default: Loss: 1.3286\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 0.9661\tAccuracy: 4449.0/5000 (89%)\n",
      "drop: Loss: 1.0340\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0186\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 258 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000071 drop: 0.000034 both: 0.000076\n",
      "Train Epoch: 258 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000179 drop: 0.000110 both: 0.000013\n",
      "Train Epoch: 258 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000289 drop: 0.000114 both: 0.000200\n",
      "Train Epoch: 258 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000155 drop: 0.005312 both: 0.000799\n",
      "Test set:\n",
      "default: Loss: 1.3336\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 0.9898\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0135\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 0.9872\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 259 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001011 drop: 0.000180 both: 0.000018\n",
      "Train Epoch: 259 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000047 both: 0.000050\n",
      "Train Epoch: 259 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000018 both: 0.000090\n",
      "Train Epoch: 259 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000061 both: 0.000106\n",
      "Test set:\n",
      "default: Loss: 1.3374\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 0.9987\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 0.9902\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 0.9807\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 260 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.003489 drop: 0.000167 both: 0.000012\n",
      "Train Epoch: 260 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000916 both: 0.000318\n",
      "Train Epoch: 260 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000235 drop: 0.000206 both: 0.000054\n",
      "Train Epoch: 260 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001800 drop: 0.000143 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.3425\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0032\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.0321\tAccuracy: 4358.0/5000 (87%)\n",
      "both: Loss: 0.9758\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 261 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000056 both: 0.000030\n",
      "Train Epoch: 261 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000108 drop: 0.000303 both: 0.000034\n",
      "Train Epoch: 261 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000224 drop: 0.000092 both: 0.000057\n",
      "Train Epoch: 261 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000053 both: 0.000113\n",
      "Test set:\n",
      "default: Loss: 1.3430\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0225\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0035\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 0.9979\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 262 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000023 both: 0.001765\n",
      "Train Epoch: 262 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000773 drop: 0.000012 both: 0.000189\n",
      "Train Epoch: 262 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000066 drop: 0.000083 both: 0.001886\n",
      "Train Epoch: 262 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000007 both: 0.007828\n",
      "Test set:\n",
      "default: Loss: 1.3498\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0336\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0047\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0090\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 263 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000035 drop: 0.000051 both: 0.000081\n",
      "Train Epoch: 263 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000149 drop: 0.000047 both: 0.000228\n",
      "Train Epoch: 263 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000002 both: 0.002321\n",
      "Train Epoch: 263 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.085484 drop: 0.000048 both: 0.000051\n",
      "Test set:\n",
      "default: Loss: 1.4119\tAccuracy: 4403.0/5000 (88%)\n",
      "bn: Loss: 1.0263\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0114\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0197\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 264 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000084 drop: 0.000033 both: 0.000413\n",
      "Train Epoch: 264 [10000/25000 (40%)]\tLosses default: 0.003148 bn: 0.000055 drop: 0.000033 both: 0.000365\n",
      "Train Epoch: 264 [20000/25000 (80%)]\tLosses default: 0.009977 bn: 0.000012 drop: 0.000018 both: 0.000029\n",
      "Train Epoch: 264 [25000/25000 (100%)]\tLosses default: 0.000122 bn: 0.002811 drop: 0.000007 both: 0.000205\n",
      "Test set:\n",
      "default: Loss: 1.0194\tAccuracy: 4405.0/5000 (88%)\n",
      "bn: Loss: 1.0187\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0377\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 0.9704\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 265 [0/25000 (0%)]\tLosses default: 0.000013 bn: 0.000034 drop: 0.000100 both: 0.000117\n",
      "Train Epoch: 265 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.000014 both: 0.000064\n",
      "Train Epoch: 265 [20000/25000 (80%)]\tLosses default: 0.000222 bn: 0.000265 drop: 0.000006 both: 0.000019\n",
      "Train Epoch: 265 [25000/25000 (100%)]\tLosses default: 0.000538 bn: 0.000087 drop: 0.000021 both: 0.000734\n",
      "Test set:\n",
      "default: Loss: 1.0413\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0053\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0210\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 0.9561\tAccuracy: 4410.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 266 [0/25000 (0%)]\tLosses default: 0.000066 bn: 0.007596 drop: 0.000004 both: 0.000385\n",
      "Train Epoch: 266 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000298 drop: 0.000008 both: 0.000203\n",
      "Train Epoch: 266 [20000/25000 (80%)]\tLosses default: 0.000071 bn: 0.000171 drop: 0.000020 both: 0.000738\n",
      "Train Epoch: 266 [25000/25000 (100%)]\tLosses default: 0.000076 bn: 0.000013 drop: 0.000011 both: 0.006181\n",
      "Test set:\n",
      "default: Loss: 1.0589\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0271\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0215\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 0.9824\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 267 [0/25000 (0%)]\tLosses default: 0.000079 bn: 0.000269 drop: 0.000015 both: 0.000422\n",
      "Train Epoch: 267 [10000/25000 (40%)]\tLosses default: 0.000114 bn: 0.000059 drop: 0.000035 both: 0.000043\n",
      "Train Epoch: 267 [20000/25000 (80%)]\tLosses default: 0.000021 bn: 0.000006 drop: 0.000014 both: 0.016624\n",
      "Train Epoch: 267 [25000/25000 (100%)]\tLosses default: 0.000102 bn: 0.000001 drop: 0.000001 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.0706\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0158\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0418\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 0.9909\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 268 [0/25000 (0%)]\tLosses default: 0.000026 bn: 0.000145 drop: 0.000020 both: 0.000045\n",
      "Train Epoch: 268 [10000/25000 (40%)]\tLosses default: 0.000020 bn: 0.000003 drop: 0.001017 both: 0.001719\n",
      "Train Epoch: 268 [20000/25000 (80%)]\tLosses default: 0.000070 bn: 0.000038 drop: 0.005962 both: 0.014061\n",
      "Train Epoch: 268 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.001689 drop: 0.000171 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.0806\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0153\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 0.9967\tAccuracy: 4366.0/5000 (87%)\n",
      "both: Loss: 0.9934\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 269 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000336 drop: 0.000075 both: 0.000083\n",
      "Train Epoch: 269 [10000/25000 (40%)]\tLosses default: 0.000039 bn: 0.000003 drop: 0.001020 both: 0.000248\n",
      "Train Epoch: 269 [20000/25000 (80%)]\tLosses default: 0.000045 bn: 0.000094 drop: 0.000624 both: 0.000167\n",
      "Train Epoch: 269 [25000/25000 (100%)]\tLosses default: 0.000016 bn: 0.000020 drop: 0.001517 both: 0.000070\n",
      "Test set:\n",
      "default: Loss: 1.0922\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0033\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 0.9971\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 0.9761\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 270 [0/25000 (0%)]\tLosses default: 0.000040 bn: 0.004299 drop: 0.001851 both: 0.000125\n",
      "Train Epoch: 270 [10000/25000 (40%)]\tLosses default: 0.000038 bn: 0.000037 drop: 0.002395 both: 0.000726\n",
      "Train Epoch: 270 [20000/25000 (80%)]\tLosses default: 0.000207 bn: 0.000158 drop: 0.000512 both: 0.000508\n",
      "Train Epoch: 270 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000009 drop: 0.010681 both: 0.008089\n",
      "Test set:\n",
      "default: Loss: 1.1023\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0384\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0627\tAccuracy: 4341.0/5000 (87%)\n",
      "both: Loss: 1.0303\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 271 [0/25000 (0%)]\tLosses default: 0.000029 bn: 0.000063 drop: 0.000375 both: 0.000159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 271 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000094 drop: 0.000020 both: 0.002930\n",
      "Train Epoch: 271 [20000/25000 (80%)]\tLosses default: 0.000024 bn: 0.000967 drop: 0.000016 both: 0.000074\n",
      "Train Epoch: 271 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000008 drop: 0.000028 both: 0.000046\n",
      "Test set:\n",
      "default: Loss: 1.1152\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0328\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 0.9982\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 0.9939\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 272 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000116 drop: 0.000650 both: 0.000072\n",
      "Train Epoch: 272 [10000/25000 (40%)]\tLosses default: 0.000035 bn: 0.003142 drop: 0.000007 both: 0.000334\n",
      "Train Epoch: 272 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.002406 drop: 0.000035 both: 0.000031\n",
      "Train Epoch: 272 [25000/25000 (100%)]\tLosses default: 0.000034 bn: 0.000017 drop: 0.000323 both: 0.000160\n",
      "Test set:\n",
      "default: Loss: 1.1259\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0024\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.0116\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 0.9733\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 273 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000040 drop: 0.000033 both: 0.000093\n",
      "Train Epoch: 273 [10000/25000 (40%)]\tLosses default: 0.000032 bn: 0.000070 drop: 0.000424 both: 0.004827\n",
      "Train Epoch: 273 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.001517 drop: 0.000010 both: 0.000014\n",
      "Train Epoch: 273 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000006 drop: 0.000066 both: 0.000075\n",
      "Test set:\n",
      "default: Loss: 1.1376\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0013\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.0057\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0277\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 274 [0/25000 (0%)]\tLosses default: 0.000047 bn: 0.000458 drop: 0.000066 both: 0.000214\n",
      "Train Epoch: 274 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000015 drop: 0.000090 both: 0.000090\n",
      "Train Epoch: 274 [20000/25000 (80%)]\tLosses default: 0.000009 bn: 0.000022 drop: 0.000052 both: 0.000024\n",
      "Train Epoch: 274 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000085 drop: 0.000048 both: 0.000112\n",
      "Test set:\n",
      "default: Loss: 1.1479\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0072\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.0063\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0271\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 275 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.009084 drop: 0.000018 both: 0.000044\n",
      "Train Epoch: 275 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000143 drop: 0.000015 both: 0.000762\n",
      "Train Epoch: 275 [20000/25000 (80%)]\tLosses default: 0.000010 bn: 0.002424 drop: 0.000016 both: 0.000861\n",
      "Train Epoch: 275 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000116 drop: 0.000051 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.1597\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0417\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.0074\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0286\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 276 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000341 drop: 0.000013 both: 0.005560\n",
      "Train Epoch: 276 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000009 drop: 0.000069 both: 0.000104\n",
      "Train Epoch: 276 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.057176 drop: 0.000006 both: 0.000631\n",
      "Train Epoch: 276 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000085 drop: 0.000017 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.1706\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0102\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0158\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0031\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 277 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000201 drop: 0.000007 both: 0.000097\n",
      "Train Epoch: 277 [10000/25000 (40%)]\tLosses default: 0.000021 bn: 0.000017 drop: 0.000012 both: 0.000593\n",
      "Train Epoch: 277 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000097 drop: 0.000009 both: 0.000016\n",
      "Train Epoch: 277 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.001596 drop: 0.000025 both: 0.000428\n",
      "Test set:\n",
      "default: Loss: 1.1812\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 0.9856\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0369\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0097\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 278 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000157 drop: 0.000013 both: 0.000130\n",
      "Train Epoch: 278 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000025 drop: 0.000015 both: 0.000113\n",
      "Train Epoch: 278 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000111 drop: 0.000033 both: 0.000030\n",
      "Train Epoch: 278 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000428 drop: 0.000009 both: 0.000081\n",
      "Test set:\n",
      "default: Loss: 1.1927\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0128\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0398\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0116\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 279 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000018 drop: 0.000006 both: 0.000049\n",
      "Train Epoch: 279 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000008 both: 0.002061\n",
      "Train Epoch: 279 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000022 drop: 0.000010 both: 0.000230\n",
      "Train Epoch: 279 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000064 drop: 0.000005 both: 0.000034\n",
      "Test set:\n",
      "default: Loss: 1.2024\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0252\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0279\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0030\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 280 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000097 both: 0.001067\n",
      "Train Epoch: 280 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.006719 drop: 0.000060 both: 0.000534\n",
      "Train Epoch: 280 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000079 drop: 0.000011 both: 0.000006\n",
      "Train Epoch: 280 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000020 drop: 0.000011 both: 0.000054\n",
      "Test set:\n",
      "default: Loss: 1.2127\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0356\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.0559\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0253\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 281 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000104 drop: 0.000009 both: 0.000042\n",
      "Train Epoch: 281 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000055 both: 0.000003\n",
      "Train Epoch: 281 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000184 drop: 0.053800 both: 0.000047\n",
      "Train Epoch: 281 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000114 drop: 0.002311 both: 0.000049\n",
      "Test set:\n",
      "default: Loss: 1.2224\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0136\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 0.9741\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0129\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 282 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000002 drop: 0.003126 both: 0.000198\n",
      "Train Epoch: 282 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000189 drop: 0.000561 both: 0.001457\n",
      "Train Epoch: 282 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000001 drop: 0.006986 both: 0.000149\n",
      "Train Epoch: 282 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.002940 drop: 0.000083 both: 0.002162\n",
      "Test set:\n",
      "default: Loss: 1.2329\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 0.9932\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 0.9881\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0015\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 283 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000017 drop: 0.000528 both: 0.002186\n",
      "Train Epoch: 283 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000007 drop: 0.031362 both: 0.000609\n",
      "Train Epoch: 283 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000628 drop: 0.000006 both: 0.000046\n",
      "Train Epoch: 283 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000043 drop: 0.000197 both: 0.000072\n",
      "Test set:\n",
      "default: Loss: 1.2420\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0188\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 0.9949\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 0.9818\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 284 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.055466 drop: 0.000051 both: 0.000037\n",
      "Train Epoch: 284 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000022 both: 0.000416\n",
      "Train Epoch: 284 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000195 both: 0.000790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 284 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000195 drop: 0.000019 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.2499\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 0.9978\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 0.9917\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0070\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 285 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000022 drop: 0.000142 both: 0.000166\n",
      "Train Epoch: 285 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000061 drop: 0.000335 both: 0.000698\n",
      "Train Epoch: 285 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000079 both: 0.000026\n",
      "Train Epoch: 285 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000011 drop: 0.000200 both: 0.040969\n",
      "Test set:\n",
      "default: Loss: 1.2586\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0054\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.0190\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 0.9797\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 286 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000064 drop: 0.000256 both: 0.000032\n",
      "Train Epoch: 286 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000011 drop: 0.000061 both: 0.000119\n",
      "Train Epoch: 286 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000002 both: 0.000002\n",
      "Train Epoch: 286 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000190 drop: 0.000030 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.2666\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0303\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.0130\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 0.9476\tAccuracy: 4419.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 287 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000031 both: 0.000028\n",
      "Train Epoch: 287 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000003 both: 0.000014\n",
      "Train Epoch: 287 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000124 drop: 0.000610 both: 0.000025\n",
      "Train Epoch: 287 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000017 drop: 0.000031 both: 0.000034\n",
      "Test set:\n",
      "default: Loss: 1.2761\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0367\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.0164\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 0.9713\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 288 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000093 drop: 0.000006 both: 0.000072\n",
      "Train Epoch: 288 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000369 drop: 0.000007 both: 0.000018\n",
      "Train Epoch: 288 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000138 both: 0.000083\n",
      "Train Epoch: 288 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000592 drop: 0.000048 both: 0.000114\n",
      "Test set:\n",
      "default: Loss: 1.2832\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0744\tAccuracy: 4393.0/5000 (88%)\n",
      "drop: Loss: 1.0113\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 0.9751\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 289 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000481 drop: 0.000080 both: 0.000018\n",
      "Train Epoch: 289 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000026 drop: 0.000006 both: 0.000027\n",
      "Train Epoch: 289 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000055 drop: 0.000047 both: 0.000007\n",
      "Train Epoch: 289 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000504 drop: 0.000014 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.2916\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0155\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.0190\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 0.9749\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 290 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000061 drop: 0.000010 both: 0.002821\n",
      "Train Epoch: 290 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000018 drop: 0.000034 both: 0.040881\n",
      "Train Epoch: 290 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000146 drop: 0.000028 both: 0.001024\n",
      "Train Epoch: 290 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000579 drop: 0.000007 both: 0.001524\n",
      "Test set:\n",
      "default: Loss: 1.2983\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 0.9852\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0165\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 1.0111\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 291 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000076 both: 0.001705\n",
      "Train Epoch: 291 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000027 both: 0.000064\n",
      "Train Epoch: 291 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000056 drop: 0.000019 both: 0.068956\n",
      "Train Epoch: 291 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.016090 drop: 0.000037 both: 0.000100\n",
      "Test set:\n",
      "default: Loss: 1.3042\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0094\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.0203\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0190\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 292 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000003 both: 0.000095\n",
      "Train Epoch: 292 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.097710 drop: 0.000008 both: 0.000232\n",
      "Train Epoch: 292 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000028 drop: 0.000512 both: 0.000235\n",
      "Train Epoch: 292 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.006366 drop: 0.000021 both: 0.000612\n",
      "Test set:\n",
      "default: Loss: 1.3114\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0120\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.0319\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 0.9985\tAccuracy: 4410.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 293 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.025778 drop: 0.000031 both: 0.000840\n",
      "Train Epoch: 293 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000015 both: 0.000018\n",
      "Train Epoch: 293 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000008 both: 0.000688\n",
      "Train Epoch: 293 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000245 drop: 0.000007 both: 0.007705\n",
      "Test set:\n",
      "default: Loss: 1.3171\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 0.9977\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.0368\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 1.0453\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 294 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000636 drop: 0.000024 both: 0.000033\n",
      "Train Epoch: 294 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000014 both: 0.000003\n",
      "Train Epoch: 294 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000072 drop: 0.000007 both: 0.000119\n",
      "Train Epoch: 294 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000003 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.3223\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 0.9896\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.0478\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 0.9955\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 295 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000003 both: 0.000146\n",
      "Train Epoch: 295 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000072 drop: 0.000001 both: 0.000013\n",
      "Train Epoch: 295 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000015 both: 0.000037\n",
      "Train Epoch: 295 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000022 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.3292\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.0127\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.0684\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0242\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 296 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000005 both: 0.000053\n",
      "Train Epoch: 296 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000027 both: 0.001060\n",
      "Train Epoch: 296 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000003 both: 0.000030\n",
      "Train Epoch: 296 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000254 drop: 0.000024 both: 0.000750\n",
      "Test set:\n",
      "default: Loss: 1.3356\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0144\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0837\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 0.9839\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 297 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000003 both: 0.000039\n",
      "Train Epoch: 297 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.069201 both: 0.000185\n",
      "Train Epoch: 297 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000432 both: 0.000024\n",
      "Train Epoch: 297 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000262 drop: 0.000234 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.3376\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0233\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 0.9784\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0190\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 298 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.032891 both: 0.000073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 298 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000674 drop: 0.000584 both: 0.000021\n",
      "Train Epoch: 298 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.003086 drop: 0.000214 both: 0.000240\n",
      "Train Epoch: 298 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001242 drop: 0.000555 both: 0.000460\n",
      "Test set:\n",
      "default: Loss: 1.3439\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0480\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 0.9951\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0106\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 299 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000171 drop: 0.000393 both: 0.000043\n",
      "Train Epoch: 299 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.004693 drop: 0.000070 both: 0.000410\n",
      "Train Epoch: 299 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000338 drop: 0.000260 both: 0.000501\n",
      "Train Epoch: 299 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001272 drop: 0.000006 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3509\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.0240\tAccuracy: 4391.0/5000 (88%)\n",
      "drop: Loss: 0.9903\tAccuracy: 4366.0/5000 (87%)\n",
      "both: Loss: 1.0093\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 300 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000083 both: 0.000222\n",
      "Train Epoch: 300 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000123 drop: 0.000098 both: 0.000052\n",
      "Train Epoch: 300 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000039 drop: 0.000060 both: 0.000062\n",
      "Train Epoch: 300 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.067894 drop: 0.000381 both: 0.000963\n",
      "Test set:\n",
      "default: Loss: 1.3552\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0390\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 0.9870\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0084\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 301 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000104 drop: 0.000007 both: 0.000113\n",
      "Train Epoch: 301 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.004637 drop: 0.000027 both: 0.000591\n",
      "Train Epoch: 301 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.014022 drop: 0.000115 both: 0.000034\n",
      "Train Epoch: 301 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000038 drop: 0.000120 both: 0.000039\n",
      "Test set:\n",
      "default: Loss: 1.3574\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0118\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 0.9961\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0262\tAccuracy: 4412.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 302 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.002713 drop: 0.000093 both: 0.000995\n",
      "Train Epoch: 302 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000049 both: 0.000009\n",
      "Train Epoch: 302 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000025 both: 0.000027\n",
      "Train Epoch: 302 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.002539 drop: 0.000330 both: 0.000693\n",
      "Test set:\n",
      "default: Loss: 1.3593\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0180\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 0.9908\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0176\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 303 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000016 both: 0.000042\n",
      "Train Epoch: 303 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000304 drop: 0.000011 both: 0.038446\n",
      "Train Epoch: 303 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.002896 drop: 0.000040 both: 0.010411\n",
      "Train Epoch: 303 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000006 both: 0.001430\n",
      "Test set:\n",
      "default: Loss: 1.3651\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0356\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0059\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0387\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 304 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000193 drop: 0.000044 both: 0.004826\n",
      "Train Epoch: 304 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000585 drop: 0.000044 both: 0.001838\n",
      "Train Epoch: 304 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001598 drop: 0.000005 both: 0.000872\n",
      "Train Epoch: 304 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001314 drop: 0.000012 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.3705\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0060\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0344\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0506\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 305 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.004922 drop: 0.000066 both: 0.000049\n",
      "Train Epoch: 305 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000203 both: 0.000004\n",
      "Train Epoch: 305 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000066 both: 0.018110\n",
      "Train Epoch: 305 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000021 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.3685\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0298\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 0.9863\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0142\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 306 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000051 both: 0.000022\n",
      "Train Epoch: 306 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000179 both: 0.029680\n",
      "Train Epoch: 306 [20000/25000 (80%)]\tLosses default: 0.000025 bn: 0.000037 drop: 0.000092 both: 0.000401\n",
      "Train Epoch: 306 [25000/25000 (100%)]\tLosses default: 0.045164 bn: 0.000018 drop: 0.000069 both: 0.008268\n",
      "Test set:\n",
      "default: Loss: 1.1493\tAccuracy: 4377.0/5000 (88%)\n",
      "bn: Loss: 1.0416\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 0.9815\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0125\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 307 [0/25000 (0%)]\tLosses default: 0.088489 bn: 0.000010 drop: 0.000107 both: 0.000019\n",
      "Train Epoch: 307 [10000/25000 (40%)]\tLosses default: 0.002279 bn: 0.000021 drop: 0.000087 both: 0.000025\n",
      "Train Epoch: 307 [20000/25000 (80%)]\tLosses default: 0.000012 bn: 0.000004 drop: 0.000007 both: 0.000003\n",
      "Train Epoch: 307 [25000/25000 (100%)]\tLosses default: 0.000211 bn: 0.000296 drop: 0.000014 both: 0.000172\n",
      "Test set:\n",
      "default: Loss: 1.1318\tAccuracy: 4411.0/5000 (88%)\n",
      "bn: Loss: 1.0697\tAccuracy: 4384.0/5000 (88%)\n",
      "drop: Loss: 0.9867\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 0.9798\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 308 [0/25000 (0%)]\tLosses default: 0.020819 bn: 0.000063 drop: 0.000008 both: 0.000060\n",
      "Train Epoch: 308 [10000/25000 (40%)]\tLosses default: 0.001355 bn: 0.000071 drop: 0.000016 both: 0.000062\n",
      "Train Epoch: 308 [20000/25000 (80%)]\tLosses default: 0.000027 bn: 0.000022 drop: 0.000546 both: 0.000056\n",
      "Train Epoch: 308 [25000/25000 (100%)]\tLosses default: 0.003116 bn: 0.000149 drop: 0.000057 both: 0.001534\n",
      "Test set:\n",
      "default: Loss: 1.0728\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0249\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 0.9932\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0051\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 309 [0/25000 (0%)]\tLosses default: 0.000042 bn: 0.000544 drop: 0.000587 both: 0.000061\n",
      "Train Epoch: 309 [10000/25000 (40%)]\tLosses default: 0.000021 bn: 0.000003 drop: 0.000602 both: 0.000043\n",
      "Train Epoch: 309 [20000/25000 (80%)]\tLosses default: 0.000032 bn: 0.000068 drop: 0.011542 both: 0.002993\n",
      "Train Epoch: 309 [25000/25000 (100%)]\tLosses default: 0.000047 bn: 0.000493 drop: 0.000080 both: 0.004085\n",
      "Test set:\n",
      "default: Loss: 1.0755\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0185\tAccuracy: 4400.0/5000 (88%)\n",
      "drop: Loss: 1.0426\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 0.9962\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 310 [0/25000 (0%)]\tLosses default: 0.000106 bn: 0.000021 drop: 0.001395 both: 0.000026\n",
      "Train Epoch: 310 [10000/25000 (40%)]\tLosses default: 0.000011 bn: 0.000047 drop: 0.000160 both: 0.004125\n",
      "Train Epoch: 310 [20000/25000 (80%)]\tLosses default: 0.000027 bn: 0.000005 drop: 0.000036 both: 0.000057\n",
      "Train Epoch: 310 [25000/25000 (100%)]\tLosses default: 0.000051 bn: 0.000069 drop: 0.000145 both: 0.000431\n",
      "Test set:\n",
      "default: Loss: 1.0840\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0004\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.0550\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0878\tAccuracy: 4367.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 311 [0/25000 (0%)]\tLosses default: 0.000078 bn: 0.000417 drop: 0.000136 both: 0.001602\n",
      "Train Epoch: 311 [10000/25000 (40%)]\tLosses default: 0.000017 bn: 0.001122 drop: 0.000106 both: 0.000037\n",
      "Train Epoch: 311 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.005286 both: 0.000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 311 [25000/25000 (100%)]\tLosses default: 0.000020 bn: 0.000004 drop: 0.003921 both: 0.000044\n",
      "Test set:\n",
      "default: Loss: 1.0927\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0179\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0186\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 0.9921\tAccuracy: 4423.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 312 [0/25000 (0%)]\tLosses default: 0.000056 bn: 0.020161 drop: 0.000080 both: 0.002857\n",
      "Train Epoch: 312 [10000/25000 (40%)]\tLosses default: 0.000059 bn: 0.000004 drop: 0.000064 both: 0.000007\n",
      "Train Epoch: 312 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000006 drop: 0.000073 both: 0.000024\n",
      "Train Epoch: 312 [25000/25000 (100%)]\tLosses default: 0.000107 bn: 0.000513 drop: 0.001240 both: 0.000082\n",
      "Test set:\n",
      "default: Loss: 1.1024\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 0.9804\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.0442\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 0.9987\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 313 [0/25000 (0%)]\tLosses default: 0.000011 bn: 0.000006 drop: 0.000940 both: 0.000387\n",
      "Train Epoch: 313 [10000/25000 (40%)]\tLosses default: 0.000021 bn: 0.000011 drop: 0.000237 both: 0.000002\n",
      "Train Epoch: 313 [20000/25000 (80%)]\tLosses default: 0.000030 bn: 0.000097 drop: 0.000027 both: 0.000043\n",
      "Train Epoch: 313 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000236 both: 0.000030\n",
      "Test set:\n",
      "default: Loss: 1.1103\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0271\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0542\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0058\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 314 [0/25000 (0%)]\tLosses default: 0.000028 bn: 0.000337 drop: 0.000069 both: 0.103688\n",
      "Train Epoch: 314 [10000/25000 (40%)]\tLosses default: 0.000032 bn: 0.008457 drop: 0.000085 both: 0.016414\n",
      "Train Epoch: 314 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000015 drop: 0.000874 both: 0.000095\n",
      "Train Epoch: 314 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000095 drop: 0.000245 both: 0.000864\n",
      "Test set:\n",
      "default: Loss: 1.1207\tAccuracy: 4448.0/5000 (89%)\n",
      "bn: Loss: 1.0302\tAccuracy: 4391.0/5000 (88%)\n",
      "drop: Loss: 1.0480\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 0.9808\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 315 [0/25000 (0%)]\tLosses default: 0.000026 bn: 0.001385 drop: 0.000077 both: 0.000424\n",
      "Train Epoch: 315 [10000/25000 (40%)]\tLosses default: 0.000048 bn: 0.000412 drop: 0.006535 both: 0.083089\n",
      "Train Epoch: 315 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000015 drop: 0.000706 both: 0.000012\n",
      "Train Epoch: 315 [25000/25000 (100%)]\tLosses default: 0.000015 bn: 0.000043 drop: 0.000085 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.1298\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0013\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.0267\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0048\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 316 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000008 drop: 0.000011 both: 0.000015\n",
      "Train Epoch: 316 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000073 drop: 0.000125 both: 0.000166\n",
      "Train Epoch: 316 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000198 drop: 0.000049 both: 0.000084\n",
      "Train Epoch: 316 [25000/25000 (100%)]\tLosses default: 0.000026 bn: 0.000157 drop: 0.000682 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.1388\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.0258\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.0373\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0198\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 317 [0/25000 (0%)]\tLosses default: 0.000011 bn: 0.000013 drop: 0.000011 both: 0.000081\n",
      "Train Epoch: 317 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000087 drop: 0.000016 both: 0.000009\n",
      "Train Epoch: 317 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000002 drop: 0.000018 both: 0.000017\n",
      "Train Epoch: 317 [25000/25000 (100%)]\tLosses default: 0.000012 bn: 0.000852 drop: 0.000178 both: 0.000120\n",
      "Test set:\n",
      "default: Loss: 1.1491\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 0.9999\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0421\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 0.9987\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 318 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000049 drop: 0.000050 both: 0.000033\n",
      "Train Epoch: 318 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000006 drop: 0.000189 both: 0.000234\n",
      "Train Epoch: 318 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000039 drop: 0.000029 both: 0.000362\n",
      "Train Epoch: 318 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000074 drop: 0.000477 both: 0.002117\n",
      "Test set:\n",
      "default: Loss: 1.1584\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0275\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.0388\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0968\tAccuracy: 4350.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 319 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000052 drop: 0.000016 both: 0.000093\n",
      "Train Epoch: 319 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000021 both: 0.000709\n",
      "Train Epoch: 319 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.001789 drop: 0.000199 both: 0.000026\n",
      "Train Epoch: 319 [25000/25000 (100%)]\tLosses default: 0.000011 bn: 0.000239 drop: 0.000014 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.1690\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0109\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.0415\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0406\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 320 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000083 drop: 0.000030 both: 0.000079\n",
      "Train Epoch: 320 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000013 drop: 0.000090 both: 0.001897\n",
      "Train Epoch: 320 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000028 drop: 0.000027 both: 0.000211\n",
      "Train Epoch: 320 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000029 drop: 0.000042 both: 0.000046\n",
      "Test set:\n",
      "default: Loss: 1.1777\tAccuracy: 4448.0/5000 (89%)\n",
      "bn: Loss: 1.0332\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.0466\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0558\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 321 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000007 drop: 0.000025 both: 0.000058\n",
      "Train Epoch: 321 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000079 drop: 0.000039 both: 0.002351\n",
      "Train Epoch: 321 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000171 both: 0.000030\n",
      "Train Epoch: 321 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.028066 drop: 0.000005 both: 0.000281\n",
      "Test set:\n",
      "default: Loss: 1.1870\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.0571\tAccuracy: 4383.0/5000 (88%)\n",
      "drop: Loss: 1.0630\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0539\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 322 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000015 drop: 0.000007 both: 0.000034\n",
      "Train Epoch: 322 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000016 drop: 0.000030 both: 0.000071\n",
      "Train Epoch: 322 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000174 drop: 0.000020 both: 0.000004\n",
      "Train Epoch: 322 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.003190 drop: 0.000087 both: 0.000612\n",
      "Test set:\n",
      "default: Loss: 1.1964\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0145\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0475\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.0043\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 323 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000011 drop: 0.000005 both: 0.000006\n",
      "Train Epoch: 323 [10000/25000 (40%)]\tLosses default: 0.000012 bn: 0.000022 drop: 0.000017 both: 0.000103\n",
      "Train Epoch: 323 [20000/25000 (80%)]\tLosses default: 0.000012 bn: 0.058150 drop: 0.000013 both: 0.000034\n",
      "Train Epoch: 323 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.002028 drop: 0.000005 both: 0.000460\n",
      "Test set:\n",
      "default: Loss: 1.2060\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.0105\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.0460\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0062\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 324 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000031 drop: 0.000021 both: 0.000598\n",
      "Train Epoch: 324 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000516 drop: 0.000005 both: 0.000024\n",
      "Train Epoch: 324 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000020 drop: 0.000006 both: 0.000186\n",
      "Train Epoch: 324 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000210 drop: 0.000001 both: 0.000875\n",
      "Test set:\n",
      "default: Loss: 1.2139\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 0.9822\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0736\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0067\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 325 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000087 drop: 0.000007 both: 0.000020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 325 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000267 drop: 0.000013 both: 0.000028\n",
      "Train Epoch: 325 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000004 both: 0.000065\n",
      "Train Epoch: 325 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000549 drop: 0.000037 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.2239\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.0632\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.0688\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 1.0163\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 326 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000595 drop: 0.000013 both: 0.004747\n",
      "Train Epoch: 326 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000102 drop: 0.000012 both: 0.000048\n",
      "Train Epoch: 326 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000004 both: 0.000030\n",
      "Train Epoch: 326 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000098 drop: 0.000208 both: 0.000186\n",
      "Test set:\n",
      "default: Loss: 1.2321\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0599\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.0890\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0199\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 327 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000081 drop: 0.000008 both: 0.000004\n",
      "Train Epoch: 327 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000001 both: 0.000311\n",
      "Train Epoch: 327 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000061 drop: 0.000006 both: 0.000376\n",
      "Train Epoch: 327 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000362 drop: 0.000003 both: 0.000035\n",
      "Test set:\n",
      "default: Loss: 1.2404\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0283\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.0818\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0247\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 328 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000003 both: 0.000438\n",
      "Train Epoch: 328 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000002 both: 0.001186\n",
      "Train Epoch: 328 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.001516 drop: 0.000011 both: 0.000164\n",
      "Train Epoch: 328 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000030 drop: 0.000009 both: 0.000117\n",
      "Test set:\n",
      "default: Loss: 1.2476\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0314\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.0865\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0261\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 329 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000008 both: 0.000040\n",
      "Train Epoch: 329 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000004 both: 0.000047\n",
      "Train Epoch: 329 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000014 drop: 0.000070 both: 0.000030\n",
      "Train Epoch: 329 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000003 both: 0.000422\n",
      "Test set:\n",
      "default: Loss: 1.2558\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0323\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.1005\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0169\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 330 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000052 drop: 0.000009 both: 0.017154\n",
      "Train Epoch: 330 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000027 drop: 0.014360 both: 0.000026\n",
      "Train Epoch: 330 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000145 drop: 0.001979 both: 0.000015\n",
      "Train Epoch: 330 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.003011 drop: 0.002491 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.2637\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.1222\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.0195\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.0136\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 331 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000142 both: 0.000109\n",
      "Train Epoch: 331 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000748 drop: 0.000110 both: 0.000026\n",
      "Train Epoch: 331 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000028 drop: 0.000408 both: 0.000034\n",
      "Train Epoch: 331 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.005021 drop: 0.000007 both: 0.000939\n",
      "Test set:\n",
      "default: Loss: 1.2690\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0587\tAccuracy: 4401.0/5000 (88%)\n",
      "drop: Loss: 1.0379\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0776\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 332 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000098 drop: 0.000188 both: 0.027986\n",
      "Train Epoch: 332 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000994 both: 0.000167\n",
      "Train Epoch: 332 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000108 drop: 0.000029 both: 0.002337\n",
      "Train Epoch: 332 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000411 drop: 0.000012 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.2766\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0372\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.0342\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0129\tAccuracy: 4415.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 333 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000022 both: 0.007984\n",
      "Train Epoch: 333 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.092076 drop: 0.000059 both: 0.000091\n",
      "Train Epoch: 333 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000047 drop: 0.000027 both: 0.000106\n",
      "Train Epoch: 333 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000344 drop: 0.000019 both: 0.001916\n",
      "Test set:\n",
      "default: Loss: 1.2831\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0459\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0385\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0244\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 334 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000017 drop: 0.000004 both: 0.000156\n",
      "Train Epoch: 334 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000013 both: 0.000066\n",
      "Train Epoch: 334 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000621 drop: 0.000005 both: 0.000245\n",
      "Train Epoch: 334 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000004 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.2891\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0554\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0414\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0384\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 335 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000223 drop: 0.000105 both: 0.000017\n",
      "Train Epoch: 335 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000052 drop: 0.000037 both: 0.000489\n",
      "Train Epoch: 335 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000231 drop: 0.000206 both: 0.000051\n",
      "Train Epoch: 335 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000076 both: 0.000078\n",
      "Test set:\n",
      "default: Loss: 1.2963\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0449\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.0619\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0403\tAccuracy: 4370.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 336 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000003 both: 0.000081\n",
      "Train Epoch: 336 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000018 both: 0.000254\n",
      "Train Epoch: 336 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000272 drop: 0.000280 both: 0.000375\n",
      "Train Epoch: 336 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000120 drop: 0.000216 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.3014\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0302\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 1.0428\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0408\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 337 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.002084 drop: 0.000002 both: 0.000018\n",
      "Train Epoch: 337 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000118 drop: 0.000014 both: 0.000056\n",
      "Train Epoch: 337 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000043 both: 0.000036\n",
      "Train Epoch: 337 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000009 both: 0.000703\n",
      "Test set:\n",
      "default: Loss: 1.3057\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0366\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.0473\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0153\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 338 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000038 both: 0.035719\n",
      "Train Epoch: 338 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000003 both: 0.000006\n",
      "Train Epoch: 338 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000052 drop: 0.000017 both: 0.000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 338 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000234 drop: 0.000013 both: 0.000134\n",
      "Test set:\n",
      "default: Loss: 1.3110\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.0212\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0634\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0249\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 339 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000412 drop: 0.000089 both: 0.000060\n",
      "Train Epoch: 339 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.012667 drop: 0.000005 both: 0.000148\n",
      "Train Epoch: 339 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000093 drop: 0.000034 both: 0.000020\n",
      "Train Epoch: 339 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001496 drop: 0.000009 both: 0.008369\n",
      "Test set:\n",
      "default: Loss: 1.3177\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0300\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.0550\tAccuracy: 4413.0/5000 (88%)\n",
      "both: Loss: 1.0564\tAccuracy: 4358.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 340 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000221 drop: 0.000037 both: 0.000835\n",
      "Train Epoch: 340 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000064 drop: 0.000011 both: 0.000544\n",
      "Train Epoch: 340 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000022 both: 0.001775\n",
      "Train Epoch: 340 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000012 both: 0.000062\n",
      "Test set:\n",
      "default: Loss: 1.3225\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0321\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0703\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 1.0718\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 341 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000006 both: 0.000021\n",
      "Train Epoch: 341 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000268 drop: 0.002810 both: 0.000313\n",
      "Train Epoch: 341 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000060 both: 0.000011\n",
      "Train Epoch: 341 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000007 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.3283\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 0.9914\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0890\tAccuracy: 4409.0/5000 (88%)\n",
      "both: Loss: 1.0166\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 342 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 342 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.004186 both: 0.000105\n",
      "Train Epoch: 342 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000304 drop: 0.006337 both: 0.000008\n",
      "Train Epoch: 342 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000155 drop: 0.002632 both: 0.015015\n",
      "Test set:\n",
      "default: Loss: 1.3323\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0161\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0543\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0303\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 343 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000378 both: 0.000012\n",
      "Train Epoch: 343 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.021592 both: 0.000036\n",
      "Train Epoch: 343 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000200 both: 0.000054\n",
      "Train Epoch: 343 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000192 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.3353\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0327\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0849\tAccuracy: 4363.0/5000 (87%)\n",
      "both: Loss: 1.0431\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 344 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000224 both: 0.000119\n",
      "Train Epoch: 344 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000076 both: 0.000219\n",
      "Train Epoch: 344 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000086 drop: 0.000009 both: 0.000071\n",
      "Train Epoch: 344 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001610 drop: 0.000017 both: 0.000049\n",
      "Test set:\n",
      "default: Loss: 1.3424\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0601\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.0732\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0431\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 345 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000253 drop: 0.000156 both: 0.000039\n",
      "Train Epoch: 345 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000036 drop: 0.000096 both: 0.002034\n",
      "Train Epoch: 345 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000988 drop: 0.001426 both: 0.000058\n",
      "Train Epoch: 345 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001184 drop: 0.000090 both: 0.000038\n",
      "Test set:\n",
      "default: Loss: 1.3455\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0527\tAccuracy: 4394.0/5000 (88%)\n",
      "drop: Loss: 1.0408\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0147\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 346 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001046 drop: 0.000098 both: 0.000065\n",
      "Train Epoch: 346 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000136 both: 0.000042\n",
      "Train Epoch: 346 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000470 drop: 0.000033 both: 0.000003\n",
      "Train Epoch: 346 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000013 both: 0.012995\n",
      "Test set:\n",
      "default: Loss: 1.3482\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0345\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.0498\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0377\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 347 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000298 both: 0.001040\n",
      "Train Epoch: 347 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000132 both: 0.000015\n",
      "Train Epoch: 347 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000249 drop: 0.000076 both: 0.000063\n",
      "Train Epoch: 347 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000007 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.3511\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0366\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.0427\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0083\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 348 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000094 drop: 0.000023 both: 0.024669\n",
      "Train Epoch: 348 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000334 drop: 0.000238 both: 0.000019\n",
      "Train Epoch: 348 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000035 drop: 0.000005 both: 0.000064\n",
      "Train Epoch: 348 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000374 drop: 0.000008 both: 0.000031\n",
      "Test set:\n",
      "default: Loss: 1.3663\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 0.9786\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0499\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 0.9891\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 349 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000013 both: 0.000011\n",
      "Train Epoch: 349 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000037 both: 0.000088\n",
      "Train Epoch: 349 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000007 both: 0.000011\n",
      "Train Epoch: 349 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.002903 drop: 0.000010 both: 0.000074\n",
      "Test set:\n",
      "default: Loss: 1.3613\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 0.9787\tAccuracy: 4447.0/5000 (89%)\n",
      "drop: Loss: 1.0545\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0293\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 350 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000053 drop: 0.000033 both: 0.000502\n",
      "Train Epoch: 350 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000018 both: 0.000252\n",
      "Train Epoch: 350 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000225 drop: 0.000010 both: 0.000444\n",
      "Train Epoch: 350 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000181 drop: 0.000019 both: 0.003192\n",
      "Test set:\n",
      "default: Loss: 1.4266\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0436\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0564\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0657\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 351 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000065 both: 0.000008\n",
      "Train Epoch: 351 [10000/25000 (40%)]\tLosses default: 0.000606 bn: 0.000007 drop: 0.000005 both: 0.000272\n",
      "Train Epoch: 351 [20000/25000 (80%)]\tLosses default: 0.000064 bn: 0.001191 drop: 0.000005 both: 0.000568\n",
      "Train Epoch: 351 [25000/25000 (100%)]\tLosses default: 0.000058 bn: 0.000291 drop: 0.000003 both: 0.000588\n",
      "Test set:\n",
      "default: Loss: 1.0665\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.0472\tAccuracy: 4395.0/5000 (88%)\n",
      "drop: Loss: 1.0661\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0622\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 352 [0/25000 (0%)]\tLosses default: 0.000066 bn: 0.007815 drop: 0.000004 both: 0.000030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 352 [10000/25000 (40%)]\tLosses default: 0.000034 bn: 0.000017 drop: 0.000103 both: 0.000047\n",
      "Train Epoch: 352 [20000/25000 (80%)]\tLosses default: 0.000236 bn: 0.000241 drop: 0.002216 both: 0.000024\n",
      "Train Epoch: 352 [25000/25000 (100%)]\tLosses default: 0.000080 bn: 0.000036 drop: 0.000565 both: 0.000207\n",
      "Test set:\n",
      "default: Loss: 1.0797\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 0.9913\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0510\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0659\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 353 [0/25000 (0%)]\tLosses default: 0.000166 bn: 0.000020 drop: 0.000063 both: 0.003243\n",
      "Train Epoch: 353 [10000/25000 (40%)]\tLosses default: 0.000017 bn: 0.000210 drop: 0.004238 both: 0.000634\n",
      "Train Epoch: 353 [20000/25000 (80%)]\tLosses default: 0.000014 bn: 0.000026 drop: 0.000103 both: 0.000073\n",
      "Train Epoch: 353 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.058418 drop: 0.000006 both: 0.000581\n",
      "Test set:\n",
      "default: Loss: 1.0859\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 0.9964\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0186\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0435\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 354 [0/25000 (0%)]\tLosses default: 0.000053 bn: 0.000015 drop: 0.000135 both: 0.000356\n",
      "Train Epoch: 354 [10000/25000 (40%)]\tLosses default: 0.000103 bn: 0.000019 drop: 0.000554 both: 0.000276\n",
      "Train Epoch: 354 [20000/25000 (80%)]\tLosses default: 0.000094 bn: 0.000080 drop: 0.000057 both: 0.000365\n",
      "Train Epoch: 354 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000041 drop: 0.000013 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.0942\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0074\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 1.0205\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0355\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 355 [0/25000 (0%)]\tLosses default: 0.000016 bn: 0.000016 drop: 0.000021 both: 0.002187\n",
      "Train Epoch: 355 [10000/25000 (40%)]\tLosses default: 0.000031 bn: 0.000241 drop: 0.000182 both: 0.000097\n",
      "Train Epoch: 355 [20000/25000 (80%)]\tLosses default: 0.000046 bn: 0.000002 drop: 0.000201 both: 0.000038\n",
      "Train Epoch: 355 [25000/25000 (100%)]\tLosses default: 0.000055 bn: 0.000088 drop: 0.000016 both: 0.000566\n",
      "Test set:\n",
      "default: Loss: 1.1035\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0362\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.0394\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0032\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 356 [0/25000 (0%)]\tLosses default: 0.000016 bn: 0.000006 drop: 0.000098 both: 0.000010\n",
      "Train Epoch: 356 [10000/25000 (40%)]\tLosses default: 0.000057 bn: 0.000009 drop: 0.000033 both: 0.001164\n",
      "Train Epoch: 356 [20000/25000 (80%)]\tLosses default: 0.000016 bn: 0.000009 drop: 0.000105 both: 0.000075\n",
      "Train Epoch: 356 [25000/25000 (100%)]\tLosses default: 0.000027 bn: 0.000041 drop: 0.000031 both: 0.000041\n",
      "Test set:\n",
      "default: Loss: 1.1138\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0334\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.0479\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0168\tAccuracy: 4414.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 357 [0/25000 (0%)]\tLosses default: 0.000013 bn: 0.000004 drop: 0.000053 both: 0.005228\n",
      "Train Epoch: 357 [10000/25000 (40%)]\tLosses default: 0.000020 bn: 0.000004 drop: 0.000019 both: 0.000173\n",
      "Train Epoch: 357 [20000/25000 (80%)]\tLosses default: 0.000019 bn: 0.000011 drop: 0.000015 both: 0.000235\n",
      "Train Epoch: 357 [25000/25000 (100%)]\tLosses default: 0.000030 bn: 0.006192 drop: 0.000102 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.1217\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0241\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0533\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0276\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 358 [0/25000 (0%)]\tLosses default: 0.000092 bn: 0.000030 drop: 0.000239 both: 0.000048\n",
      "Train Epoch: 358 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000006 drop: 0.000032 both: 0.000025\n",
      "Train Epoch: 358 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000004 drop: 0.000023 both: 0.000033\n",
      "Train Epoch: 358 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000111 both: 0.000159\n",
      "Test set:\n",
      "default: Loss: 1.1306\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0118\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0500\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0283\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 359 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000115 drop: 0.000070 both: 0.000655\n",
      "Train Epoch: 359 [10000/25000 (40%)]\tLosses default: 0.000048 bn: 0.000039 drop: 0.000011 both: 0.001254\n",
      "Train Epoch: 359 [20000/25000 (80%)]\tLosses default: 0.000009 bn: 0.000007 drop: 0.000008 both: 0.000974\n",
      "Train Epoch: 359 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000052 drop: 0.000025 both: 0.000071\n",
      "Test set:\n",
      "default: Loss: 1.1409\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0509\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.0583\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0388\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 360 [0/25000 (0%)]\tLosses default: 0.000014 bn: 0.000087 drop: 0.000084 both: 0.000401\n",
      "Train Epoch: 360 [10000/25000 (40%)]\tLosses default: 0.000012 bn: 0.000023 drop: 0.000017 both: 0.000013\n",
      "Train Epoch: 360 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.019534 drop: 0.000044 both: 0.018403\n",
      "Train Epoch: 360 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000008 drop: 0.078997 both: 0.000101\n",
      "Test set:\n",
      "default: Loss: 1.1494\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0181\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1018\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0141\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 361 [0/25000 (0%)]\tLosses default: 0.000019 bn: 0.000028 drop: 0.000176 both: 0.000003\n",
      "Train Epoch: 361 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.005457 drop: 0.057096 both: 0.000234\n",
      "Train Epoch: 361 [20000/25000 (80%)]\tLosses default: 0.000024 bn: 0.000780 drop: 0.071570 both: 0.000289\n",
      "Train Epoch: 361 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000044 drop: 0.000333 both: 0.000152\n",
      "Test set:\n",
      "default: Loss: 1.1601\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0290\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0402\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0266\tAccuracy: 4359.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 362 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000203 both: 0.002246\n",
      "Train Epoch: 362 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.000220 drop: 0.000151 both: 0.004658\n",
      "Train Epoch: 362 [20000/25000 (80%)]\tLosses default: 0.000010 bn: 0.000002 drop: 0.000017 both: 0.000102\n",
      "Train Epoch: 362 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000054 drop: 0.000103 both: 0.000143\n",
      "Test set:\n",
      "default: Loss: 1.1706\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0336\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0564\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0182\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 363 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000005 drop: 0.000563 both: 0.000171\n",
      "Train Epoch: 363 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000033 drop: 0.000025 both: 0.000252\n",
      "Train Epoch: 363 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000073 drop: 0.000002 both: 0.002456\n",
      "Train Epoch: 363 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000185 drop: 0.000100 both: 0.000118\n",
      "Test set:\n",
      "default: Loss: 1.1796\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0005\tAccuracy: 4449.0/5000 (89%)\n",
      "drop: Loss: 1.0249\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0398\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 364 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000519 drop: 0.000050 both: 0.006494\n",
      "Train Epoch: 364 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000044 drop: 0.000002 both: 0.000007\n",
      "Train Epoch: 364 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.029381 drop: 0.000003 both: 0.003173\n",
      "Train Epoch: 364 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000067 drop: 0.000008 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.1883\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 0.9918\tAccuracy: 4444.0/5000 (89%)\n",
      "drop: Loss: 1.0455\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0349\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 365 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000110 drop: 0.000042 both: 0.000038\n",
      "Train Epoch: 365 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000011 drop: 0.000011 both: 0.000048\n",
      "Train Epoch: 365 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001870 drop: 0.000009 both: 0.000189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 365 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000072 drop: 0.000051 both: 0.000099\n",
      "Test set:\n",
      "default: Loss: 1.1971\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0243\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.0427\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0382\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 366 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.000006 drop: 0.000022 both: 0.000064\n",
      "Train Epoch: 366 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000041 drop: 0.000023 both: 0.000320\n",
      "Train Epoch: 366 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000019 both: 0.000129\n",
      "Train Epoch: 366 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000000 drop: 0.000003 both: 0.000062\n",
      "Test set:\n",
      "default: Loss: 1.2079\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.0537\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0564\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0392\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 367 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000005 drop: 0.000003 both: 0.000168\n",
      "Train Epoch: 367 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000002 drop: 0.000066 both: 0.000633\n",
      "Train Epoch: 367 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.016275 drop: 0.000006 both: 0.000015\n",
      "Train Epoch: 367 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000046 drop: 0.000133 both: 0.006277\n",
      "Test set:\n",
      "default: Loss: 1.2162\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0701\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.0590\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0043\tAccuracy: 4416.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 368 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000045 drop: 0.000404 both: 0.000003\n",
      "Train Epoch: 368 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.003811 drop: 0.000009 both: 0.000068\n",
      "Train Epoch: 368 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000110 drop: 0.000009 both: 0.000200\n",
      "Train Epoch: 368 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000011 drop: 0.000027 both: 0.000041\n",
      "Test set:\n",
      "default: Loss: 1.2259\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0364\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0439\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0357\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 369 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.037029 drop: 0.000021 both: 0.000009\n",
      "Train Epoch: 369 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000016 both: 0.000535\n",
      "Train Epoch: 369 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000113 drop: 0.025916 both: 0.000064\n",
      "Train Epoch: 369 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000019 drop: 0.000147 both: 0.000040\n",
      "Test set:\n",
      "default: Loss: 1.2339\tAccuracy: 4448.0/5000 (89%)\n",
      "bn: Loss: 1.0324\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0779\tAccuracy: 4345.0/5000 (87%)\n",
      "both: Loss: 1.0442\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 370 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.085585 both: 0.000094\n",
      "Train Epoch: 370 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000087 drop: 0.000039 both: 0.000202\n",
      "Train Epoch: 370 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000155 drop: 0.000118 both: 0.000028\n",
      "Train Epoch: 370 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000024 drop: 0.000026 both: 0.000214\n",
      "Test set:\n",
      "default: Loss: 1.2429\tAccuracy: 4451.0/5000 (89%)\n",
      "bn: Loss: 1.0359\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0476\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 0.9984\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 371 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000002 both: 0.000024\n",
      "Train Epoch: 371 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000135 drop: 0.000180 both: 0.000756\n",
      "Train Epoch: 371 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000009 drop: 0.000018 both: 0.019226\n",
      "Train Epoch: 371 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000130 drop: 0.000679 both: 0.000038\n",
      "Test set:\n",
      "default: Loss: 1.2497\tAccuracy: 4449.0/5000 (89%)\n",
      "bn: Loss: 1.0315\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0528\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.0104\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 372 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000041 drop: 0.000034 both: 0.000128\n",
      "Train Epoch: 372 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000279 both: 0.000062\n",
      "Train Epoch: 372 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000182 drop: 0.000008 both: 0.000067\n",
      "Train Epoch: 372 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000196 drop: 0.001169 both: 0.000124\n",
      "Test set:\n",
      "default: Loss: 1.2577\tAccuracy: 4453.0/5000 (89%)\n",
      "bn: Loss: 1.0666\tAccuracy: 4392.0/5000 (88%)\n",
      "drop: Loss: 1.0618\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0234\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 373 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.010099 drop: 0.000029 both: 0.000035\n",
      "Train Epoch: 373 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000051 drop: 0.000023 both: 0.000088\n",
      "Train Epoch: 373 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000892 drop: 0.000632 both: 0.000936\n",
      "Train Epoch: 373 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000450 drop: 0.000042 both: 0.004687\n",
      "Test set:\n",
      "default: Loss: 1.2653\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0617\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 1.0545\tAccuracy: 4412.0/5000 (88%)\n",
      "both: Loss: 1.0452\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 374 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000039 drop: 0.000021 both: 0.000139\n",
      "Train Epoch: 374 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000023 drop: 0.000116 both: 0.002288\n",
      "Train Epoch: 374 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000264 drop: 0.000008 both: 0.000041\n",
      "Train Epoch: 374 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000468 drop: 0.000018 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.2720\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0713\tAccuracy: 4387.0/5000 (88%)\n",
      "drop: Loss: 1.0717\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.0183\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 375 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000015 both: 0.001941\n",
      "Train Epoch: 375 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000076 drop: 0.000044 both: 0.000004\n",
      "Train Epoch: 375 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000194 drop: 0.000010 both: 0.000043\n",
      "Train Epoch: 375 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000189 drop: 0.000137 both: 0.000192\n",
      "Test set:\n",
      "default: Loss: 1.2787\tAccuracy: 4450.0/5000 (89%)\n",
      "bn: Loss: 1.0453\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.0653\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0294\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 376 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000046 drop: 0.000002 both: 0.000482\n",
      "Train Epoch: 376 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000095 both: 0.015841\n",
      "Train Epoch: 376 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000012 both: 0.000009\n",
      "Train Epoch: 376 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000110 both: 0.000597\n",
      "Test set:\n",
      "default: Loss: 1.2848\tAccuracy: 4450.0/5000 (89%)\n",
      "bn: Loss: 1.0240\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0639\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0257\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 377 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.006853 drop: 0.000004 both: 0.000013\n",
      "Train Epoch: 377 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000074 drop: 0.000006 both: 0.000195\n",
      "Train Epoch: 377 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000034 both: 0.000059\n",
      "Train Epoch: 377 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000078 drop: 0.000054 both: 0.000224\n",
      "Test set:\n",
      "default: Loss: 1.2929\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0725\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0786\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 1.0272\tAccuracy: 4370.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 378 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000171 drop: 0.000032 both: 0.032803\n",
      "Train Epoch: 378 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000366 drop: 0.000039 both: 0.009273\n",
      "Train Epoch: 378 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000096 drop: 0.000016 both: 0.000057\n",
      "Train Epoch: 378 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000089 drop: 0.000008 both: 0.000105\n",
      "Test set:\n",
      "default: Loss: 1.2967\tAccuracy: 4450.0/5000 (89%)\n",
      "bn: Loss: 1.0380\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0692\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0221\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 379 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000729 drop: 0.000038 both: 0.000171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 379 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000076 drop: 0.208829 both: 0.000017\n",
      "Train Epoch: 379 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.004920 drop: 0.004984 both: 0.000370\n",
      "Train Epoch: 379 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000018 drop: 0.000157 both: 0.000161\n",
      "Test set:\n",
      "default: Loss: 1.3038\tAccuracy: 4450.0/5000 (89%)\n",
      "bn: Loss: 1.0759\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.0383\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0274\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 380 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000063 both: 0.000148\n",
      "Train Epoch: 380 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000490 drop: 0.000990 both: 0.000038\n",
      "Train Epoch: 380 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000146 both: 0.006732\n",
      "Train Epoch: 380 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000090 drop: 0.000034 both: 0.000068\n",
      "Test set:\n",
      "default: Loss: 1.3108\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0501\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.0528\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0245\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 381 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000016 both: 0.000025\n",
      "Train Epoch: 381 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000271 drop: 0.000017 both: 0.001384\n",
      "Train Epoch: 381 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001222 drop: 0.000010 both: 0.000085\n",
      "Train Epoch: 381 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000089 drop: 0.001311 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.3154\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.0381\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.0471\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0296\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 382 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000495 drop: 0.000216 both: 0.000036\n",
      "Train Epoch: 382 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000213 both: 0.000110\n",
      "Train Epoch: 382 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.076943 drop: 0.000036 both: 0.000196\n",
      "Train Epoch: 382 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000059 both: 0.000046\n",
      "Test set:\n",
      "default: Loss: 1.3211\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0350\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0434\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 0.9909\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 383 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000067 drop: 0.000002 both: 0.000002\n",
      "Train Epoch: 383 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.002118 drop: 0.000059 both: 0.000016\n",
      "Train Epoch: 383 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.004933 drop: 0.000037 both: 0.004008\n",
      "Train Epoch: 383 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000071 both: 0.027683\n",
      "Test set:\n",
      "default: Loss: 1.3273\tAccuracy: 4449.0/5000 (89%)\n",
      "bn: Loss: 1.0217\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0480\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0088\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 384 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000014 both: 0.000049\n",
      "Train Epoch: 384 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000090 drop: 0.000003 both: 0.000064\n",
      "Train Epoch: 384 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000051 both: 0.000318\n",
      "Train Epoch: 384 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001786 drop: 0.000011 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.3337\tAccuracy: 4451.0/5000 (89%)\n",
      "bn: Loss: 1.0530\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.0653\tAccuracy: 4366.0/5000 (87%)\n",
      "both: Loss: 1.0092\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 385 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000005 both: 0.000074\n",
      "Train Epoch: 385 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000248 drop: 0.000007 both: 0.018012\n",
      "Train Epoch: 385 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.003844 drop: 0.000011 both: 0.000025\n",
      "Train Epoch: 385 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000043 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.3382\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 0.9934\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.0494\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0589\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 386 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000008 both: 0.000020\n",
      "Train Epoch: 386 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000001 both: 0.000158\n",
      "Train Epoch: 386 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000003 both: 0.000244\n",
      "Train Epoch: 386 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000100 drop: 0.000010 both: 0.000051\n",
      "Test set:\n",
      "default: Loss: 1.3421\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 0.9910\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0556\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0208\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 387 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000161 drop: 0.000014 both: 0.000294\n",
      "Train Epoch: 387 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000650 drop: 0.000004 both: 0.000008\n",
      "Train Epoch: 387 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.013668 drop: 0.000085 both: 0.000031\n",
      "Train Epoch: 387 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000004 both: 0.000043\n",
      "Test set:\n",
      "default: Loss: 1.3494\tAccuracy: 4449.0/5000 (89%)\n",
      "bn: Loss: 1.0054\tAccuracy: 4442.0/5000 (89%)\n",
      "drop: Loss: 1.0643\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0423\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 388 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000056 drop: 0.000019 both: 0.000010\n",
      "Train Epoch: 388 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000341 drop: 0.000048 both: 0.012256\n",
      "Train Epoch: 388 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000002 both: 0.000023\n",
      "Train Epoch: 388 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000022 both: 0.000106\n",
      "Test set:\n",
      "default: Loss: 1.3551\tAccuracy: 4449.0/5000 (89%)\n",
      "bn: Loss: 1.0003\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.0628\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0360\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 389 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000011 both: 0.000047\n",
      "Train Epoch: 389 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000005 both: 0.000204\n",
      "Train Epoch: 389 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.011761 drop: 0.000015 both: 0.000024\n",
      "Train Epoch: 389 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000006 both: 0.000531\n",
      "Test set:\n",
      "default: Loss: 1.3546\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0086\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.0826\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0281\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 390 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000014 both: 0.000703\n",
      "Train Epoch: 390 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000140 both: 0.000016\n",
      "Train Epoch: 390 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000007 both: 0.000022\n",
      "Train Epoch: 390 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000013 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3606\tAccuracy: 4451.0/5000 (89%)\n",
      "bn: Loss: 1.0268\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0893\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0274\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 391 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000006 both: 0.000003\n",
      "Train Epoch: 391 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.012472 drop: 0.000008 both: 0.000061\n",
      "Train Epoch: 391 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001474 drop: 0.000009 both: 0.000060\n",
      "Train Epoch: 391 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000055 drop: 0.000007 both: 0.000100\n",
      "Test set:\n",
      "default: Loss: 1.3617\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.0175\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0675\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0310\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 392 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000125 drop: 0.000003 both: 0.000709\n",
      "Train Epoch: 392 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000087 drop: 0.002138 both: 0.000036\n",
      "Train Epoch: 392 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000094 drop: 0.002488 both: 0.007041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 392 [25000/25000 (100%)]\tLosses default: 0.027963 bn: 0.000047 drop: 0.012830 both: 0.000035\n",
      "Test set:\n",
      "default: Loss: 1.3310\tAccuracy: 4346.0/5000 (87%)\n",
      "bn: Loss: 1.0019\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0277\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.0441\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 393 [0/25000 (0%)]\tLosses default: 0.031706 bn: 0.000444 drop: 0.000374 both: 0.000212\n",
      "Train Epoch: 393 [10000/25000 (40%)]\tLosses default: 0.000202 bn: 0.000052 drop: 0.000549 both: 0.000283\n",
      "Train Epoch: 393 [20000/25000 (80%)]\tLosses default: 0.000138 bn: 0.000299 drop: 0.000230 both: 0.000155\n",
      "Train Epoch: 393 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000010 drop: 0.000037 both: 0.000154\n",
      "Test set:\n",
      "default: Loss: 1.0873\tAccuracy: 4404.0/5000 (88%)\n",
      "bn: Loss: 0.9831\tAccuracy: 4445.0/5000 (89%)\n",
      "drop: Loss: 1.0149\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0476\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 394 [0/25000 (0%)]\tLosses default: 0.001142 bn: 0.000066 drop: 0.000287 both: 0.000079\n",
      "Train Epoch: 394 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000011 drop: 0.000010 both: 0.000005\n",
      "Train Epoch: 394 [20000/25000 (80%)]\tLosses default: 0.007970 bn: 0.000024 drop: 0.000012 both: 0.010435\n",
      "Train Epoch: 394 [25000/25000 (100%)]\tLosses default: 0.000126 bn: 0.000304 drop: 0.000069 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.0775\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0066\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.0151\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0325\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 395 [0/25000 (0%)]\tLosses default: 0.000695 bn: 0.000011 drop: 0.000051 both: 0.000092\n",
      "Train Epoch: 395 [10000/25000 (40%)]\tLosses default: 0.000024 bn: 0.000480 drop: 0.000041 both: 0.005210\n",
      "Train Epoch: 395 [20000/25000 (80%)]\tLosses default: 0.000065 bn: 0.000012 drop: 0.003462 both: 0.000014\n",
      "Train Epoch: 395 [25000/25000 (100%)]\tLosses default: 0.001088 bn: 0.000040 drop: 0.000304 both: 0.000114\n",
      "Test set:\n",
      "default: Loss: 1.1237\tAccuracy: 4398.0/5000 (88%)\n",
      "bn: Loss: 0.9819\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0240\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.0478\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 396 [0/25000 (0%)]\tLosses default: 0.125973 bn: 0.000017 drop: 0.000112 both: 0.001412\n",
      "Train Epoch: 396 [10000/25000 (40%)]\tLosses default: 0.000591 bn: 0.000626 drop: 0.000019 both: 0.000788\n",
      "Train Epoch: 396 [20000/25000 (80%)]\tLosses default: 0.000232 bn: 0.000040 drop: 0.000030 both: 0.011301\n",
      "Train Epoch: 396 [25000/25000 (100%)]\tLosses default: 0.000046 bn: 0.000825 drop: 0.000004 both: 0.000064\n",
      "Test set:\n",
      "default: Loss: 1.1879\tAccuracy: 4360.0/5000 (87%)\n",
      "bn: Loss: 1.0541\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0429\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0179\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 397 [0/25000 (0%)]\tLosses default: 0.000116 bn: 0.000168 drop: 0.000013 both: 0.000713\n",
      "Train Epoch: 397 [10000/25000 (40%)]\tLosses default: 0.000139 bn: 0.000218 drop: 0.000152 both: 0.002348\n",
      "Train Epoch: 397 [20000/25000 (80%)]\tLosses default: 0.000623 bn: 0.000010 drop: 0.000070 both: 0.000009\n",
      "Train Epoch: 397 [25000/25000 (100%)]\tLosses default: 0.037834 bn: 0.000002 drop: 0.000016 both: 0.000033\n",
      "Test set:\n",
      "default: Loss: 1.1009\tAccuracy: 4401.0/5000 (88%)\n",
      "bn: Loss: 1.0243\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0890\tAccuracy: 4356.0/5000 (87%)\n",
      "both: Loss: 0.9958\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 398 [0/25000 (0%)]\tLosses default: 0.007562 bn: 0.003213 drop: 0.000018 both: 0.000049\n",
      "Train Epoch: 398 [10000/25000 (40%)]\tLosses default: 0.000028 bn: 0.000021 drop: 0.000028 both: 0.000009\n",
      "Train Epoch: 398 [20000/25000 (80%)]\tLosses default: 0.041578 bn: 0.000528 drop: 0.000315 both: 0.002573\n",
      "Train Epoch: 398 [25000/25000 (100%)]\tLosses default: 0.000221 bn: 0.020029 drop: 0.000146 both: 0.000477\n",
      "Test set:\n",
      "default: Loss: 1.1156\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0336\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0623\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0355\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 399 [0/25000 (0%)]\tLosses default: 0.002051 bn: 0.000826 drop: 0.000017 both: 0.000054\n",
      "Train Epoch: 399 [10000/25000 (40%)]\tLosses default: 0.000501 bn: 0.001474 drop: 0.000395 both: 0.023675\n",
      "Train Epoch: 399 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000502 drop: 0.000015 both: 0.000067\n",
      "Train Epoch: 399 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000002 drop: 0.000024 both: 0.000024\n",
      "Test set:\n",
      "default: Loss: 1.1278\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0412\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0293\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0281\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 400 [0/25000 (0%)]\tLosses default: 0.000018 bn: 0.012355 drop: 0.000011 both: 0.000030\n",
      "Train Epoch: 400 [10000/25000 (40%)]\tLosses default: 0.000037 bn: 0.000011 drop: 0.000002 both: 0.000271\n",
      "Train Epoch: 400 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000052 drop: 0.000007 both: 0.003770\n",
      "Train Epoch: 400 [25000/25000 (100%)]\tLosses default: 0.000082 bn: 0.000007 drop: 0.000028 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.1230\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0424\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0395\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0302\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 401 [0/25000 (0%)]\tLosses default: 0.000041 bn: 0.000068 drop: 0.000274 both: 0.000138\n",
      "Train Epoch: 401 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000018 drop: 0.000010 both: 0.001714\n",
      "Train Epoch: 401 [20000/25000 (80%)]\tLosses default: 0.000013 bn: 0.000039 drop: 0.000007 both: 0.000018\n",
      "Train Epoch: 401 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000192 drop: 0.000078 both: 0.000151\n",
      "Test set:\n",
      "default: Loss: 1.1233\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0118\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0523\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0193\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 402 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000297 drop: 0.000059 both: 0.000032\n",
      "Train Epoch: 402 [10000/25000 (40%)]\tLosses default: 0.000014 bn: 0.000009 drop: 0.000020 both: 0.000027\n",
      "Train Epoch: 402 [20000/25000 (80%)]\tLosses default: 0.000078 bn: 0.000066 drop: 0.002416 both: 0.000497\n",
      "Train Epoch: 402 [25000/25000 (100%)]\tLosses default: 0.000055 bn: 0.007176 drop: 0.011560 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.1278\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0231\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1514\tAccuracy: 4291.0/5000 (86%)\n",
      "both: Loss: 1.0696\tAccuracy: 4356.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 403 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000071 drop: 0.206678 both: 0.000058\n",
      "Train Epoch: 403 [10000/25000 (40%)]\tLosses default: 0.000021 bn: 0.000012 drop: 0.007346 both: 0.000055\n",
      "Train Epoch: 403 [20000/25000 (80%)]\tLosses default: 0.000016 bn: 0.000008 drop: 0.000055 both: 0.000065\n",
      "Train Epoch: 403 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000048 both: 0.000025\n",
      "Test set:\n",
      "default: Loss: 1.1323\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0264\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.0082\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0404\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 404 [0/25000 (0%)]\tLosses default: 0.000016 bn: 0.001108 drop: 0.000062 both: 0.000157\n",
      "Train Epoch: 404 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000029 drop: 0.007677 both: 0.002034\n",
      "Train Epoch: 404 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000029 drop: 0.000093 both: 0.000248\n",
      "Train Epoch: 404 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000095 drop: 0.006713 both: 0.000045\n",
      "Test set:\n",
      "default: Loss: 1.1381\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0248\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0544\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0323\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 405 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000104 drop: 0.000094 both: 0.000069\n",
      "Train Epoch: 405 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000033 drop: 0.000067 both: 0.000003\n",
      "Train Epoch: 405 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000050 drop: 0.001495 both: 0.003802\n",
      "Train Epoch: 405 [25000/25000 (100%)]\tLosses default: 0.000057 bn: 0.000004 drop: 0.000052 both: 0.014197\n",
      "Test set:\n",
      "default: Loss: 1.1444\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0195\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0089\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0404\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 406 [0/25000 (0%)]\tLosses default: 0.000040 bn: 0.000011 drop: 0.004124 both: 0.007724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 406 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000019 drop: 0.000029 both: 0.000009\n",
      "Train Epoch: 406 [20000/25000 (80%)]\tLosses default: 0.000031 bn: 0.000015 drop: 0.000026 both: 0.000072\n",
      "Train Epoch: 406 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000042 both: 0.000038\n",
      "Test set:\n",
      "default: Loss: 1.1516\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9973\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0436\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0007\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 407 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.000106 drop: 0.000051 both: 0.005818\n",
      "Train Epoch: 407 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000005 drop: 0.000033 both: 0.002298\n",
      "Train Epoch: 407 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000055 drop: 0.000097 both: 0.000210\n",
      "Train Epoch: 407 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000020 both: 0.000243\n",
      "Test set:\n",
      "default: Loss: 1.1576\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 0.9955\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0255\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0100\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 408 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.002782 drop: 0.000002 both: 0.000003\n",
      "Train Epoch: 408 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000030 both: 0.000160\n",
      "Train Epoch: 408 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.001929 drop: 0.000010 both: 0.000028\n",
      "Train Epoch: 408 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.126776 drop: 0.006065 both: 0.000507\n",
      "Test set:\n",
      "default: Loss: 1.1646\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0458\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0831\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0133\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 409 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.003200 drop: 0.000077 both: 0.000025\n",
      "Train Epoch: 409 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000091 drop: 0.000148 both: 0.000023\n",
      "Train Epoch: 409 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000052 drop: 0.000026 both: 0.000072\n",
      "Train Epoch: 409 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000157 drop: 0.000061 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.1722\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 0.9951\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 1.0401\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0344\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 410 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000046 drop: 0.000133 both: 0.000021\n",
      "Train Epoch: 410 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.008102 drop: 0.000007 both: 0.000012\n",
      "Train Epoch: 410 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000987 drop: 0.000068 both: 0.028977\n",
      "Train Epoch: 410 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001024 drop: 0.000011 both: 0.000060\n",
      "Test set:\n",
      "default: Loss: 1.1795\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 0.9815\tAccuracy: 4449.0/5000 (89%)\n",
      "drop: Loss: 1.0260\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0320\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 411 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000135 both: 0.009316\n",
      "Train Epoch: 411 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000011 drop: 0.000126 both: 0.000085\n",
      "Train Epoch: 411 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000044 drop: 0.000024 both: 0.000019\n",
      "Train Epoch: 411 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000020 drop: 0.000012 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1867\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 0.9986\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.0312\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0119\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 412 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000018 drop: 0.000007 both: 0.000476\n",
      "Train Epoch: 412 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000037 drop: 0.000006 both: 0.002320\n",
      "Train Epoch: 412 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000199 both: 0.000013\n",
      "Train Epoch: 412 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000009 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.1952\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0117\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0286\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0209\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 413 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.003339 drop: 0.000012 both: 0.000011\n",
      "Train Epoch: 413 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000018 drop: 0.000438 both: 0.000008\n",
      "Train Epoch: 413 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.028977 drop: 0.000240 both: 0.087426\n",
      "Train Epoch: 413 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000083 drop: 0.000008 both: 0.000768\n",
      "Test set:\n",
      "default: Loss: 1.2028\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0173\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0365\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0353\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 414 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000019 drop: 0.000199 both: 0.003896\n",
      "Train Epoch: 414 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000106 drop: 0.000004 both: 0.000013\n",
      "Train Epoch: 414 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000170 drop: 0.000044 both: 0.010947\n",
      "Train Epoch: 414 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000060 both: 0.201797\n",
      "Test set:\n",
      "default: Loss: 1.2103\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0442\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0340\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0560\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 415 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000086 drop: 0.000012 both: 0.000047\n",
      "Train Epoch: 415 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000019 drop: 0.000022 both: 0.003234\n",
      "Train Epoch: 415 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.003369 drop: 0.000025 both: 0.000118\n",
      "Train Epoch: 415 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000032 drop: 0.000018 both: 0.000162\n",
      "Test set:\n",
      "default: Loss: 1.2193\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0312\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.0476\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0437\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 416 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.002019 drop: 0.000007 both: 0.000337\n",
      "Train Epoch: 416 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000032 both: 0.000016\n",
      "Train Epoch: 416 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000006 both: 0.000147\n",
      "Train Epoch: 416 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000083 drop: 0.000043 both: 0.000071\n",
      "Test set:\n",
      "default: Loss: 1.2268\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0417\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0469\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 0.9967\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 417 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000099 drop: 0.000005 both: 0.003302\n",
      "Train Epoch: 417 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000010 drop: 0.000021 both: 0.000106\n",
      "Train Epoch: 417 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000021 both: 0.000017\n",
      "Train Epoch: 417 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000070 drop: 0.000002 both: 0.001287\n",
      "Test set:\n",
      "default: Loss: 1.2334\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0382\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0450\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0188\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 418 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000130 drop: 0.000064 both: 0.000060\n",
      "Train Epoch: 418 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000697 drop: 0.000004 both: 0.001002\n",
      "Train Epoch: 418 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.005517 drop: 0.000004 both: 0.000192\n",
      "Train Epoch: 418 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000032 drop: 0.000016 both: 0.000175\n",
      "Test set:\n",
      "default: Loss: 1.2418\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0346\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.0540\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0359\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 419 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000034 drop: 0.000021 both: 0.000005\n",
      "Train Epoch: 419 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000005 both: 0.000497\n",
      "Train Epoch: 419 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000033 drop: 0.000012 both: 0.000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 419 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000021 drop: 0.000005 both: 0.000068\n",
      "Test set:\n",
      "default: Loss: 1.2493\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0003\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 1.0535\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0679\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 420 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000020 drop: 0.000089 both: 0.000328\n",
      "Train Epoch: 420 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000029 both: 0.000299\n",
      "Train Epoch: 420 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000013 both: 0.000008\n",
      "Train Epoch: 420 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000319 drop: 0.000008 both: 0.000068\n",
      "Test set:\n",
      "default: Loss: 1.2575\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0256\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.0711\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.1049\tAccuracy: 4355.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 421 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.012946 drop: 0.000281 both: 0.000173\n",
      "Train Epoch: 421 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000002 both: 0.000008\n",
      "Train Epoch: 421 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001103 drop: 0.000022 both: 0.001713\n",
      "Train Epoch: 421 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000566 drop: 0.000010 both: 0.000231\n",
      "Test set:\n",
      "default: Loss: 1.2636\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0773\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.0769\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0695\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 422 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000030 both: 0.000006\n",
      "Train Epoch: 422 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000063 both: 0.000284\n",
      "Train Epoch: 422 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000195 drop: 0.005610 both: 0.000413\n",
      "Train Epoch: 422 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000152 drop: 0.012519 both: 0.000023\n",
      "Test set:\n",
      "default: Loss: 1.2708\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0899\tAccuracy: 4397.0/5000 (88%)\n",
      "drop: Loss: 1.0051\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0381\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 423 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000046 drop: 0.000035 both: 0.000089\n",
      "Train Epoch: 423 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000098 drop: 0.000036 both: 0.000017\n",
      "Train Epoch: 423 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000016 drop: 0.001404 both: 0.000047\n",
      "Train Epoch: 423 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000107 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.2777\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 0.9714\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.0013\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0539\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 424 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000477 both: 0.000024\n",
      "Train Epoch: 424 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000103 both: 0.000081\n",
      "Train Epoch: 424 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.033154 both: 0.000007\n",
      "Train Epoch: 424 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000053 both: 0.000117\n",
      "Test set:\n",
      "default: Loss: 1.2848\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0055\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0404\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0408\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 425 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.009806 both: 0.000011\n",
      "Train Epoch: 425 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000095 drop: 0.000085 both: 0.000034\n",
      "Train Epoch: 425 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000007 both: 0.000011\n",
      "Train Epoch: 425 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000635 drop: 0.000011 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2921\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 0.9666\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 1.0281\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0311\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 426 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000077 both: 0.000021\n",
      "Train Epoch: 426 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000019 both: 0.000096\n",
      "Train Epoch: 426 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000089 both: 0.046599\n",
      "Train Epoch: 426 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000078 drop: 0.000038 both: 0.000084\n",
      "Test set:\n",
      "default: Loss: 1.2980\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0032\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0615\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0121\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 427 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000032 both: 0.000007\n",
      "Train Epoch: 427 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000276 both: 0.000006\n",
      "Train Epoch: 427 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000736\n",
      "Train Epoch: 427 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.001416 both: 0.000120\n",
      "Test set:\n",
      "default: Loss: 1.3033\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0326\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0541\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0438\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 428 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.112373 both: 0.000008\n",
      "Train Epoch: 428 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000064 both: 0.000471\n",
      "Train Epoch: 428 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000592 drop: 0.000163 both: 0.000783\n",
      "Train Epoch: 428 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000068 both: 0.000993\n",
      "Test set:\n",
      "default: Loss: 1.3104\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0453\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.0327\tAccuracy: 4372.0/5000 (87%)\n",
      "both: Loss: 1.0587\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 429 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000053 drop: 0.004361 both: 0.037223\n",
      "Train Epoch: 429 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.004929 drop: 0.000004 both: 0.001335\n",
      "Train Epoch: 429 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000666 drop: 0.000154 both: 0.019360\n",
      "Train Epoch: 429 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000008 both: 0.000044\n",
      "Test set:\n",
      "default: Loss: 1.3159\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0268\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0785\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0127\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 430 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000071 both: 0.000027\n",
      "Train Epoch: 430 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000005 both: 0.000066\n",
      "Train Epoch: 430 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000004 both: 0.000011\n",
      "Train Epoch: 430 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000511 drop: 0.000016 both: 0.000728\n",
      "Test set:\n",
      "default: Loss: 1.3224\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0569\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0690\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0148\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 431 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000107 drop: 0.000030 both: 0.000082\n",
      "Train Epoch: 431 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000070 drop: 0.000008 both: 0.000019\n",
      "Train Epoch: 431 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000034 both: 0.000046\n",
      "Train Epoch: 431 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000154 drop: 0.000074 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3286\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0256\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.0638\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0554\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 432 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000013 both: 0.000006\n",
      "Train Epoch: 432 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000027 both: 0.000014\n",
      "Train Epoch: 432 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000005 both: 0.000010\n",
      "Train Epoch: 432 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000148 drop: 0.000036 both: 0.000611\n",
      "Test set:\n",
      "default: Loss: 1.3342\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0416\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.0801\tAccuracy: 4367.0/5000 (87%)\n",
      "both: Loss: 1.0383\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 433 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000004 both: 0.000082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 433 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000180 drop: 0.007340 both: 0.000029\n",
      "Train Epoch: 433 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.004600 drop: 0.001444 both: 0.000234\n",
      "Train Epoch: 433 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000106 both: 0.001546\n",
      "Test set:\n",
      "default: Loss: 1.3392\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0552\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.0664\tAccuracy: 4355.0/5000 (87%)\n",
      "both: Loss: 1.0947\tAccuracy: 4370.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 434 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000302 both: 0.000081\n",
      "Train Epoch: 434 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000347 drop: 0.000626 both: 0.000585\n",
      "Train Epoch: 434 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000073 drop: 0.000046 both: 0.000011\n",
      "Train Epoch: 434 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000045 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3434\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0255\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0285\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0481\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 435 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000136 both: 0.004266\n",
      "Train Epoch: 435 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000066 both: 0.000571\n",
      "Train Epoch: 435 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000082 drop: 0.000044 both: 0.025848\n",
      "Train Epoch: 435 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000022 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3448\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0517\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.0695\tAccuracy: 4357.0/5000 (87%)\n",
      "both: Loss: 1.0452\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 436 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.004627 drop: 0.073819 both: 0.000154\n",
      "Train Epoch: 436 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000106 both: 0.000007\n",
      "Train Epoch: 436 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000047 both: 0.000245\n",
      "Train Epoch: 436 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.009845 drop: 0.001163 both: 0.001104\n",
      "Test set:\n",
      "default: Loss: 1.3504\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0282\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0251\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0446\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 437 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000113 both: 0.000003\n",
      "Train Epoch: 437 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000061 both: 0.000060\n",
      "Train Epoch: 437 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000028 both: 0.000005\n",
      "Train Epoch: 437 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.011374 drop: 0.000282 both: 0.001350\n",
      "Test set:\n",
      "default: Loss: 1.3519\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0418\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.0503\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0547\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 438 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000195 both: 0.000943\n",
      "Train Epoch: 438 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000091 drop: 0.000039 both: 0.000149\n",
      "Train Epoch: 438 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.007596 drop: 0.000063 both: 0.000227\n",
      "Train Epoch: 438 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.056490 drop: 0.000043 both: 0.002036\n",
      "Test set:\n",
      "default: Loss: 1.3568\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0285\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.0422\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0426\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 439 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000175 drop: 0.000010 both: 0.000240\n",
      "Train Epoch: 439 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000070 drop: 0.000077 both: 0.006786\n",
      "Train Epoch: 439 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.069187 drop: 0.000066 both: 0.000352\n",
      "Train Epoch: 439 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000057 both: 0.009754\n",
      "Test set:\n",
      "default: Loss: 1.3600\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0093\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.0340\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0757\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 440 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.001977 both: 0.066226\n",
      "Train Epoch: 440 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000474 drop: 0.000575 both: 0.000379\n",
      "Train Epoch: 440 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000094 both: 0.000005\n",
      "Train Epoch: 440 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000087 drop: 0.000033 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.3611\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0101\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 1.0275\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0568\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 441 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000853 drop: 0.000025 both: 0.000123\n",
      "Train Epoch: 441 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000031 both: 0.000114\n",
      "Train Epoch: 441 [20000/25000 (80%)]\tLosses default: 0.120600 bn: 0.001512 drop: 0.000030 both: 0.000052\n",
      "Train Epoch: 441 [25000/25000 (100%)]\tLosses default: 0.370865 bn: 0.000002 drop: 0.000013 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.0310\tAccuracy: 4392.0/5000 (88%)\n",
      "bn: Loss: 1.0161\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.0174\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 1.0544\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 442 [0/25000 (0%)]\tLosses default: 0.011445 bn: 0.000031 drop: 0.000047 both: 0.000026\n",
      "Train Epoch: 442 [10000/25000 (40%)]\tLosses default: 0.000722 bn: 0.000020 drop: 0.000006 both: 0.000013\n",
      "Train Epoch: 442 [20000/25000 (80%)]\tLosses default: 0.200100 bn: 0.000002 drop: 0.000004 both: 0.000241\n",
      "Train Epoch: 442 [25000/25000 (100%)]\tLosses default: 0.000322 bn: 0.000049 drop: 0.000170 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.0846\tAccuracy: 4404.0/5000 (88%)\n",
      "bn: Loss: 1.0368\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 0.9957\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0472\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 443 [0/25000 (0%)]\tLosses default: 0.192120 bn: 0.000015 drop: 0.000065 both: 0.000023\n",
      "Train Epoch: 443 [10000/25000 (40%)]\tLosses default: 0.000354 bn: 0.000012 drop: 0.000088 both: 0.000026\n",
      "Train Epoch: 443 [20000/25000 (80%)]\tLosses default: 0.000121 bn: 0.001539 drop: 0.000060 both: 0.000129\n",
      "Train Epoch: 443 [25000/25000 (100%)]\tLosses default: 0.001492 bn: 0.000002 drop: 0.000021 both: 0.000839\n",
      "Test set:\n",
      "default: Loss: 1.1279\tAccuracy: 4402.0/5000 (88%)\n",
      "bn: Loss: 1.0114\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0248\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.0474\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 444 [0/25000 (0%)]\tLosses default: 0.000603 bn: 0.000052 drop: 0.000195 both: 0.000033\n",
      "Train Epoch: 444 [10000/25000 (40%)]\tLosses default: 0.000664 bn: 0.000004 drop: 0.000055 both: 0.004921\n",
      "Train Epoch: 444 [20000/25000 (80%)]\tLosses default: 0.000084 bn: 0.000081 drop: 0.000003 both: 0.000022\n",
      "Train Epoch: 444 [25000/25000 (100%)]\tLosses default: 0.001461 bn: 0.000089 drop: 0.000055 both: 0.022585\n",
      "Test set:\n",
      "default: Loss: 1.1659\tAccuracy: 4396.0/5000 (88%)\n",
      "bn: Loss: 1.0183\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0233\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0821\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 445 [0/25000 (0%)]\tLosses default: 0.012062 bn: 0.000040 drop: 0.000024 both: 0.000058\n",
      "Train Epoch: 445 [10000/25000 (40%)]\tLosses default: 0.024892 bn: 0.000002 drop: 0.000013 both: 0.007011\n",
      "Train Epoch: 445 [20000/25000 (80%)]\tLosses default: 0.004924 bn: 0.000698 drop: 0.000004 both: 0.000059\n",
      "Train Epoch: 445 [25000/25000 (100%)]\tLosses default: 0.056270 bn: 0.000021 drop: 0.001726 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.3013\tAccuracy: 4359.0/5000 (87%)\n",
      "bn: Loss: 1.0206\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0329\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0571\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 446 [0/25000 (0%)]\tLosses default: 0.102428 bn: 0.000058 drop: 0.000018 both: 0.000017\n",
      "Train Epoch: 446 [10000/25000 (40%)]\tLosses default: 0.000289 bn: 0.000106 drop: 0.071909 both: 0.000349\n",
      "Train Epoch: 446 [20000/25000 (80%)]\tLosses default: 0.002186 bn: 0.000220 drop: 0.015984 both: 0.000342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 446 [25000/25000 (100%)]\tLosses default: 0.000107 bn: 0.000105 drop: 0.000817 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.1094\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.0449\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0309\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.0298\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 447 [0/25000 (0%)]\tLosses default: 0.000143 bn: 0.017020 drop: 0.000037 both: 0.000596\n",
      "Train Epoch: 447 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000001 drop: 0.000129 both: 0.000009\n",
      "Train Epoch: 447 [20000/25000 (80%)]\tLosses default: 0.000236 bn: 0.000030 drop: 0.004525 both: 0.001153\n",
      "Train Epoch: 447 [25000/25000 (100%)]\tLosses default: 0.000275 bn: 0.000208 drop: 0.000025 both: 0.000865\n",
      "Test set:\n",
      "default: Loss: 1.1218\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0304\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0556\tAccuracy: 4361.0/5000 (87%)\n",
      "both: Loss: 1.0241\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 448 [0/25000 (0%)]\tLosses default: 0.000064 bn: 0.000037 drop: 0.000080 both: 0.000195\n",
      "Train Epoch: 448 [10000/25000 (40%)]\tLosses default: 0.000014 bn: 0.000027 drop: 0.000038 both: 0.000029\n",
      "Train Epoch: 448 [20000/25000 (80%)]\tLosses default: 0.000036 bn: 0.000091 drop: 0.000031 both: 0.000021\n",
      "Train Epoch: 448 [25000/25000 (100%)]\tLosses default: 0.000033 bn: 0.018217 drop: 0.000759 both: 0.000361\n",
      "Test set:\n",
      "default: Loss: 1.1306\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.0246\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.0304\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0113\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 449 [0/25000 (0%)]\tLosses default: 0.000052 bn: 0.000004 drop: 0.000005 both: 0.000359\n",
      "Train Epoch: 449 [10000/25000 (40%)]\tLosses default: 0.000024 bn: 0.000206 drop: 0.000032 both: 0.006714\n",
      "Train Epoch: 449 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000010 drop: 0.000020 both: 0.000324\n",
      "Train Epoch: 449 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000281 drop: 0.000037 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1404\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0785\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0704\tAccuracy: 4366.0/5000 (87%)\n",
      "both: Loss: 1.0257\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 450 [0/25000 (0%)]\tLosses default: 0.000051 bn: 0.000116 drop: 0.000098 both: 0.000009\n",
      "Train Epoch: 450 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000013 drop: 0.000213 both: 0.000071\n",
      "Train Epoch: 450 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.006131 both: 0.000076\n",
      "Train Epoch: 450 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000032 drop: 0.000034 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.1508\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0808\tAccuracy: 4393.0/5000 (88%)\n",
      "drop: Loss: 1.0584\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0299\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 451 [0/25000 (0%)]\tLosses default: 0.000018 bn: 0.000187 drop: 0.000414 both: 0.000062\n",
      "Train Epoch: 451 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000004 drop: 0.000436 both: 0.000229\n",
      "Train Epoch: 451 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000192 drop: 0.000008 both: 0.000007\n",
      "Train Epoch: 451 [25000/25000 (100%)]\tLosses default: 0.000018 bn: 0.000004 drop: 0.000447 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.1597\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0691\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0312\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0526\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 452 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.000054 drop: 0.000178 both: 0.003316\n",
      "Train Epoch: 452 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000085 drop: 0.000042 both: 0.000037\n",
      "Train Epoch: 452 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000003 drop: 0.000181 both: 0.006145\n",
      "Train Epoch: 452 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000061 drop: 0.000012 both: 0.000261\n",
      "Test set:\n",
      "default: Loss: 1.1695\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0563\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.0285\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0592\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 453 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.000054 both: 0.000046\n",
      "Train Epoch: 453 [10000/25000 (40%)]\tLosses default: 0.000023 bn: 0.000029 drop: 0.000033 both: 0.003961\n",
      "Train Epoch: 453 [20000/25000 (80%)]\tLosses default: 0.000014 bn: 0.000004 drop: 0.000027 both: 0.000005\n",
      "Train Epoch: 453 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000875 drop: 0.000010 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.1780\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0812\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.0251\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0923\tAccuracy: 4351.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 454 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.000352 drop: 0.000015 both: 0.000171\n",
      "Train Epoch: 454 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000018 drop: 0.000035 both: 0.000199\n",
      "Train Epoch: 454 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000018 drop: 0.000013 both: 0.000020\n",
      "Train Epoch: 454 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000058 drop: 0.000025 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.1871\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0391\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.0227\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0738\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 455 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000020 both: 0.000108\n",
      "Train Epoch: 455 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000045 both: 0.000021\n",
      "Train Epoch: 455 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000880 drop: 0.000014 both: 0.004394\n",
      "Train Epoch: 455 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000001 drop: 0.000004 both: 0.000030\n",
      "Test set:\n",
      "default: Loss: 1.1953\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0242\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0328\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0545\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 456 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000124 drop: 0.000031 both: 0.000038\n",
      "Train Epoch: 456 [10000/25000 (40%)]\tLosses default: 0.000016 bn: 0.000014 drop: 0.000017 both: 0.002788\n",
      "Train Epoch: 456 [20000/25000 (80%)]\tLosses default: 0.000010 bn: 0.000041 drop: 0.000022 both: 0.000022\n",
      "Train Epoch: 456 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.001568 drop: 0.000011 both: 0.002886\n",
      "Test set:\n",
      "default: Loss: 1.2026\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0281\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.0239\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0892\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 457 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000100 drop: 0.000001 both: 0.000085\n",
      "Train Epoch: 457 [10000/25000 (40%)]\tLosses default: 0.000012 bn: 0.000090 drop: 0.000191 both: 0.000027\n",
      "Train Epoch: 457 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000019 drop: 0.000017 both: 0.001239\n",
      "Train Epoch: 457 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.003985 both: 0.000162\n",
      "Test set:\n",
      "default: Loss: 1.2118\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0345\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1806\tAccuracy: 4316.0/5000 (86%)\n",
      "both: Loss: 1.0425\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 458 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.002815 drop: 0.005953 both: 0.000006\n",
      "Train Epoch: 458 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.003278 drop: 0.000260 both: 0.000373\n",
      "Train Epoch: 458 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000011 drop: 0.000069 both: 0.005100\n",
      "Train Epoch: 458 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000083 drop: 0.000292 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.2205\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0414\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0425\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0514\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 459 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.003880 drop: 0.000020 both: 0.005214\n",
      "Train Epoch: 459 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000164 drop: 0.000039 both: 0.000084\n",
      "Train Epoch: 459 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000132 both: 0.000192\n",
      "Train Epoch: 459 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000030 drop: 0.000101 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.2277\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0433\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1026\tAccuracy: 4362.0/5000 (87%)\n",
      "both: Loss: 1.0194\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 460 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.003019 both: 0.000169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 460 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000011 drop: 0.000009 both: 0.000010\n",
      "Train Epoch: 460 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000060 drop: 0.000079 both: 0.000309\n",
      "Train Epoch: 460 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000242 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.2340\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0613\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.0331\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0423\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 461 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000392 drop: 0.000011 both: 0.000017\n",
      "Train Epoch: 461 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000219 drop: 0.000028 both: 0.000021\n",
      "Train Epoch: 461 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000155 drop: 0.000066 both: 0.002852\n",
      "Train Epoch: 461 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000092 drop: 0.000020 both: 0.000067\n",
      "Test set:\n",
      "default: Loss: 1.2425\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0321\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0353\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0316\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 462 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000020 both: 0.000010\n",
      "Train Epoch: 462 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000012 both: 0.000004\n",
      "Train Epoch: 462 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000006 drop: 0.000054 both: 0.000015\n",
      "Train Epoch: 462 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000046 drop: 0.000052 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.2505\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0208\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0428\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0601\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 463 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000033 both: 0.000002\n",
      "Train Epoch: 463 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000207 drop: 0.000024 both: 0.000257\n",
      "Train Epoch: 463 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000011 both: 0.000086\n",
      "Train Epoch: 463 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000025 drop: 0.000016 both: 0.004822\n",
      "Test set:\n",
      "default: Loss: 1.2566\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 0.9986\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.0506\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0421\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 464 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000018 drop: 0.000011 both: 0.000959\n",
      "Train Epoch: 464 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001997 drop: 0.000006 both: 0.000055\n",
      "Train Epoch: 464 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000197 drop: 0.000021 both: 0.000078\n",
      "Train Epoch: 464 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000022 drop: 0.010993 both: 0.006315\n",
      "Test set:\n",
      "default: Loss: 1.2635\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0991\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.0834\tAccuracy: 4360.0/5000 (87%)\n",
      "both: Loss: 0.9890\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 465 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000079 both: 0.000006\n",
      "Train Epoch: 465 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.096697 both: 0.000005\n",
      "Train Epoch: 465 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000261 drop: 0.000083 both: 0.021287\n",
      "Train Epoch: 465 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000287 drop: 0.000106 both: 0.000160\n",
      "Test set:\n",
      "default: Loss: 1.2704\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0336\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0901\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0478\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 466 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000038 drop: 0.000044 both: 0.000002\n",
      "Train Epoch: 466 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000028 both: 0.000023\n",
      "Train Epoch: 466 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.083122 both: 0.000275\n",
      "Train Epoch: 466 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000027 both: 0.000035\n",
      "Test set:\n",
      "default: Loss: 1.2763\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0011\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.1660\tAccuracy: 4319.0/5000 (86%)\n",
      "both: Loss: 1.0471\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 467 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000037 both: 0.000017\n",
      "Train Epoch: 467 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000062 both: 0.000037\n",
      "Train Epoch: 467 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000111 both: 0.000327\n",
      "Train Epoch: 467 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000042 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.2819\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0048\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1160\tAccuracy: 4348.0/5000 (87%)\n",
      "both: Loss: 1.0256\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 468 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000010 both: 0.009854\n",
      "Train Epoch: 468 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001342 drop: 0.000017 both: 0.000002\n",
      "Train Epoch: 468 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001773 drop: 0.000012 both: 0.000236\n",
      "Train Epoch: 468 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000099 drop: 0.000025 both: 0.000353\n",
      "Test set:\n",
      "default: Loss: 1.2893\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0121\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0757\tAccuracy: 4361.0/5000 (87%)\n",
      "both: Loss: 1.0556\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 469 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000104 drop: 0.000042 both: 0.000010\n",
      "Train Epoch: 469 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.068565 drop: 0.000054 both: 0.000019\n",
      "Train Epoch: 469 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000163 drop: 0.000212 both: 0.000099\n",
      "Train Epoch: 469 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000027 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2960\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 0.9970\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0567\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.0650\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 470 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000011 both: 0.000092\n",
      "Train Epoch: 470 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000057 drop: 0.000014 both: 0.000039\n",
      "Train Epoch: 470 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.002420 drop: 0.000011 both: 0.000014\n",
      "Train Epoch: 470 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000004 both: 0.000056\n",
      "Test set:\n",
      "default: Loss: 1.3006\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.0089\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0774\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0481\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 471 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000497 both: 0.020645\n",
      "Train Epoch: 471 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000013 both: 0.002134\n",
      "Train Epoch: 471 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000083 drop: 0.000006 both: 0.001000\n",
      "Train Epoch: 471 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.051483 drop: 0.000022 both: 0.000197\n",
      "Test set:\n",
      "default: Loss: 1.3087\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 0.9940\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.0638\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0184\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 472 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000005 both: 0.000083\n",
      "Train Epoch: 472 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000019 both: 0.000019\n",
      "Train Epoch: 472 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000338 drop: 0.000013 both: 0.000009\n",
      "Train Epoch: 472 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000081 drop: 0.000002 both: 0.000165\n",
      "Test set:\n",
      "default: Loss: 1.3121\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0019\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.0891\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0718\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 473 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000100 both: 0.000007\n",
      "Train Epoch: 473 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000015 both: 0.000193\n",
      "Train Epoch: 473 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000835 drop: 0.000084 both: 0.025636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 473 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000029 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3177\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0656\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0818\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0626\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 474 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001131 drop: 0.000025 both: 0.025405\n",
      "Train Epoch: 474 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000012 both: 0.000037\n",
      "Train Epoch: 474 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000327 drop: 0.000003 both: 0.000558\n",
      "Train Epoch: 474 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000384 drop: 0.000002 both: 0.000340\n",
      "Test set:\n",
      "default: Loss: 1.3266\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 0.9641\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0693\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0311\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 475 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.004417 drop: 0.000014 both: 0.000078\n",
      "Train Epoch: 475 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000099 drop: 0.000043 both: 0.001043\n",
      "Train Epoch: 475 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000144 drop: 0.000009 both: 0.000342\n",
      "Train Epoch: 475 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000607 drop: 0.000009 both: 0.000036\n",
      "Test set:\n",
      "default: Loss: 1.3292\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 0.9690\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0921\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0854\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 476 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000009 both: 0.000643\n",
      "Train Epoch: 476 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000003 both: 0.000005\n",
      "Train Epoch: 476 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000013 both: 0.000018\n",
      "Train Epoch: 476 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.001219\n",
      "Test set:\n",
      "default: Loss: 1.3344\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 0.9889\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0934\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0210\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 477 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000025 both: 0.000007\n",
      "Train Epoch: 477 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.016644 drop: 0.000022 both: 0.000012\n",
      "Train Epoch: 477 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000012 both: 0.000148\n",
      "Train Epoch: 477 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.002706 drop: 0.001717 both: 0.000216\n",
      "Test set:\n",
      "default: Loss: 1.3388\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0489\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1412\tAccuracy: 4344.0/5000 (87%)\n",
      "both: Loss: 1.0531\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 478 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000030 both: 0.000070\n",
      "Train Epoch: 478 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000566 both: 0.049333\n",
      "Train Epoch: 478 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000060 drop: 0.000097 both: 0.008120\n",
      "Train Epoch: 478 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.002331 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3440\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0256\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0871\tAccuracy: 4351.0/5000 (87%)\n",
      "both: Loss: 1.0371\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 479 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000005 both: 0.000079\n",
      "Train Epoch: 479 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000023 both: 0.000016\n",
      "Train Epoch: 479 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.008191 drop: 0.000170 both: 0.000548\n",
      "Train Epoch: 479 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000400 both: 0.000139\n",
      "Test set:\n",
      "default: Loss: 1.3479\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0537\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0638\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0555\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 480 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000272 drop: 0.000015 both: 0.000286\n",
      "Train Epoch: 480 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.006348 drop: 0.000113 both: 0.000025\n",
      "Train Epoch: 480 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000408 drop: 0.000064 both: 0.001134\n",
      "Train Epoch: 480 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000048 both: 0.001806\n",
      "Test set:\n",
      "default: Loss: 1.3525\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0378\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0447\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0275\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 481 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001315 drop: 0.000108 both: 0.000003\n",
      "Train Epoch: 481 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000057 drop: 0.000013 both: 0.000019\n",
      "Train Epoch: 481 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000052 both: 0.000254\n",
      "Train Epoch: 481 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000045 drop: 0.000013 both: 0.009426\n",
      "Test set:\n",
      "default: Loss: 1.3555\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0257\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0582\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0755\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 482 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000014 both: 0.000008\n",
      "Train Epoch: 482 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.001463\n",
      "Train Epoch: 482 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001035 drop: 0.000012 both: 0.000027\n",
      "Train Epoch: 482 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.105763 drop: 0.000006 both: 0.055107\n",
      "Test set:\n",
      "default: Loss: 1.3603\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0290\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0410\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0419\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 483 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000222 drop: 0.000058 both: 0.000333\n",
      "Train Epoch: 483 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000010 both: 0.000107\n",
      "Train Epoch: 483 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.002616 drop: 0.000008 both: 0.000017\n",
      "Train Epoch: 483 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000562 drop: 0.000008 both: 0.000250\n",
      "Test set:\n",
      "default: Loss: 1.3602\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0050\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.0645\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0354\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 484 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000020 both: 0.000864\n",
      "Train Epoch: 484 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.024832 drop: 0.000003 both: 0.000429\n",
      "Train Epoch: 484 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000948 drop: 0.000002 both: 0.000025\n",
      "Train Epoch: 484 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.008723 drop: 0.000012 both: 0.000203\n",
      "Test set:\n",
      "default: Loss: 1.3638\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0272\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0735\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0582\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 485 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000044 drop: 0.000014 both: 0.000022\n",
      "Train Epoch: 485 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000065 drop: 0.000008 both: 0.000010\n",
      "Train Epoch: 485 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.000003\n",
      "Train Epoch: 485 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000082 drop: 0.000086 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.3661\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0228\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0546\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0447\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 486 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000008 both: 0.004206\n",
      "Train Epoch: 486 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000052 drop: 0.000006 both: 0.000086\n",
      "Train Epoch: 486 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000006 both: 0.000444\n",
      "Train Epoch: 486 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000040 drop: 0.000020 both: 0.000416\n",
      "Test set:\n",
      "default: Loss: 1.3661\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0223\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0614\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0435\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 487 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000035 drop: 0.000010 both: 0.000019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 487 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000011 both: 0.000009\n",
      "Train Epoch: 487 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000038 drop: 0.000008 both: 0.001952\n",
      "Train Epoch: 487 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000008 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3670\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0332\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0939\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0358\tAccuracy: 4412.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 488 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000134 drop: 0.000003 both: 0.000047\n",
      "Train Epoch: 488 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000020 both: 0.000014\n",
      "Train Epoch: 488 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.002477 both: 0.000042\n",
      "Train Epoch: 488 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000004 both: 0.000033\n",
      "Test set:\n",
      "default: Loss: 1.3718\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0338\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0633\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0290\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 489 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000021 both: 0.000062\n",
      "Train Epoch: 489 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000040 both: 0.000014\n",
      "Train Epoch: 489 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000461 drop: 0.000002 both: 0.000108\n",
      "Train Epoch: 489 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000005 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.3735\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0164\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0938\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0233\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 490 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000097 drop: 0.000007 both: 0.000011\n",
      "Train Epoch: 490 [10000/25000 (40%)]\tLosses default: 0.095549 bn: 0.000711 drop: 0.000019 both: 0.024825\n",
      "Train Epoch: 490 [20000/25000 (80%)]\tLosses default: 0.000476 bn: 0.000009 drop: 0.000006 both: 0.000019\n",
      "Train Epoch: 490 [25000/25000 (100%)]\tLosses default: 0.000099 bn: 0.000005 drop: 0.000011 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.1017\tAccuracy: 4407.0/5000 (88%)\n",
      "bn: Loss: 1.0101\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1073\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0094\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 491 [0/25000 (0%)]\tLosses default: 0.006860 bn: 0.000001 drop: 0.000018 both: 0.000038\n",
      "Train Epoch: 491 [10000/25000 (40%)]\tLosses default: 0.000024 bn: 0.054956 drop: 0.003972 both: 0.000028\n",
      "Train Epoch: 491 [20000/25000 (80%)]\tLosses default: 0.000532 bn: 0.000002 drop: 0.000389 both: 0.000018\n",
      "Train Epoch: 491 [25000/25000 (100%)]\tLosses default: 0.000500 bn: 0.000212 drop: 0.070655 both: 0.000329\n",
      "Test set:\n",
      "default: Loss: 1.0765\tAccuracy: 4409.0/5000 (88%)\n",
      "bn: Loss: 1.0465\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.0601\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.0421\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 492 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.000003 drop: 0.018340 both: 0.000007\n",
      "Train Epoch: 492 [10000/25000 (40%)]\tLosses default: 0.004633 bn: 0.000605 drop: 0.000127 both: 0.000019\n",
      "Train Epoch: 492 [20000/25000 (80%)]\tLosses default: 0.000022 bn: 0.000001 drop: 0.000541 both: 0.004921\n",
      "Train Epoch: 492 [25000/25000 (100%)]\tLosses default: 0.000896 bn: 0.000064 drop: 0.001624 both: 0.013573\n",
      "Test set:\n",
      "default: Loss: 1.0887\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0344\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0374\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0718\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 493 [0/25000 (0%)]\tLosses default: 0.000022 bn: 0.012330 drop: 0.000019 both: 0.000536\n",
      "Train Epoch: 493 [10000/25000 (40%)]\tLosses default: 0.000012 bn: 0.000036 drop: 0.000041 both: 0.000007\n",
      "Train Epoch: 493 [20000/25000 (80%)]\tLosses default: 0.000226 bn: 0.000015 drop: 0.000722 both: 0.008962\n",
      "Train Epoch: 493 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000049 drop: 0.000011 both: 0.000132\n",
      "Test set:\n",
      "default: Loss: 1.0976\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.0370\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.0515\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0512\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 494 [0/25000 (0%)]\tLosses default: 0.000206 bn: 0.000268 drop: 0.000161 both: 0.000059\n",
      "Train Epoch: 494 [10000/25000 (40%)]\tLosses default: 0.000017 bn: 0.000089 drop: 0.000059 both: 0.002612\n",
      "Train Epoch: 494 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000022 drop: 0.000227 both: 0.000053\n",
      "Train Epoch: 494 [25000/25000 (100%)]\tLosses default: 0.000012 bn: 0.000030 drop: 0.035434 both: 0.000133\n",
      "Test set:\n",
      "default: Loss: 1.1053\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0213\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.0711\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0260\tAccuracy: 4416.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 495 [0/25000 (0%)]\tLosses default: 0.000143 bn: 0.000037 drop: 0.021822 both: 0.000167\n",
      "Train Epoch: 495 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.002479 drop: 0.000737 both: 0.000219\n",
      "Train Epoch: 495 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000002 drop: 0.000011 both: 0.000208\n",
      "Train Epoch: 495 [25000/25000 (100%)]\tLosses default: 0.000020 bn: 0.000008 drop: 0.005703 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.1138\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0741\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0675\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0069\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 496 [0/25000 (0%)]\tLosses default: 0.000041 bn: 0.000068 drop: 0.001394 both: 0.000012\n",
      "Train Epoch: 496 [10000/25000 (40%)]\tLosses default: 0.000014 bn: 0.000016 drop: 0.000002 both: 0.000003\n",
      "Train Epoch: 496 [20000/25000 (80%)]\tLosses default: 0.000016 bn: 0.000015 drop: 0.000012 both: 0.021641\n",
      "Train Epoch: 496 [25000/25000 (100%)]\tLosses default: 0.000011 bn: 0.000004 drop: 0.000162 both: 0.017494\n",
      "Test set:\n",
      "default: Loss: 1.1217\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0162\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.0527\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0182\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 497 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000213 both: 0.000019\n",
      "Train Epoch: 497 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000135 drop: 0.000020 both: 0.000007\n",
      "Train Epoch: 497 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000002 drop: 0.000035 both: 0.000033\n",
      "Train Epoch: 497 [25000/25000 (100%)]\tLosses default: 0.000089 bn: 0.000054 drop: 0.000608 both: 0.003036\n",
      "Test set:\n",
      "default: Loss: 1.1297\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0325\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.0635\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 1.0180\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 498 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000005 both: 0.000058\n",
      "Train Epoch: 498 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000025 drop: 0.000007 both: 0.000011\n",
      "Train Epoch: 498 [20000/25000 (80%)]\tLosses default: 0.000038 bn: 0.000995 drop: 0.000180 both: 0.000027\n",
      "Train Epoch: 498 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000212 drop: 0.000011 both: 0.000083\n",
      "Test set:\n",
      "default: Loss: 1.1385\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0443\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0627\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0485\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 499 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000008 drop: 0.000012 both: 0.000013\n",
      "Train Epoch: 499 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.000013 drop: 0.000025 both: 0.000011\n",
      "Train Epoch: 499 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.004928 drop: 0.000002 both: 0.000012\n",
      "Train Epoch: 499 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000003 drop: 0.000015 both: 0.011977\n",
      "Test set:\n",
      "default: Loss: 1.1470\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0323\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.0719\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0601\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 500 [0/25000 (0%)]\tLosses default: 0.000030 bn: 0.000033 drop: 0.000014 both: 0.000257\n",
      "Train Epoch: 500 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000034 drop: 0.000002 both: 0.000003\n",
      "Train Epoch: 500 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000016 drop: 0.000075 both: 0.000023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 500 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000001 drop: 0.000018 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.1556\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0429\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.0544\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0210\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 501 [0/25000 (0%)]\tLosses default: 0.000013 bn: 0.000002 drop: 0.000011 both: 0.000049\n",
      "Train Epoch: 501 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000012 drop: 0.000045 both: 0.000023\n",
      "Train Epoch: 501 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000005 both: 0.000094\n",
      "Train Epoch: 501 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000188 drop: 0.002375 both: 0.008019\n",
      "Test set:\n",
      "default: Loss: 1.1640\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0217\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0884\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.0025\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 502 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000047 drop: 0.013528 both: 0.000015\n",
      "Train Epoch: 502 [10000/25000 (40%)]\tLosses default: 0.000013 bn: 0.000383 drop: 0.031716 both: 0.000497\n",
      "Train Epoch: 502 [20000/25000 (80%)]\tLosses default: 0.000012 bn: 0.002582 drop: 0.004070 both: 0.000823\n",
      "Train Epoch: 502 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000041 drop: 0.001513 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.1728\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0426\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0301\tAccuracy: 4360.0/5000 (87%)\n",
      "both: Loss: 0.9973\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 503 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000015 drop: 0.000137 both: 0.000005\n",
      "Train Epoch: 503 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000013 drop: 0.000925 both: 0.000130\n",
      "Train Epoch: 503 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000017 drop: 0.000351 both: 0.031812\n",
      "Train Epoch: 503 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.014099 drop: 0.000091 both: 0.000030\n",
      "Test set:\n",
      "default: Loss: 1.1817\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0895\tAccuracy: 4387.0/5000 (88%)\n",
      "drop: Loss: 1.0211\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 0.9981\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 504 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000063 drop: 0.000594 both: 0.000854\n",
      "Train Epoch: 504 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000044 drop: 0.000644 both: 0.001393\n",
      "Train Epoch: 504 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000011 drop: 0.000161 both: 0.000027\n",
      "Train Epoch: 504 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000021 drop: 0.000017 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.1905\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0187\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0221\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0474\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 505 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000015 both: 0.000007\n",
      "Train Epoch: 505 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000067 both: 0.000079\n",
      "Train Epoch: 505 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000308 drop: 0.000068 both: 0.000340\n",
      "Train Epoch: 505 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000261 drop: 0.000013 both: 0.000123\n",
      "Test set:\n",
      "default: Loss: 1.1999\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 0.9942\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0198\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0454\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 506 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000019 drop: 0.000062 both: 0.000022\n",
      "Train Epoch: 506 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000007 both: 0.102048\n",
      "Train Epoch: 506 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.002698 drop: 0.000144 both: 0.000055\n",
      "Train Epoch: 506 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000014 both: 0.000079\n",
      "Test set:\n",
      "default: Loss: 1.2088\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 0.9968\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0375\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0640\tAccuracy: 4365.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 507 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000011 drop: 0.000159 both: 0.000101\n",
      "Train Epoch: 507 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000683 drop: 0.000012 both: 0.000061\n",
      "Train Epoch: 507 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000072 both: 0.000032\n",
      "Train Epoch: 507 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.071604 drop: 0.000082 both: 0.000130\n",
      "Test set:\n",
      "default: Loss: 1.2167\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0550\tAccuracy: 4393.0/5000 (88%)\n",
      "drop: Loss: 1.0273\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0634\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 508 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000063 drop: 0.000045 both: 0.000038\n",
      "Train Epoch: 508 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000039 drop: 0.000019 both: 0.000279\n",
      "Train Epoch: 508 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000414 drop: 0.000035 both: 0.001129\n",
      "Train Epoch: 508 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000013 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.2256\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0236\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0392\tAccuracy: 4413.0/5000 (88%)\n",
      "both: Loss: 1.0537\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 509 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000690 drop: 0.000017 both: 0.000396\n",
      "Train Epoch: 509 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000189 drop: 0.000033 both: 0.003349\n",
      "Train Epoch: 509 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000142 drop: 0.000001 both: 0.000003\n",
      "Train Epoch: 509 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000030 drop: 0.000019 both: 0.000068\n",
      "Test set:\n",
      "default: Loss: 1.2347\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0436\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0576\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0556\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 510 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000016 both: 0.002503\n",
      "Train Epoch: 510 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.003042 drop: 0.000073 both: 0.001634\n",
      "Train Epoch: 510 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000066 both: 0.000941\n",
      "Train Epoch: 510 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.003274 both: 0.000062\n",
      "Test set:\n",
      "default: Loss: 1.2430\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0469\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.1129\tAccuracy: 4348.0/5000 (87%)\n",
      "both: Loss: 1.0385\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 511 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000069 drop: 0.000019 both: 0.000047\n",
      "Train Epoch: 511 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000209 both: 0.000047\n",
      "Train Epoch: 511 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.008386 drop: 0.001119 both: 0.000004\n",
      "Train Epoch: 511 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000010 drop: 0.000006 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.2517\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0379\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.0540\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0518\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 512 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000036 drop: 0.000448 both: 0.000584\n",
      "Train Epoch: 512 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.032031 drop: 0.000099 both: 0.000122\n",
      "Train Epoch: 512 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000863 drop: 0.000106 both: 0.000485\n",
      "Train Epoch: 512 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.002108 drop: 0.000011 both: 0.001050\n",
      "Test set:\n",
      "default: Loss: 1.2590\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0155\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0280\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0694\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 513 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000078 both: 0.000003\n",
      "Train Epoch: 513 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000255 drop: 0.000083 both: 0.000005\n",
      "Train Epoch: 513 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000029 both: 0.000004\n",
      "Train Epoch: 513 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000106 drop: 0.000075 both: 0.000163\n",
      "Test set:\n",
      "default: Loss: 1.2682\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0071\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0466\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0317\tAccuracy: 4410.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 514 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000019 drop: 0.000055 both: 0.000015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 514 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000111 drop: 0.000019 both: 0.000059\n",
      "Train Epoch: 514 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000200 drop: 0.000035 both: 0.004060\n",
      "Train Epoch: 514 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000152 drop: 0.000015 both: 0.001702\n",
      "Test set:\n",
      "default: Loss: 1.2756\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0011\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0272\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0483\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 515 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000021 both: 0.000236\n",
      "Train Epoch: 515 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.007450 drop: 0.000122 both: 0.000031\n",
      "Train Epoch: 515 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.042658 drop: 0.000006 both: 0.145980\n",
      "Train Epoch: 515 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.003920 drop: 0.000069 both: 0.011928\n",
      "Test set:\n",
      "default: Loss: 1.2847\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0008\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0359\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0481\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 516 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000012 both: 0.000010\n",
      "Train Epoch: 516 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000319 drop: 0.000102 both: 0.005233\n",
      "Train Epoch: 516 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000004 both: 0.000011\n",
      "Train Epoch: 516 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000006 both: 0.002715\n",
      "Test set:\n",
      "default: Loss: 1.2936\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0296\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0376\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 1.0379\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 517 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.013856 drop: 0.000005 both: 0.000042\n",
      "Train Epoch: 517 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001612 drop: 0.000013 both: 0.000124\n",
      "Train Epoch: 517 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.011713 drop: 0.000010 both: 0.000011\n",
      "Train Epoch: 517 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001006 drop: 0.000135 both: 0.000055\n",
      "Test set:\n",
      "default: Loss: 1.3000\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0074\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0341\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0346\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 518 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000042 both: 0.001508\n",
      "Train Epoch: 518 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000037 both: 0.000055\n",
      "Train Epoch: 518 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000004 both: 0.001531\n",
      "Train Epoch: 518 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.094820 drop: 0.000018 both: 0.001099\n",
      "Test set:\n",
      "default: Loss: 1.3091\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0112\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.0460\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0894\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 519 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000884 drop: 0.000007 both: 0.000164\n",
      "Train Epoch: 519 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000012 both: 0.000020\n",
      "Train Epoch: 519 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000013 both: 0.000011\n",
      "Train Epoch: 519 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000364 drop: 0.000006 both: 0.001260\n",
      "Test set:\n",
      "default: Loss: 1.3122\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 0.9891\tAccuracy: 4442.0/5000 (89%)\n",
      "drop: Loss: 1.0660\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0673\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 520 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000007 both: 0.000044\n",
      "Train Epoch: 520 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000918 drop: 0.000017 both: 0.000058\n",
      "Train Epoch: 520 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001570 drop: 0.175313 both: 0.000023\n",
      "Train Epoch: 520 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000178 drop: 0.000247 both: 0.000032\n",
      "Test set:\n",
      "default: Loss: 1.3222\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0355\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.0692\tAccuracy: 4357.0/5000 (87%)\n",
      "both: Loss: 1.0853\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 521 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000912 both: 0.003879\n",
      "Train Epoch: 521 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000105 drop: 0.000095 both: 0.000026\n",
      "Train Epoch: 521 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000209 drop: 0.000121 both: 0.000111\n",
      "Train Epoch: 521 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000061 drop: 0.000080 both: 0.000072\n",
      "Test set:\n",
      "default: Loss: 1.3316\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0217\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.0265\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0757\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 522 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000135 both: 0.000013\n",
      "Train Epoch: 522 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000022 both: 0.000342\n",
      "Train Epoch: 522 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000082 drop: 0.000061 both: 0.000119\n",
      "Train Epoch: 522 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000113 drop: 0.000195 both: 0.000186\n",
      "Test set:\n",
      "default: Loss: 1.3326\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0439\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.0449\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0684\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 523 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000098 drop: 0.000138 both: 0.000468\n",
      "Train Epoch: 523 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000005 both: 0.000022\n",
      "Train Epoch: 523 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000056 both: 0.000004\n",
      "Train Epoch: 523 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000030 both: 0.000169\n",
      "Test set:\n",
      "default: Loss: 1.3397\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0132\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0673\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0262\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 524 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.005656 drop: 0.000046 both: 0.000078\n",
      "Train Epoch: 524 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000012 both: 0.000015\n",
      "Train Epoch: 524 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000361 drop: 0.000262 both: 0.000091\n",
      "Train Epoch: 524 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.030457 drop: 0.000016 both: 0.000116\n",
      "Test set:\n",
      "default: Loss: 1.3479\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0219\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0467\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0734\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 525 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000056 drop: 0.000004 both: 0.007189\n",
      "Train Epoch: 525 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000032 both: 0.000038\n",
      "Train Epoch: 525 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000079 both: 0.000073\n",
      "Train Epoch: 525 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000090 both: 0.000156\n",
      "Test set:\n",
      "default: Loss: 1.3556\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0053\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 1.0475\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0661\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 526 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000017 both: 0.000050\n",
      "Train Epoch: 526 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000040 drop: 0.000010 both: 0.000525\n",
      "Train Epoch: 526 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000019 both: 0.000219\n",
      "Train Epoch: 526 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000082 drop: 0.000108 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.3573\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0004\tAccuracy: 4442.0/5000 (89%)\n",
      "drop: Loss: 1.0496\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0695\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 527 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.004986 drop: 0.000009 both: 0.000648\n",
      "Train Epoch: 527 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000014 both: 0.000014\n",
      "Train Epoch: 527 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000020 both: 0.000173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 527 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.004074 drop: 0.000008 both: 0.000041\n",
      "Test set:\n",
      "default: Loss: 1.3620\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 0.9759\tAccuracy: 4462.0/5000 (89%)\n",
      "drop: Loss: 1.0722\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0615\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 528 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000094 drop: 0.000048 both: 0.000117\n",
      "Train Epoch: 528 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000007 both: 0.000003\n",
      "Train Epoch: 528 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000054 drop: 0.000018 both: 0.000269\n",
      "Train Epoch: 528 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000286 drop: 0.002307 both: 0.000472\n",
      "Test set:\n",
      "default: Loss: 1.3640\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 0.9961\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.1055\tAccuracy: 4366.0/5000 (87%)\n",
      "both: Loss: 1.0436\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 529 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000262 both: 0.000016\n",
      "Train Epoch: 529 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000064 drop: 0.060088 both: 0.002025\n",
      "Train Epoch: 529 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000152 both: 0.000010\n",
      "Train Epoch: 529 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000539 both: 0.000116\n",
      "Test set:\n",
      "default: Loss: 1.3683\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0311\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.0253\tAccuracy: 4353.0/5000 (87%)\n",
      "both: Loss: 1.0918\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 530 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000925 both: 0.000003\n",
      "Train Epoch: 530 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000722 both: 0.000131\n",
      "Train Epoch: 530 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.014670 drop: 0.000130 both: 0.000470\n",
      "Train Epoch: 530 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.021640 both: 0.000113\n",
      "Test set:\n",
      "default: Loss: 1.3714\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0594\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0269\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.1031\tAccuracy: 4363.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 531 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.032306 drop: 0.000036 both: 0.018565\n",
      "Train Epoch: 531 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000040 drop: 0.000099 both: 0.000008\n",
      "Train Epoch: 531 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000180 drop: 0.000030 both: 0.000012\n",
      "Train Epoch: 531 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000687 drop: 0.000018 both: 0.002057\n",
      "Test set:\n",
      "default: Loss: 1.3741\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0657\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0581\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0712\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 532 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000084 both: 0.101290\n",
      "Train Epoch: 532 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000073 both: 0.001756\n",
      "Train Epoch: 532 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000809 both: 0.000040\n",
      "Train Epoch: 532 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000142 drop: 0.000006 both: 0.000028\n",
      "Test set:\n",
      "default: Loss: 1.3763\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0234\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.0142\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0626\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 533 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000010 both: 0.000006\n",
      "Train Epoch: 533 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000131 drop: 0.000353 both: 0.000013\n",
      "Train Epoch: 533 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000030 both: 0.000040\n",
      "Train Epoch: 533 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000110\n",
      "Test set:\n",
      "default: Loss: 1.3779\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0348\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0256\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0787\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 534 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000033 both: 0.000005\n",
      "Train Epoch: 534 [10000/25000 (40%)]\tLosses default: 0.000432 bn: 0.000010 drop: 0.000019 both: 0.040054\n",
      "Train Epoch: 534 [20000/25000 (80%)]\tLosses default: 0.000034 bn: 0.000001 drop: 0.000148 both: 0.000124\n",
      "Train Epoch: 534 [25000/25000 (100%)]\tLosses default: 0.003138 bn: 0.001359 drop: 0.000026 both: 0.000040\n",
      "Test set:\n",
      "default: Loss: 1.0162\tAccuracy: 4411.0/5000 (88%)\n",
      "bn: Loss: 1.0728\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.0500\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.1329\tAccuracy: 4347.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 535 [0/25000 (0%)]\tLosses default: 0.000175 bn: 0.000317 drop: 0.000010 both: 0.000126\n",
      "Train Epoch: 535 [10000/25000 (40%)]\tLosses default: 0.000706 bn: 0.000035 drop: 0.000007 both: 0.000113\n",
      "Train Epoch: 535 [20000/25000 (80%)]\tLosses default: 0.000170 bn: 0.000088 drop: 0.000005 both: 0.002977\n",
      "Train Epoch: 535 [25000/25000 (100%)]\tLosses default: 0.000493 bn: 0.000030 drop: 0.000017 both: 0.000295\n",
      "Test set:\n",
      "default: Loss: 1.0619\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0082\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0534\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0795\tAccuracy: 4365.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 536 [0/25000 (0%)]\tLosses default: 0.000022 bn: 0.000049 drop: 0.000019 both: 0.011724\n",
      "Train Epoch: 536 [10000/25000 (40%)]\tLosses default: 0.000127 bn: 0.007205 drop: 0.000015 both: 0.000017\n",
      "Train Epoch: 536 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000006 drop: 0.000054 both: 0.000135\n",
      "Train Epoch: 536 [25000/25000 (100%)]\tLosses default: 0.000063 bn: 0.000331 drop: 0.053983 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.0837\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0253\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1674\tAccuracy: 4335.0/5000 (87%)\n",
      "both: Loss: 1.0605\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 537 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000013 drop: 0.001422 both: 0.000014\n",
      "Train Epoch: 537 [10000/25000 (40%)]\tLosses default: 0.000090 bn: 0.000246 drop: 0.000187 both: 0.000029\n",
      "Train Epoch: 537 [20000/25000 (80%)]\tLosses default: 0.000017 bn: 0.000014 drop: 0.000010 both: 0.000093\n",
      "Train Epoch: 537 [25000/25000 (100%)]\tLosses default: 0.000052 bn: 0.000040 drop: 0.000064 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.0834\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0233\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0066\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0384\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 538 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000068 drop: 0.000031 both: 0.000009\n",
      "Train Epoch: 538 [10000/25000 (40%)]\tLosses default: 0.000012 bn: 0.000198 drop: 0.000081 both: 0.000034\n",
      "Train Epoch: 538 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000054 drop: 0.000111 both: 0.000011\n",
      "Train Epoch: 538 [25000/25000 (100%)]\tLosses default: 0.000033 bn: 0.000591 drop: 0.000020 both: 0.003036\n",
      "Test set:\n",
      "default: Loss: 1.0938\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 0.9980\tAccuracy: 4445.0/5000 (89%)\n",
      "drop: Loss: 1.0150\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0442\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 539 [0/25000 (0%)]\tLosses default: 0.000059 bn: 0.000035 drop: 0.000019 both: 0.000009\n",
      "Train Epoch: 539 [10000/25000 (40%)]\tLosses default: 0.000472 bn: 0.000016 drop: 0.000045 both: 0.000030\n",
      "Train Epoch: 539 [20000/25000 (80%)]\tLosses default: 0.000048 bn: 0.000011 drop: 0.000028 both: 0.000003\n",
      "Train Epoch: 539 [25000/25000 (100%)]\tLosses default: 0.000151 bn: 0.000099 drop: 0.000105 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.1049\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0183\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0509\tAccuracy: 4363.0/5000 (87%)\n",
      "both: Loss: 1.0611\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 540 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000015 drop: 0.000195 both: 0.000126\n",
      "Train Epoch: 540 [10000/25000 (40%)]\tLosses default: 0.000033 bn: 0.000003 drop: 0.000008 both: 0.000015\n",
      "Train Epoch: 540 [20000/25000 (80%)]\tLosses default: 0.000098 bn: 0.000003 drop: 0.000009 both: 0.010936\n",
      "Train Epoch: 540 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000036 drop: 0.000023 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.1135\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0049\tAccuracy: 4454.0/5000 (89%)\n",
      "drop: Loss: 1.0315\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0583\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 541 [0/25000 (0%)]\tLosses default: 0.000014 bn: 0.000019 drop: 0.000081 both: 0.000050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 541 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000004 both: 0.000006\n",
      "Train Epoch: 541 [20000/25000 (80%)]\tLosses default: 0.000045 bn: 0.000068 drop: 0.000021 both: 0.028672\n",
      "Train Epoch: 541 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000010 drop: 0.000006 both: 0.000209\n",
      "Test set:\n",
      "default: Loss: 1.1222\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 0.9962\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 1.0219\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0726\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 542 [0/25000 (0%)]\tLosses default: 0.000036 bn: 0.000046 drop: 0.000033 both: 0.000020\n",
      "Train Epoch: 542 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000017 both: 0.000002\n",
      "Train Epoch: 542 [20000/25000 (80%)]\tLosses default: 0.000035 bn: 0.000004 drop: 0.000011 both: 0.000004\n",
      "Train Epoch: 542 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000015 drop: 0.000015 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.1325\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0652\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.0522\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0479\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 543 [0/25000 (0%)]\tLosses default: 0.000019 bn: 0.000015 drop: 0.000288 both: 0.039129\n",
      "Train Epoch: 543 [10000/25000 (40%)]\tLosses default: 0.000036 bn: 0.000046 drop: 0.000026 both: 0.000037\n",
      "Train Epoch: 543 [20000/25000 (80%)]\tLosses default: 0.000022 bn: 0.006290 drop: 0.000015 both: 0.000038\n",
      "Train Epoch: 543 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000053 drop: 0.000012 both: 0.001247\n",
      "Test set:\n",
      "default: Loss: 1.1418\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0017\tAccuracy: 4451.0/5000 (89%)\n",
      "drop: Loss: 1.0432\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0605\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 544 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000016 both: 0.000043\n",
      "Train Epoch: 544 [10000/25000 (40%)]\tLosses default: 0.000035 bn: 0.000533 drop: 0.000009 both: 0.000256\n",
      "Train Epoch: 544 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000002 drop: 0.000009 both: 0.000183\n",
      "Train Epoch: 544 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000015 drop: 0.000020 both: 0.007824\n",
      "Test set:\n",
      "default: Loss: 1.1505\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0179\tAccuracy: 4448.0/5000 (89%)\n",
      "drop: Loss: 1.0435\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0482\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 545 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.000002 drop: 0.000008 both: 0.044832\n",
      "Train Epoch: 545 [10000/25000 (40%)]\tLosses default: 0.000017 bn: 0.000091 drop: 0.000008 both: 0.000006\n",
      "Train Epoch: 545 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000034 both: 0.000008\n",
      "Train Epoch: 545 [25000/25000 (100%)]\tLosses default: 0.000011 bn: 0.000005 drop: 0.000022 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.1599\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0300\tAccuracy: 4446.0/5000 (89%)\n",
      "drop: Loss: 1.0659\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0451\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 546 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000006 both: 0.000004\n",
      "Train Epoch: 546 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000058 drop: 0.000012 both: 0.000222\n",
      "Train Epoch: 546 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000005 drop: 0.000003 both: 0.000280\n",
      "Train Epoch: 546 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000027 drop: 0.000005 both: 0.000143\n",
      "Test set:\n",
      "default: Loss: 1.1715\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0337\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0664\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0498\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 547 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000020 drop: 0.000002 both: 0.000007\n",
      "Train Epoch: 547 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000352 drop: 0.000028 both: 0.000372\n",
      "Train Epoch: 547 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000179 drop: 0.000005 both: 0.000022\n",
      "Train Epoch: 547 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000227 drop: 0.000022 both: 0.000158\n",
      "Test set:\n",
      "default: Loss: 1.1801\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0160\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.0639\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0625\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 548 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000017 drop: 0.000004 both: 0.000015\n",
      "Train Epoch: 548 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000223 drop: 0.000023 both: 0.000774\n",
      "Train Epoch: 548 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000006 drop: 0.000007 both: 0.000159\n",
      "Train Epoch: 548 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000032 drop: 0.000005 both: 0.000176\n",
      "Test set:\n",
      "default: Loss: 1.1890\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0262\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.0562\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0477\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 549 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000019 drop: 0.000007 both: 0.000017\n",
      "Train Epoch: 549 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000081 drop: 0.000009 both: 0.000033\n",
      "Train Epoch: 549 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000044 drop: 0.000005 both: 0.000008\n",
      "Train Epoch: 549 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000032 drop: 0.000027 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 1.1988\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0338\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.0857\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0776\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 550 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000723 drop: 0.000012 both: 0.000139\n",
      "Train Epoch: 550 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000624 drop: 0.000004 both: 0.000027\n",
      "Train Epoch: 550 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000023 drop: 0.000004 both: 0.000034\n",
      "Train Epoch: 550 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000049 drop: 0.000020 both: 0.000546\n",
      "Test set:\n",
      "default: Loss: 1.2080\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0468\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.0838\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0470\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 551 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000078 drop: 0.000017 both: 0.002144\n",
      "Train Epoch: 551 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000036 drop: 0.000009 both: 0.000017\n",
      "Train Epoch: 551 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000014 drop: 0.000014 both: 0.000033\n",
      "Train Epoch: 551 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000001 both: 0.000132\n",
      "Test set:\n",
      "default: Loss: 1.2174\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0957\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 1.0907\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0630\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 552 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000064 drop: 0.000005 both: 0.000080\n",
      "Train Epoch: 552 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000016 drop: 0.000003 both: 0.000011\n",
      "Train Epoch: 552 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000054 drop: 0.000030 both: 0.000041\n",
      "Train Epoch: 552 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000018 drop: 0.000000 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2263\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0371\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0890\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0751\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 553 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000007 both: 0.000027\n",
      "Train Epoch: 553 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000229 drop: 0.000012 both: 0.000033\n",
      "Train Epoch: 553 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.005005 drop: 0.000120 both: 0.000008\n",
      "Train Epoch: 553 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000054 drop: 0.046530 both: 0.000149\n",
      "Test set:\n",
      "default: Loss: 1.2352\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0669\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1724\tAccuracy: 4313.0/5000 (86%)\n",
      "both: Loss: 1.0912\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 554 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000021 drop: 0.002121 both: 0.000830\n",
      "Train Epoch: 554 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000471 drop: 0.000076 both: 0.023895\n",
      "Train Epoch: 554 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000196 drop: 0.000788 both: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 554 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000183 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2436\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0481\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.0733\tAccuracy: 4344.0/5000 (87%)\n",
      "both: Loss: 1.0491\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 555 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.007902 drop: 0.000224 both: 0.000178\n",
      "Train Epoch: 555 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000206 drop: 0.004419 both: 0.000007\n",
      "Train Epoch: 555 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000146 drop: 0.000065 both: 0.000192\n",
      "Train Epoch: 555 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000010 both: 0.000042\n",
      "Test set:\n",
      "default: Loss: 1.2525\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0445\tAccuracy: 4404.0/5000 (88%)\n",
      "drop: Loss: 1.0180\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0832\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 556 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.001392 drop: 0.000018 both: 0.000006\n",
      "Train Epoch: 556 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000086 drop: 0.000050 both: 0.000015\n",
      "Train Epoch: 556 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000018 both: 0.000014\n",
      "Train Epoch: 556 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000019 both: 0.000038\n",
      "Test set:\n",
      "default: Loss: 1.2626\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0329\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.0321\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0694\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 557 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000696 drop: 0.000025 both: 0.000038\n",
      "Train Epoch: 557 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000472 both: 0.008415\n",
      "Train Epoch: 557 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000145 drop: 0.000246 both: 0.002618\n",
      "Train Epoch: 557 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000114 both: 0.000038\n",
      "Test set:\n",
      "default: Loss: 1.2693\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0452\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 1.0520\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0847\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 558 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000739 both: 0.001056\n",
      "Train Epoch: 558 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000014 both: 0.000023\n",
      "Train Epoch: 558 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000019 drop: 0.000008 both: 0.000006\n",
      "Train Epoch: 558 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001637 drop: 0.000091 both: 0.000246\n",
      "Test set:\n",
      "default: Loss: 1.2781\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0475\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0309\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0781\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 559 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000032 drop: 0.000108 both: 0.000046\n",
      "Train Epoch: 559 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000005 both: 0.000039\n",
      "Train Epoch: 559 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000106 drop: 0.000098 both: 0.023490\n",
      "Train Epoch: 559 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000014 both: 0.001653\n",
      "Test set:\n",
      "default: Loss: 1.2858\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0334\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0657\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0789\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 560 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000062 both: 0.000050\n",
      "Train Epoch: 560 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000929 drop: 0.000040 both: 0.000055\n",
      "Train Epoch: 560 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000153 drop: 0.000154 both: 0.038016\n",
      "Train Epoch: 560 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000053 drop: 0.000030 both: 0.000030\n",
      "Test set:\n",
      "default: Loss: 1.2933\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0810\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.0625\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0655\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 561 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000090 drop: 0.000374 both: 0.000092\n",
      "Train Epoch: 561 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000019 both: 0.000202\n",
      "Train Epoch: 561 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000164 drop: 0.000103 both: 0.000010\n",
      "Train Epoch: 561 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000015 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3019\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0287\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0679\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0213\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 562 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000084 drop: 0.000081 both: 0.000009\n",
      "Train Epoch: 562 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000054 both: 0.000012\n",
      "Train Epoch: 562 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.002665 both: 0.000013\n",
      "Train Epoch: 562 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.005720 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.3072\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0649\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0710\tAccuracy: 4351.0/5000 (87%)\n",
      "both: Loss: 1.0670\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 563 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000380 drop: 0.072969 both: 0.000008\n",
      "Train Epoch: 563 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000041 both: 0.000096\n",
      "Train Epoch: 563 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000491 drop: 0.007033 both: 0.013383\n",
      "Train Epoch: 563 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000084 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3161\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0449\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.0395\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0658\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 564 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000899 drop: 0.001567 both: 0.000083\n",
      "Train Epoch: 564 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000067 both: 0.000022\n",
      "Train Epoch: 564 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000251 drop: 0.000023 both: 0.000056\n",
      "Train Epoch: 564 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000019 both: 0.000099\n",
      "Test set:\n",
      "default: Loss: 1.3240\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0915\tAccuracy: 4384.0/5000 (88%)\n",
      "drop: Loss: 1.0365\tAccuracy: 4367.0/5000 (87%)\n",
      "both: Loss: 1.0610\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 565 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001768 drop: 0.000008 both: 0.000019\n",
      "Train Epoch: 565 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.025868 drop: 0.000046 both: 0.000133\n",
      "Train Epoch: 565 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000038 drop: 0.000023 both: 0.006640\n",
      "Train Epoch: 565 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000150 drop: 0.000037 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.3292\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0171\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0404\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0473\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 566 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.020381 drop: 0.000088 both: 0.002970\n",
      "Train Epoch: 566 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000104 both: 0.000020\n",
      "Train Epoch: 566 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000074 drop: 0.000476 both: 0.000005\n",
      "Train Epoch: 566 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000033 both: 0.000074\n",
      "Test set:\n",
      "default: Loss: 1.3367\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0268\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.0427\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0988\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 567 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001156 drop: 0.000009 both: 0.000107\n",
      "Train Epoch: 567 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000090 drop: 0.000014 both: 0.000038\n",
      "Train Epoch: 567 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.034817 drop: 0.000002 both: 0.000020\n",
      "Train Epoch: 567 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000077 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 1.3421\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0360\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0630\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0650\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 568 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000066 drop: 0.000038 both: 0.000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 568 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000018 both: 0.006354\n",
      "Train Epoch: 568 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000019 both: 0.000003\n",
      "Train Epoch: 568 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000002 both: 0.000032\n",
      "Test set:\n",
      "default: Loss: 1.3499\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0457\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0608\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0415\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 569 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000220 drop: 0.000021 both: 0.000034\n",
      "Train Epoch: 569 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000015 both: 0.000525\n",
      "Train Epoch: 569 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000103 both: 0.000050\n",
      "Train Epoch: 569 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000137 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.3552\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0441\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0505\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0566\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 570 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000044 drop: 0.000014 both: 0.000048\n",
      "Train Epoch: 570 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000050 drop: 0.000005 both: 0.000025\n",
      "Train Epoch: 570 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000015 both: 0.000026\n",
      "Train Epoch: 570 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000067 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.3620\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0537\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.0638\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0757\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 571 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000008 both: 0.000016\n",
      "Train Epoch: 571 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000040 both: 0.000042\n",
      "Train Epoch: 571 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000019 both: 0.000002\n",
      "Train Epoch: 571 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000037 both: 0.000055\n",
      "Test set:\n",
      "default: Loss: 1.3692\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0584\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.0640\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0746\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 572 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000221 drop: 0.000012 both: 0.000012\n",
      "Train Epoch: 572 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000022 both: 0.000121\n",
      "Train Epoch: 572 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000026 both: 0.000013\n",
      "Train Epoch: 572 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000136 drop: 0.000014 both: 0.094974\n",
      "Test set:\n",
      "default: Loss: 1.3720\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0356\tAccuracy: 4401.0/5000 (88%)\n",
      "drop: Loss: 1.0752\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0810\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 573 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000022 both: 0.000143\n",
      "Train Epoch: 573 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000025 both: 0.000022\n",
      "Train Epoch: 573 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000012 both: 0.000101\n",
      "Train Epoch: 573 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000055 both: 0.135032\n",
      "Test set:\n",
      "default: Loss: 1.3797\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0349\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0830\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0565\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 574 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000018 both: 0.043612\n",
      "Train Epoch: 574 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000039 drop: 0.000006 both: 0.000139\n",
      "Train Epoch: 574 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000346 drop: 0.000026 both: 0.000483\n",
      "Train Epoch: 574 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000009 both: 0.000047\n",
      "Test set:\n",
      "default: Loss: 1.3824\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0331\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.0809\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0621\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 575 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000112 drop: 0.000011 both: 0.000863\n",
      "Train Epoch: 575 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000003 both: 0.000304\n",
      "Train Epoch: 575 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.112155 drop: 0.000008 both: 0.000008\n",
      "Train Epoch: 575 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000061 drop: 0.157606 both: 0.000073\n",
      "Test set:\n",
      "default: Loss: 1.3842\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0513\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.2470\tAccuracy: 4329.0/5000 (87%)\n",
      "both: Loss: 1.1042\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 576 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000174 drop: 0.002337 both: 0.000025\n",
      "Train Epoch: 576 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000961 drop: 0.056665 both: 0.000240\n",
      "Train Epoch: 576 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.026340 drop: 0.001376 both: 0.000088\n",
      "Train Epoch: 576 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.017554 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.3957\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0462\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0636\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0412\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 577 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000531 drop: 0.000093 both: 0.000216\n",
      "Train Epoch: 577 [10000/25000 (40%)]\tLosses default: 0.000094 bn: 0.000069 drop: 0.000023 both: 0.000064\n",
      "Train Epoch: 577 [20000/25000 (80%)]\tLosses default: 0.000095 bn: 0.000001 drop: 0.000007 both: 0.000006\n",
      "Train Epoch: 577 [25000/25000 (100%)]\tLosses default: 0.001085 bn: 0.005478 drop: 0.000035 both: 0.002794\n",
      "Test set:\n",
      "default: Loss: 1.1716\tAccuracy: 4398.0/5000 (88%)\n",
      "bn: Loss: 1.0664\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0705\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0405\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 578 [0/25000 (0%)]\tLosses default: 0.000099 bn: 0.022754 drop: 0.000006 both: 0.000044\n",
      "Train Epoch: 578 [10000/25000 (40%)]\tLosses default: 0.000011 bn: 0.007633 drop: 0.000233 both: 0.000280\n",
      "Train Epoch: 578 [20000/25000 (80%)]\tLosses default: 0.000024 bn: 0.000005 drop: 0.000086 both: 0.000007\n",
      "Train Epoch: 578 [25000/25000 (100%)]\tLosses default: 0.000350 bn: 0.000274 drop: 0.000038 both: 0.000317\n",
      "Test set:\n",
      "default: Loss: 1.1747\tAccuracy: 4406.0/5000 (88%)\n",
      "bn: Loss: 0.9880\tAccuracy: 4457.0/5000 (89%)\n",
      "drop: Loss: 1.0743\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0603\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 579 [0/25000 (0%)]\tLosses default: 0.000014 bn: 0.000266 drop: 0.000011 both: 0.000021\n",
      "Train Epoch: 579 [10000/25000 (40%)]\tLosses default: 0.000028 bn: 0.002040 drop: 0.001451 both: 0.000328\n",
      "Train Epoch: 579 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000010 drop: 0.000246 both: 0.000345\n",
      "Train Epoch: 579 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000094 drop: 0.000009 both: 0.003205\n",
      "Test set:\n",
      "default: Loss: 1.1843\tAccuracy: 4412.0/5000 (88%)\n",
      "bn: Loss: 1.0056\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.0745\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 0.9930\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 580 [0/25000 (0%)]\tLosses default: 0.000287 bn: 0.000009 drop: 0.000150 both: 0.000051\n",
      "Train Epoch: 580 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000013 drop: 0.000002 both: 0.000147\n",
      "Train Epoch: 580 [20000/25000 (80%)]\tLosses default: 0.000063 bn: 0.000036 drop: 0.000075 both: 0.002375\n",
      "Train Epoch: 580 [25000/25000 (100%)]\tLosses default: 0.000036 bn: 0.000019 drop: 0.000018 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1792\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0394\tAccuracy: 4447.0/5000 (89%)\n",
      "drop: Loss: 1.0749\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0276\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 581 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000058 drop: 0.000034 both: 0.000876\n",
      "Train Epoch: 581 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000006 both: 0.000057\n",
      "Train Epoch: 581 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000008 drop: 0.000003 both: 0.000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 581 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.121869 both: 0.000369\n",
      "Test set:\n",
      "default: Loss: 1.1888\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0279\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.0676\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0225\tAccuracy: 4422.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 582 [0/25000 (0%)]\tLosses default: 0.000008 bn: 0.000089 drop: 0.000047 both: 0.000009\n",
      "Train Epoch: 582 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.025982 drop: 0.002691 both: 0.002000\n",
      "Train Epoch: 582 [20000/25000 (80%)]\tLosses default: 0.000042 bn: 0.001767 drop: 0.002352 both: 0.000117\n",
      "Train Epoch: 582 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000101 drop: 0.000017 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.1969\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0155\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 1.0482\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0334\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 583 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000009 both: 0.000012\n",
      "Train Epoch: 583 [10000/25000 (40%)]\tLosses default: 0.000040 bn: 0.000105 drop: 0.001208 both: 0.000034\n",
      "Train Epoch: 583 [20000/25000 (80%)]\tLosses default: 0.000023 bn: 0.000450 drop: 0.000041 both: 0.000011\n",
      "Train Epoch: 583 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000037 drop: 0.000099 both: 0.000056\n",
      "Test set:\n",
      "default: Loss: 1.2040\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 0.9906\tAccuracy: 4455.0/5000 (89%)\n",
      "drop: Loss: 1.0674\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0448\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 584 [0/25000 (0%)]\tLosses default: 0.000033 bn: 0.000662 drop: 0.000014 both: 0.000025\n",
      "Train Epoch: 584 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000003 both: 0.000039\n",
      "Train Epoch: 584 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000041 both: 0.085569\n",
      "Train Epoch: 584 [25000/25000 (100%)]\tLosses default: 0.000018 bn: 0.000217 drop: 0.000616 both: 0.018566\n",
      "Test set:\n",
      "default: Loss: 1.2125\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0235\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.0779\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0273\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 585 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.025150 drop: 0.000179 both: 0.000346\n",
      "Train Epoch: 585 [10000/25000 (40%)]\tLosses default: 0.000024 bn: 0.000018 drop: 0.000020 both: 0.000039\n",
      "Train Epoch: 585 [20000/25000 (80%)]\tLosses default: 0.000033 bn: 0.000036 drop: 0.000060 both: 0.000073\n",
      "Train Epoch: 585 [25000/25000 (100%)]\tLosses default: 0.000024 bn: 0.000012 drop: 0.000061 both: 0.012816\n",
      "Test set:\n",
      "default: Loss: 1.2186\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0099\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0861\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0284\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 586 [0/25000 (0%)]\tLosses default: 0.000017 bn: 0.000008 drop: 0.000023 both: 0.000017\n",
      "Train Epoch: 586 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000015 drop: 0.000016 both: 0.002433\n",
      "Train Epoch: 586 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000051 drop: 0.000005 both: 0.000021\n",
      "Train Epoch: 586 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000008 drop: 0.000010 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.2243\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0227\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0786\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0295\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 587 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000006 drop: 0.000041 both: 0.001134\n",
      "Train Epoch: 587 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000035 drop: 0.000005 both: 0.000044\n",
      "Train Epoch: 587 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000010 drop: 0.000002 both: 0.000049\n",
      "Train Epoch: 587 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000027 drop: 0.000026 both: 0.000034\n",
      "Test set:\n",
      "default: Loss: 1.2315\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0105\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0808\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0228\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 588 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000018 drop: 0.000003 both: 0.001236\n",
      "Train Epoch: 588 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.000146 drop: 0.000025 both: 0.074364\n",
      "Train Epoch: 588 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000019 drop: 0.000020 both: 0.000129\n",
      "Train Epoch: 588 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000002 drop: 0.000064 both: 0.000124\n",
      "Test set:\n",
      "default: Loss: 1.2383\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0211\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 1.0844\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0903\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 589 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.009266 drop: 0.000014 both: 0.000053\n",
      "Train Epoch: 589 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000039 both: 0.000025\n",
      "Train Epoch: 589 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000037 drop: 0.000007 both: 0.000111\n",
      "Train Epoch: 589 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.012140 drop: 0.000097 both: 0.007609\n",
      "Test set:\n",
      "default: Loss: 1.2446\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0049\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0764\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0624\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 590 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000036 both: 0.001674\n",
      "Train Epoch: 590 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000010 drop: 0.000005 both: 0.001589\n",
      "Train Epoch: 590 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000011 drop: 0.000003 both: 0.000324\n",
      "Train Epoch: 590 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000012 both: 0.000069\n",
      "Test set:\n",
      "default: Loss: 1.2518\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0059\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.0988\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0474\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 591 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.002727 drop: 0.000004 both: 0.000753\n",
      "Train Epoch: 591 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000168 drop: 0.000024 both: 0.000099\n",
      "Train Epoch: 591 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000021 drop: 0.000004 both: 0.000149\n",
      "Train Epoch: 591 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000228 drop: 0.000006 both: 0.000246\n",
      "Test set:\n",
      "default: Loss: 1.2595\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.0305\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0867\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0450\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 592 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.009190 drop: 0.000002 both: 0.000111\n",
      "Train Epoch: 592 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000011 drop: 0.000005 both: 0.000085\n",
      "Train Epoch: 592 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000082 drop: 0.000015 both: 0.000488\n",
      "Train Epoch: 592 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000005 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.2657\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0329\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.1073\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0472\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 593 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000839 drop: 0.000007 both: 0.000004\n",
      "Train Epoch: 593 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000153 drop: 0.000039 both: 0.000004\n",
      "Train Epoch: 593 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000107 drop: 0.000895 both: 0.000181\n",
      "Train Epoch: 593 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000065 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.2713\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.0390\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0636\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0748\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 594 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000186 drop: 0.000378 both: 0.000039\n",
      "Train Epoch: 594 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000010 drop: 0.000018 both: 0.000004\n",
      "Train Epoch: 594 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000005 both: 0.000033\n",
      "Train Epoch: 594 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000037 drop: 0.000020 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.2788\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0684\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0985\tAccuracy: 4362.0/5000 (87%)\n",
      "both: Loss: 1.0193\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 595 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.053784 drop: 0.000530 both: 0.000032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 595 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.132469 drop: 0.000047 both: 0.000463\n",
      "Train Epoch: 595 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000080 drop: 0.000015 both: 0.000017\n",
      "Train Epoch: 595 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.006007 drop: 0.000084 both: 0.028499\n",
      "Test set:\n",
      "default: Loss: 1.2839\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0224\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0552\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0710\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 596 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000045 drop: 0.000076 both: 0.001043\n",
      "Train Epoch: 596 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000272 drop: 0.000028 both: 0.000059\n",
      "Train Epoch: 596 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000323 drop: 0.000033 both: 0.000052\n",
      "Train Epoch: 596 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000014 drop: 0.000045 both: 0.186445\n",
      "Test set:\n",
      "default: Loss: 1.2886\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0333\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.0568\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0805\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 597 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000014 both: 0.020774\n",
      "Train Epoch: 597 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000123 drop: 0.000023 both: 0.033818\n",
      "Train Epoch: 597 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000323 drop: 0.000006 both: 0.004568\n",
      "Train Epoch: 597 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000019 both: 0.000097\n",
      "Test set:\n",
      "default: Loss: 1.2951\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0374\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0743\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0694\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 598 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000169 drop: 0.000044 both: 0.000463\n",
      "Train Epoch: 598 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000283 drop: 0.000066 both: 0.000004\n",
      "Train Epoch: 598 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000018 both: 0.000038\n",
      "Train Epoch: 598 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000613 drop: 0.000014 both: 0.000371\n",
      "Test set:\n",
      "default: Loss: 1.3004\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0205\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0875\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0754\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 599 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000098 drop: 0.000071 both: 0.000139\n",
      "Train Epoch: 599 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000060 both: 0.000018\n",
      "Train Epoch: 599 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000869 drop: 0.000027 both: 0.000010\n",
      "Train Epoch: 599 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000277 drop: 0.000376 both: 0.000237\n",
      "Test set:\n",
      "default: Loss: 1.3054\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0210\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0960\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0405\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 600 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000004 drop: 0.000041 both: 0.000023\n",
      "Train Epoch: 600 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.006159 drop: 0.000010 both: 0.000024\n",
      "Train Epoch: 600 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000002 drop: 0.000003 both: 0.000006\n",
      "Train Epoch: 600 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000107 drop: 0.000003 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3124\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0515\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0848\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0899\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 601 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000329 both: 0.000018\n",
      "Train Epoch: 601 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000077 drop: 0.000063 both: 0.001391\n",
      "Train Epoch: 601 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000320 drop: 0.000008 both: 0.000260\n",
      "Train Epoch: 601 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000051 both: 0.051236\n",
      "Test set:\n",
      "default: Loss: 1.3171\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0401\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1003\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0846\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 602 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000230 drop: 0.000001 both: 0.000009\n",
      "Train Epoch: 602 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000024 both: 0.005464\n",
      "Train Epoch: 602 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001021 drop: 0.000951 both: 0.000006\n",
      "Train Epoch: 602 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.019855 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.3216\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0469\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1659\tAccuracy: 4319.0/5000 (86%)\n",
      "both: Loss: 1.0794\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 603 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000418 both: 0.000011\n",
      "Train Epoch: 603 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000055 drop: 0.005630 both: 0.002644\n",
      "Train Epoch: 603 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000053 drop: 0.000121 both: 0.000031\n",
      "Train Epoch: 603 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000017 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.3276\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0216\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.0752\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0697\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 604 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000079 both: 0.000065\n",
      "Train Epoch: 604 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000024 both: 0.000013\n",
      "Train Epoch: 604 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000106 both: 0.000018\n",
      "Train Epoch: 604 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000183 both: 0.000044\n",
      "Test set:\n",
      "default: Loss: 1.3337\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0493\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0745\tAccuracy: 4372.0/5000 (87%)\n",
      "both: Loss: 1.0431\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 605 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000091 both: 0.000033\n",
      "Train Epoch: 605 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000357 drop: 0.000028 both: 0.090378\n",
      "Train Epoch: 605 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000143 drop: 0.000034 both: 0.000043\n",
      "Train Epoch: 605 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000035 both: 0.036268\n",
      "Test set:\n",
      "default: Loss: 1.3370\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0257\tAccuracy: 4442.0/5000 (89%)\n",
      "drop: Loss: 1.0691\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0523\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 606 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000052 drop: 0.000068 both: 0.002370\n",
      "Train Epoch: 606 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000106 both: 0.003304\n",
      "Train Epoch: 606 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000092 drop: 0.000027 both: 0.000075\n",
      "Train Epoch: 606 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000028 both: 0.000257\n",
      "Test set:\n",
      "default: Loss: 1.3417\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0386\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0869\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0492\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 607 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000159 drop: 0.000008 both: 0.000016\n",
      "Train Epoch: 607 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000021 both: 0.000015\n",
      "Train Epoch: 607 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000244 drop: 0.000005 both: 0.000062\n",
      "Train Epoch: 607 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000030 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.3477\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0426\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0745\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0378\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 608 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000010 both: 0.000009\n",
      "Train Epoch: 608 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000051 both: 0.000008\n",
      "Train Epoch: 608 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000021 both: 0.000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 608 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000487 drop: 0.000067 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.3499\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0590\tAccuracy: 4401.0/5000 (88%)\n",
      "drop: Loss: 1.0999\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0423\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 609 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000100 both: 0.000376\n",
      "Train Epoch: 609 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000100 drop: 0.000054 both: 0.001297\n",
      "Train Epoch: 609 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000003 both: 0.000018\n",
      "Train Epoch: 609 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000007 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.3572\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0816\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.0811\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0574\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 610 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.002312 drop: 0.000021 both: 0.000008\n",
      "Train Epoch: 610 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000222 drop: 0.000073 both: 0.000026\n",
      "Train Epoch: 610 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000054 drop: 0.000006 both: 0.088723\n",
      "Train Epoch: 610 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000223 drop: 0.000001 both: 0.001270\n",
      "Test set:\n",
      "default: Loss: 1.3572\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0555\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0887\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0539\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 611 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.008198 drop: 0.000082 both: 0.003603\n",
      "Train Epoch: 611 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000023 both: 0.000325\n",
      "Train Epoch: 611 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000100 drop: 0.000036 both: 0.000032\n",
      "Train Epoch: 611 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000064 drop: 0.000001 both: 0.008337\n",
      "Test set:\n",
      "default: Loss: 1.3608\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0970\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 1.0723\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0666\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 612 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000009 both: 0.000016\n",
      "Train Epoch: 612 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000264 drop: 0.000003 both: 0.000024\n",
      "Train Epoch: 612 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000090 drop: 0.000118 both: 0.000002\n",
      "Train Epoch: 612 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000002 both: 0.000078\n",
      "Test set:\n",
      "default: Loss: 1.3662\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0533\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0918\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0614\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 613 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.003869 drop: 0.000015 both: 0.000075\n",
      "Train Epoch: 613 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000009 both: 0.002150\n",
      "Train Epoch: 613 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000003 both: 0.000029\n",
      "Train Epoch: 613 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.204826 both: 0.000031\n",
      "Test set:\n",
      "default: Loss: 1.3693\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0554\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.1146\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0246\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 614 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000121 both: 0.000098\n",
      "Train Epoch: 614 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000703 both: 0.016721\n",
      "Train Epoch: 614 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.001152 both: 0.000912\n",
      "Train Epoch: 614 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.001791 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.3736\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0482\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0577\tAccuracy: 4361.0/5000 (87%)\n",
      "both: Loss: 1.0303\tAccuracy: 4415.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 615 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000065 both: 0.000005\n",
      "Train Epoch: 615 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000083 drop: 0.000353 both: 0.000673\n",
      "Train Epoch: 615 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000106 both: 0.000075\n",
      "Train Epoch: 615 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000063 drop: 0.000077 both: 0.072184\n",
      "Test set:\n",
      "default: Loss: 1.3774\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0123\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0531\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0696\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 616 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000053 drop: 0.000011 both: 0.000037\n",
      "Train Epoch: 616 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000347 drop: 0.000063 both: 0.000005\n",
      "Train Epoch: 616 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000218 drop: 0.000183 both: 0.000031\n",
      "Train Epoch: 616 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000012 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.3792\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0122\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.0478\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0447\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 617 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000024 both: 0.000018\n",
      "Train Epoch: 617 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000003 both: 0.000177\n",
      "Train Epoch: 617 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000013 both: 0.000044\n",
      "Train Epoch: 617 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000090 drop: 0.000017 both: 0.000089\n",
      "Test set:\n",
      "default: Loss: 1.3819\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0149\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0556\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0909\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 618 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000002 both: 0.000290\n",
      "Train Epoch: 618 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000044 both: 0.000284\n",
      "Train Epoch: 618 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000005 both: 0.002936\n",
      "Train Epoch: 618 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000128 both: 0.000040\n",
      "Test set:\n",
      "default: Loss: 1.3856\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0420\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.0575\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0468\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 619 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000057 drop: 0.000010 both: 0.001224\n",
      "Train Epoch: 619 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000042 both: 0.000035\n",
      "Train Epoch: 619 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000002 both: 0.000036\n",
      "Train Epoch: 619 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000010 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 1.3859\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0731\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0725\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0747\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 620 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.002041 drop: 0.000007 both: 0.000580\n",
      "Train Epoch: 620 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000011 both: 0.001384\n",
      "Train Epoch: 620 [20000/25000 (80%)]\tLosses default: 0.219489 bn: 0.000026 drop: 0.000016 both: 0.000156\n",
      "Train Epoch: 620 [25000/25000 (100%)]\tLosses default: 0.019370 bn: 0.000003 drop: 0.000007 both: 0.000071\n",
      "Test set:\n",
      "default: Loss: 1.1868\tAccuracy: 4389.0/5000 (88%)\n",
      "bn: Loss: 1.0369\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0666\tAccuracy: 4408.0/5000 (88%)\n",
      "both: Loss: 1.0547\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 621 [0/25000 (0%)]\tLosses default: 0.008888 bn: 0.000003 drop: 0.000016 both: 0.000018\n",
      "Train Epoch: 621 [10000/25000 (40%)]\tLosses default: 0.000242 bn: 0.000042 drop: 0.000007 both: 0.000188\n",
      "Train Epoch: 621 [20000/25000 (80%)]\tLosses default: 0.000078 bn: 0.000001 drop: 0.000003 both: 0.000004\n",
      "Train Epoch: 621 [25000/25000 (100%)]\tLosses default: 0.000124 bn: 0.000219 drop: 0.000006 both: 0.000066\n",
      "Test set:\n",
      "default: Loss: 1.2015\tAccuracy: 4393.0/5000 (88%)\n",
      "bn: Loss: 1.0582\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0875\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0579\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 622 [0/25000 (0%)]\tLosses default: 0.000048 bn: 0.002800 drop: 0.000011 both: 0.000155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 622 [10000/25000 (40%)]\tLosses default: 0.000663 bn: 0.000040 drop: 0.000034 both: 0.000043\n",
      "Train Epoch: 622 [20000/25000 (80%)]\tLosses default: 0.000575 bn: 0.000047 drop: 0.000001 both: 0.000008\n",
      "Train Epoch: 622 [25000/25000 (100%)]\tLosses default: 0.118349 bn: 0.000044 drop: 0.000011 both: 0.000225\n",
      "Test set:\n",
      "default: Loss: 1.2090\tAccuracy: 4406.0/5000 (88%)\n",
      "bn: Loss: 1.0653\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0765\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0671\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 623 [0/25000 (0%)]\tLosses default: 0.000204 bn: 0.000413 drop: 0.000047 both: 0.000011\n",
      "Train Epoch: 623 [10000/25000 (40%)]\tLosses default: 0.000073 bn: 0.000125 drop: 0.000017 both: 0.000028\n",
      "Train Epoch: 623 [20000/25000 (80%)]\tLosses default: 0.000268 bn: 0.000013 drop: 0.000004 both: 0.000475\n",
      "Train Epoch: 623 [25000/25000 (100%)]\tLosses default: 0.000020 bn: 0.000283 drop: 0.000052 both: 0.000173\n",
      "Test set:\n",
      "default: Loss: 1.1581\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0783\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0725\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0443\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 624 [0/25000 (0%)]\tLosses default: 0.000037 bn: 0.000080 drop: 0.000004 both: 0.009393\n",
      "Train Epoch: 624 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.001234 drop: 0.000006 both: 0.000031\n",
      "Train Epoch: 624 [20000/25000 (80%)]\tLosses default: 0.000854 bn: 0.017210 drop: 0.000257 both: 0.000057\n",
      "Train Epoch: 624 [25000/25000 (100%)]\tLosses default: 0.000083 bn: 0.000028 drop: 0.018647 both: 0.000055\n",
      "Test set:\n",
      "default: Loss: 1.2235\tAccuracy: 4410.0/5000 (88%)\n",
      "bn: Loss: 1.0492\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.0743\tAccuracy: 4355.0/5000 (87%)\n",
      "both: Loss: 1.0617\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 625 [0/25000 (0%)]\tLosses default: 0.000026 bn: 0.000033 drop: 0.036972 both: 0.000032\n",
      "Train Epoch: 625 [10000/25000 (40%)]\tLosses default: 0.013567 bn: 0.000008 drop: 0.003134 both: 0.000099\n",
      "Train Epoch: 625 [20000/25000 (80%)]\tLosses default: 0.000831 bn: 0.000002 drop: 0.000186 both: 0.000004\n",
      "Train Epoch: 625 [25000/25000 (100%)]\tLosses default: 0.000104 bn: 0.000045 drop: 0.004768 both: 0.000086\n",
      "Test set:\n",
      "default: Loss: 1.2000\tAccuracy: 4386.0/5000 (88%)\n",
      "bn: Loss: 1.0669\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0786\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0447\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 626 [0/25000 (0%)]\tLosses default: 0.010902 bn: 0.000034 drop: 0.000014 both: 0.013555\n",
      "Train Epoch: 626 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000003 drop: 0.000675 both: 0.000015\n",
      "Train Epoch: 626 [20000/25000 (80%)]\tLosses default: 0.000048 bn: 0.000030 drop: 0.000006 both: 0.000012\n",
      "Train Epoch: 626 [25000/25000 (100%)]\tLosses default: 0.000014 bn: 0.000009 drop: 0.001927 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.1418\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0467\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.0477\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0810\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 627 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000031 both: 0.000022\n",
      "Train Epoch: 627 [10000/25000 (40%)]\tLosses default: 0.000041 bn: 0.000035 drop: 0.000012 both: 0.000321\n",
      "Train Epoch: 627 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000097 both: 0.000216\n",
      "Train Epoch: 627 [25000/25000 (100%)]\tLosses default: 0.000036 bn: 0.000014 drop: 0.000537 both: 0.001951\n",
      "Test set:\n",
      "default: Loss: 1.1428\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0505\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0597\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0582\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 628 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000016 both: 0.000271\n",
      "Train Epoch: 628 [10000/25000 (40%)]\tLosses default: 0.000218 bn: 0.000101 drop: 0.000194 both: 0.000018\n",
      "Train Epoch: 628 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000007 both: 0.000033\n",
      "Train Epoch: 628 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000002 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.1483\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0559\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.0576\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0571\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 629 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.000028 drop: 0.000063 both: 0.000050\n",
      "Train Epoch: 629 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000009 drop: 0.000048 both: 0.000023\n",
      "Train Epoch: 629 [20000/25000 (80%)]\tLosses default: 0.000025 bn: 0.000089 drop: 0.000133 both: 0.000046\n",
      "Train Epoch: 629 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.039861 drop: 0.000051 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.1529\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0504\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.0649\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0575\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 630 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.000045 drop: 0.000066 both: 0.000023\n",
      "Train Epoch: 630 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000022 drop: 0.000015 both: 0.000021\n",
      "Train Epoch: 630 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000047 both: 0.000059\n",
      "Train Epoch: 630 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000000 drop: 0.000025 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.1588\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0421\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.0746\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 1.0866\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 631 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000008 both: 0.000015\n",
      "Train Epoch: 631 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.000004 drop: 0.000113 both: 0.000005\n",
      "Train Epoch: 631 [20000/25000 (80%)]\tLosses default: 0.000034 bn: 0.000011 drop: 0.000028 both: 0.000017\n",
      "Train Epoch: 631 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000014 drop: 0.000022 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.1656\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0504\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0509\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0834\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 632 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000005 drop: 0.000004 both: 0.029507\n",
      "Train Epoch: 632 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000009 drop: 0.000006 both: 0.000138\n",
      "Train Epoch: 632 [20000/25000 (80%)]\tLosses default: 0.000031 bn: 0.000020 drop: 0.000081 both: 0.000108\n",
      "Train Epoch: 632 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000000 drop: 0.000006 both: 0.000063\n",
      "Test set:\n",
      "default: Loss: 1.1716\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0556\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0933\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0662\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 633 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.000022 drop: 0.000001 both: 0.000369\n",
      "Train Epoch: 633 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000022 drop: 0.000038 both: 0.000368\n",
      "Train Epoch: 633 [20000/25000 (80%)]\tLosses default: 0.000010 bn: 0.000010 drop: 0.000012 both: 0.000094\n",
      "Train Epoch: 633 [25000/25000 (100%)]\tLosses default: 0.000023 bn: 0.000794 drop: 0.000006 both: 0.065687\n",
      "Test set:\n",
      "default: Loss: 1.1776\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0615\tAccuracy: 4404.0/5000 (88%)\n",
      "drop: Loss: 1.0616\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0682\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 634 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000887 drop: 0.000057 both: 0.000015\n",
      "Train Epoch: 634 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000007 drop: 0.000010 both: 0.000088\n",
      "Train Epoch: 634 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000055 drop: 0.000062 both: 0.000004\n",
      "Train Epoch: 634 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000662 drop: 0.000005 both: 0.000366\n",
      "Test set:\n",
      "default: Loss: 1.1830\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0493\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0723\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0656\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 635 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000044 drop: 0.000005 both: 0.036294\n",
      "Train Epoch: 635 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000052 drop: 0.000010 both: 0.000101\n",
      "Train Epoch: 635 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000020 drop: 0.000016 both: 0.000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 635 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000269 drop: 0.000020 both: 0.000054\n",
      "Test set:\n",
      "default: Loss: 1.1900\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0531\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0908\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0658\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 636 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000005 drop: 0.000016 both: 0.001528\n",
      "Train Epoch: 636 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000210 drop: 0.000003 both: 0.000092\n",
      "Train Epoch: 636 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000031 drop: 0.000032 both: 0.000031\n",
      "Train Epoch: 636 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000077 drop: 0.000014 both: 0.000407\n",
      "Test set:\n",
      "default: Loss: 1.1959\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0565\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0954\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.1060\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 637 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000012 drop: 0.000097 both: 0.004713\n",
      "Train Epoch: 637 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000050 drop: 0.000002 both: 0.000059\n",
      "Train Epoch: 637 [20000/25000 (80%)]\tLosses default: 0.000021 bn: 0.000029 drop: 0.130428 both: 0.000154\n",
      "Train Epoch: 637 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.038175 both: 0.001021\n",
      "Test set:\n",
      "default: Loss: 1.2014\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0552\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.2122\tAccuracy: 4327.0/5000 (87%)\n",
      "both: Loss: 1.0608\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 638 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000049 drop: 0.008181 both: 0.000009\n",
      "Train Epoch: 638 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000007 drop: 0.042071 both: 0.000035\n",
      "Train Epoch: 638 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000208 drop: 0.000036 both: 0.000510\n",
      "Train Epoch: 638 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000059 drop: 0.000249 both: 0.183741\n",
      "Test set:\n",
      "default: Loss: 1.2072\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0496\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0409\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0720\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 639 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000040 drop: 0.000117 both: 0.000054\n",
      "Train Epoch: 639 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.003833 drop: 0.000402 both: 0.039207\n",
      "Train Epoch: 639 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000041 drop: 0.000061 both: 0.000134\n",
      "Train Epoch: 639 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000071 drop: 0.001502 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.2129\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0735\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.0863\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0945\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 640 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000003 drop: 0.000024 both: 0.000026\n",
      "Train Epoch: 640 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000009 drop: 0.000031 both: 0.000014\n",
      "Train Epoch: 640 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000002\n",
      "Train Epoch: 640 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.001140 drop: 0.000023 both: 0.000244\n",
      "Test set:\n",
      "default: Loss: 1.2198\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0676\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0980\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0846\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 641 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000200 drop: 0.000126 both: 0.000006\n",
      "Train Epoch: 641 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.049417 drop: 0.000019 both: 0.000903\n",
      "Train Epoch: 641 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000859 drop: 0.000013 both: 0.000066\n",
      "Train Epoch: 641 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000011 drop: 0.000009 both: 0.001466\n",
      "Test set:\n",
      "default: Loss: 1.2263\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0790\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0804\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0652\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 642 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000034 drop: 0.000017 both: 0.000041\n",
      "Train Epoch: 642 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000009 both: 0.000935\n",
      "Train Epoch: 642 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000198 both: 0.000005\n",
      "Train Epoch: 642 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000012 both: 0.000084\n",
      "Test set:\n",
      "default: Loss: 1.2323\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.1059\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1332\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.0731\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 643 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000099 drop: 0.000259 both: 0.000007\n",
      "Train Epoch: 643 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000063 drop: 0.000023 both: 0.000059\n",
      "Train Epoch: 643 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000593 drop: 0.000041 both: 0.000009\n",
      "Train Epoch: 643 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000013 drop: 0.001808 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2399\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0886\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0970\tAccuracy: 4358.0/5000 (87%)\n",
      "both: Loss: 1.0617\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 644 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.001059 drop: 0.001521 both: 0.000006\n",
      "Train Epoch: 644 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000022 drop: 0.007922 both: 0.000023\n",
      "Train Epoch: 644 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000002\n",
      "Train Epoch: 644 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000217 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2460\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0490\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0592\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.1072\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 645 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000059 drop: 0.000193 both: 0.000089\n",
      "Train Epoch: 645 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000012 drop: 0.000039 both: 0.000021\n",
      "Train Epoch: 645 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.014924 both: 0.000881\n",
      "Train Epoch: 645 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000106 drop: 0.000027 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.2530\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0600\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.0798\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.0827\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 646 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000033 drop: 0.000023 both: 0.000062\n",
      "Train Epoch: 646 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000224 both: 0.000101\n",
      "Train Epoch: 646 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.054332 drop: 0.000236 both: 0.000018\n",
      "Train Epoch: 646 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.001381 drop: 0.000004 both: 0.000070\n",
      "Test set:\n",
      "default: Loss: 1.2581\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0580\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.0831\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 0.9984\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 647 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.028904 drop: 0.000030 both: 0.000339\n",
      "Train Epoch: 647 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.011189 drop: 0.000015 both: 0.001868\n",
      "Train Epoch: 647 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000012 both: 0.001349\n",
      "Train Epoch: 647 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000026 both: 0.000144\n",
      "Test set:\n",
      "default: Loss: 1.2668\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0782\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0632\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 1.0415\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 648 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000045 drop: 0.000135 both: 0.000796\n",
      "Train Epoch: 648 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000044 drop: 0.000022 both: 0.000049\n",
      "Train Epoch: 648 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000005 both: 0.000009\n",
      "Train Epoch: 648 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000525 drop: 0.000011 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.2743\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0438\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0653\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.0517\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 649 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000070 both: 0.002093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 649 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000573 drop: 0.000062 both: 0.000016\n",
      "Train Epoch: 649 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000054 drop: 0.000196 both: 0.000012\n",
      "Train Epoch: 649 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000010 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2794\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0533\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0755\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0653\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 650 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000110 both: 0.000033\n",
      "Train Epoch: 650 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000013 both: 0.000011\n",
      "Train Epoch: 650 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000013 both: 0.000215\n",
      "Train Epoch: 650 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000132 drop: 0.000102 both: 0.000156\n",
      "Test set:\n",
      "default: Loss: 1.2866\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0341\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.1013\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 1.0540\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 651 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000030 drop: 0.000353 both: 0.000013\n",
      "Train Epoch: 651 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000032 both: 0.000022\n",
      "Train Epoch: 651 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000029 both: 0.004232\n",
      "Train Epoch: 651 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000006 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.2935\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0091\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.0821\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 1.0684\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 652 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000006 both: 0.000034\n",
      "Train Epoch: 652 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000030 both: 0.001482\n",
      "Train Epoch: 652 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000001 both: 0.000005\n",
      "Train Epoch: 652 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000001 both: 0.015047\n",
      "Test set:\n",
      "default: Loss: 1.3011\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0266\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0779\tAccuracy: 4408.0/5000 (88%)\n",
      "both: Loss: 1.0489\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 653 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000927 drop: 0.000026 both: 0.000005\n",
      "Train Epoch: 653 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000137 drop: 0.000002 both: 0.000010\n",
      "Train Epoch: 653 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000004 both: 0.000009\n",
      "Train Epoch: 653 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000056 drop: 0.000029 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.3052\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0845\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0790\tAccuracy: 4420.0/5000 (88%)\n",
      "both: Loss: 1.0441\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 654 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000085 drop: 0.000003 both: 0.000075\n",
      "Train Epoch: 654 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000016 both: 0.024428\n",
      "Train Epoch: 654 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.023682 drop: 0.000007 both: 0.000008\n",
      "Train Epoch: 654 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000426 drop: 0.000044 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.3125\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0823\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.0940\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0704\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 655 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000015 both: 0.000004\n",
      "Train Epoch: 655 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000039 drop: 0.000037 both: 0.000007\n",
      "Train Epoch: 655 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000148 drop: 0.000003 both: 0.000013\n",
      "Train Epoch: 655 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000028\n",
      "Test set:\n",
      "default: Loss: 1.3188\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0745\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 1.0996\tAccuracy: 4409.0/5000 (88%)\n",
      "both: Loss: 1.0561\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 656 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000010 both: 0.000065\n",
      "Train Epoch: 656 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000007 both: 0.000558\n",
      "Train Epoch: 656 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000008 both: 0.000035\n",
      "Train Epoch: 656 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000005 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.3270\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0415\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 1.0884\tAccuracy: 4418.0/5000 (88%)\n",
      "both: Loss: 1.0568\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 657 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000404 drop: 0.000002 both: 0.000786\n",
      "Train Epoch: 657 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000020 both: 0.000005\n",
      "Train Epoch: 657 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000000 both: 0.000029\n",
      "Train Epoch: 657 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000235 drop: 0.000005 both: 0.000434\n",
      "Test set:\n",
      "default: Loss: 1.3305\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0558\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1341\tAccuracy: 4410.0/5000 (88%)\n",
      "both: Loss: 1.0723\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 658 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000005 both: 0.025103\n",
      "Train Epoch: 658 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.005062 drop: 0.000001 both: 0.000037\n",
      "Train Epoch: 658 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000011 both: 0.000010\n",
      "Train Epoch: 658 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000013 both: 0.000111\n",
      "Test set:\n",
      "default: Loss: 1.3355\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0629\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1190\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0606\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 659 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.009001 drop: 0.000007 both: 0.000076\n",
      "Train Epoch: 659 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000148 drop: 0.000003 both: 0.000004\n",
      "Train Epoch: 659 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000827 drop: 0.000008 both: 0.000128\n",
      "Train Epoch: 659 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000059 drop: 0.000005 both: 0.000560\n",
      "Test set:\n",
      "default: Loss: 1.3411\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0280\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1820\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0655\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 660 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.011263 drop: 0.000009 both: 0.000014\n",
      "Train Epoch: 660 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.081105 both: 0.000003\n",
      "Train Epoch: 660 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000383 both: 0.001225\n",
      "Train Epoch: 660 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.024467 both: 0.000058\n",
      "Test set:\n",
      "default: Loss: 1.3445\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0632\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.0825\tAccuracy: 4360.0/5000 (87%)\n",
      "both: Loss: 1.0560\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 661 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000314 drop: 0.000923 both: 0.000009\n",
      "Train Epoch: 661 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000992 drop: 0.000340 both: 0.000071\n",
      "Train Epoch: 661 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.002082 both: 0.001211\n",
      "Train Epoch: 661 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000132 drop: 0.000007 both: 0.001294\n",
      "Test set:\n",
      "default: Loss: 1.3503\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0273\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0691\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0731\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 662 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000265 drop: 0.000056 both: 0.000040\n",
      "Train Epoch: 662 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000050 drop: 0.000030 both: 0.000040\n",
      "Train Epoch: 662 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.027137 drop: 0.000006 both: 0.000013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 662 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000068 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.3541\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0252\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0789\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0716\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 663 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000011 both: 0.000001\n",
      "Train Epoch: 663 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000013 both: 0.010209\n",
      "Train Epoch: 663 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000017 both: 0.000147\n",
      "Train Epoch: 663 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000433 drop: 0.000006 both: 0.000089\n",
      "Test set:\n",
      "default: Loss: 1.3554\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0273\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0691\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.1036\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 664 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000318 drop: 0.000010 both: 0.000044\n",
      "Train Epoch: 664 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000014 both: 0.000121\n",
      "Train Epoch: 664 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000120 drop: 0.000041 both: 0.000007\n",
      "Train Epoch: 664 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000068 drop: 0.000018 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.3589\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.0788\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.0873\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0547\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 665 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000270 both: 0.003309\n",
      "Train Epoch: 665 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000013 both: 0.000003\n",
      "Train Epoch: 665 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000002 both: 0.000009\n",
      "Train Epoch: 665 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000042 both: 0.000627\n",
      "Test set:\n",
      "default: Loss: 1.3592\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0652\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.0818\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0369\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 666 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000089 drop: 0.000003 both: 0.000005\n",
      "Train Epoch: 666 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000354 drop: 0.000022 both: 0.000296\n",
      "Train Epoch: 666 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000058 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 666 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000092 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 1.3587\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0499\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0910\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0445\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 667 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000429 drop: 0.000212 both: 0.002289\n",
      "Train Epoch: 667 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000008 both: 0.000091\n",
      "Train Epoch: 667 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000105 drop: 0.000034 both: 0.000049\n",
      "Train Epoch: 667 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000006 both: 0.000361\n",
      "Test set:\n",
      "default: Loss: 1.3586\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0335\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0894\tAccuracy: 4408.0/5000 (88%)\n",
      "both: Loss: 1.0938\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 668 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000002 both: 0.000025\n",
      "Train Epoch: 668 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000024 both: 0.002717\n",
      "Train Epoch: 668 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000004 both: 0.000014\n",
      "Train Epoch: 668 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000699 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3591\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0523\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1425\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0330\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 669 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000044 drop: 0.000022 both: 0.000035\n",
      "Train Epoch: 669 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.017855 both: 0.000024\n",
      "Train Epoch: 669 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001426 drop: 0.003790 both: 0.000031\n",
      "Train Epoch: 669 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000693 drop: 0.000094 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.3707\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1121\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 1.0947\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0239\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 670 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000132 both: 0.003361\n",
      "Train Epoch: 670 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000003 both: 0.000032\n",
      "Train Epoch: 670 [20000/25000 (80%)]\tLosses default: 0.016819 bn: 0.000050 drop: 0.000080 both: 0.000010\n",
      "Train Epoch: 670 [25000/25000 (100%)]\tLosses default: 0.000984 bn: 0.000029 drop: 0.000066 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.0326\tAccuracy: 4378.0/5000 (88%)\n",
      "bn: Loss: 1.0552\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0914\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0202\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 671 [0/25000 (0%)]\tLosses default: 0.000614 bn: 0.002769 drop: 0.000054 both: 0.001551\n",
      "Train Epoch: 671 [10000/25000 (40%)]\tLosses default: 0.006397 bn: 0.000012 drop: 0.000013 both: 0.000517\n",
      "Train Epoch: 671 [20000/25000 (80%)]\tLosses default: 0.014655 bn: 0.000195 drop: 0.000399 both: 0.000022\n",
      "Train Epoch: 671 [25000/25000 (100%)]\tLosses default: 0.000032 bn: 0.000016 drop: 0.000060 both: 0.000071\n",
      "Test set:\n",
      "default: Loss: 1.0617\tAccuracy: 4413.0/5000 (88%)\n",
      "bn: Loss: 1.0209\tAccuracy: 4446.0/5000 (89%)\n",
      "drop: Loss: 1.1052\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0263\tAccuracy: 4414.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 672 [0/25000 (0%)]\tLosses default: 0.001697 bn: 0.000009 drop: 0.000482 both: 0.000009\n",
      "Train Epoch: 672 [10000/25000 (40%)]\tLosses default: 0.000324 bn: 0.000000 drop: 0.000056 both: 0.000002\n",
      "Train Epoch: 672 [20000/25000 (80%)]\tLosses default: 0.000011 bn: 0.000036 drop: 0.000004 both: 0.000034\n",
      "Train Epoch: 672 [25000/25000 (100%)]\tLosses default: 0.000011 bn: 0.000010 drop: 0.000068 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.0779\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0427\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.0829\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0393\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 673 [0/25000 (0%)]\tLosses default: 0.000148 bn: 0.000012 drop: 0.000003 both: 0.000058\n",
      "Train Epoch: 673 [10000/25000 (40%)]\tLosses default: 0.000125 bn: 0.000003 drop: 0.000005 both: 0.000081\n",
      "Train Epoch: 673 [20000/25000 (80%)]\tLosses default: 0.000335 bn: 0.000001 drop: 0.000042 both: 0.000163\n",
      "Train Epoch: 673 [25000/25000 (100%)]\tLosses default: 0.000272 bn: 0.000055 drop: 0.000003 both: 0.000048\n",
      "Test set:\n",
      "default: Loss: 1.0914\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0276\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 1.0779\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0371\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 674 [0/25000 (0%)]\tLosses default: 0.000019 bn: 0.000011 drop: 0.000035 both: 0.000076\n",
      "Train Epoch: 674 [10000/25000 (40%)]\tLosses default: 0.000012 bn: 0.000024 drop: 0.000015 both: 0.000024\n",
      "Train Epoch: 674 [20000/25000 (80%)]\tLosses default: 0.000009 bn: 0.000006 drop: 0.000005 both: 0.000108\n",
      "Train Epoch: 674 [25000/25000 (100%)]\tLosses default: 0.000129 bn: 0.000022 drop: 0.000042 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.1062\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0343\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.0878\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0438\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 675 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.001148 drop: 0.000003 both: 0.000029\n",
      "Train Epoch: 675 [10000/25000 (40%)]\tLosses default: 0.000055 bn: 0.000736 drop: 0.000012 both: 0.000335\n",
      "Train Epoch: 675 [20000/25000 (80%)]\tLosses default: 0.000037 bn: 0.000239 drop: 0.000008 both: 0.000166\n",
      "Train Epoch: 675 [25000/25000 (100%)]\tLosses default: 0.000052 bn: 0.005722 drop: 0.000026 both: 0.034619\n",
      "Test set:\n",
      "default: Loss: 1.1178\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0576\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0773\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0569\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 676 [0/25000 (0%)]\tLosses default: 0.000018 bn: 0.000035 drop: 0.000100 both: 0.000091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 676 [10000/25000 (40%)]\tLosses default: 0.000016 bn: 0.000192 drop: 0.000020 both: 0.000121\n",
      "Train Epoch: 676 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000336 drop: 0.000014 both: 0.001210\n",
      "Train Epoch: 676 [25000/25000 (100%)]\tLosses default: 0.000019 bn: 0.000210 drop: 0.000007 both: 0.000023\n",
      "Test set:\n",
      "default: Loss: 1.1299\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.0269\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.0985\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0478\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 677 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000025 drop: 0.000056 both: 0.000150\n",
      "Train Epoch: 677 [10000/25000 (40%)]\tLosses default: 0.000047 bn: 0.000066 drop: 0.000004 both: 0.000026\n",
      "Train Epoch: 677 [20000/25000 (80%)]\tLosses default: 0.000016 bn: 0.000017 drop: 0.000023 both: 0.000003\n",
      "Train Epoch: 677 [25000/25000 (100%)]\tLosses default: 0.000050 bn: 0.000003 drop: 0.000003 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.1431\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0441\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.0997\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0476\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 678 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000030 drop: 0.000061 both: 0.000139\n",
      "Train Epoch: 678 [10000/25000 (40%)]\tLosses default: 0.000017 bn: 0.000009 drop: 0.000019 both: 0.001686\n",
      "Train Epoch: 678 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000016 drop: 0.000003 both: 0.000771\n",
      "Train Epoch: 678 [25000/25000 (100%)]\tLosses default: 0.000039 bn: 0.000035 drop: 0.000022 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.1532\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0581\tAccuracy: 4444.0/5000 (89%)\n",
      "drop: Loss: 1.1070\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0393\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 679 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000036 drop: 0.000021 both: 0.000004\n",
      "Train Epoch: 679 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000486 both: 0.000009\n",
      "Train Epoch: 679 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000094 drop: 0.000197 both: 0.000045\n",
      "Train Epoch: 679 [25000/25000 (100%)]\tLosses default: 0.000053 bn: 0.000019 drop: 0.000547 both: 0.000236\n",
      "Test set:\n",
      "default: Loss: 1.1638\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0429\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.0733\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0727\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 680 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.001766 drop: 0.000385 both: 0.000002\n",
      "Train Epoch: 680 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000019 drop: 0.000062 both: 0.000012\n",
      "Train Epoch: 680 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000006 drop: 0.000053 both: 0.000013\n",
      "Train Epoch: 680 [25000/25000 (100%)]\tLosses default: 0.000023 bn: 0.000138 drop: 0.000244 both: 0.004875\n",
      "Test set:\n",
      "default: Loss: 1.1761\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0369\tAccuracy: 4446.0/5000 (89%)\n",
      "drop: Loss: 1.0290\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0544\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 681 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000015 drop: 0.000130 both: 0.000038\n",
      "Train Epoch: 681 [10000/25000 (40%)]\tLosses default: 0.000030 bn: 0.000001 drop: 0.000043 both: 0.000215\n",
      "Train Epoch: 681 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000039 drop: 0.000057 both: 0.000012\n",
      "Train Epoch: 681 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000018 drop: 0.000068 both: 0.000278\n",
      "Test set:\n",
      "default: Loss: 1.1860\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0433\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.0399\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0779\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 682 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000010 both: 0.000014\n",
      "Train Epoch: 682 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000001 drop: 0.000064 both: 0.000236\n",
      "Train Epoch: 682 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000072 drop: 0.000060 both: 0.000525\n",
      "Train Epoch: 682 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000056 drop: 0.000077 both: 0.000422\n",
      "Test set:\n",
      "default: Loss: 1.1955\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0501\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.0385\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0628\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 683 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000004 drop: 0.000014 both: 0.010975\n",
      "Train Epoch: 683 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000019 both: 0.000005\n",
      "Train Epoch: 683 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001329 drop: 0.000091 both: 0.000009\n",
      "Train Epoch: 683 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000004 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.2071\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0581\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0446\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0756\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 684 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000057 drop: 0.000005 both: 0.000008\n",
      "Train Epoch: 684 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000007 drop: 0.000006 both: 0.000016\n",
      "Train Epoch: 684 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000603 drop: 0.000007 both: 0.000014\n",
      "Train Epoch: 684 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000020 drop: 0.000034 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.2158\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0832\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0516\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.1181\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 685 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000704 drop: 0.000055 both: 0.000044\n",
      "Train Epoch: 685 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000352 drop: 0.000122 both: 0.000254\n",
      "Train Epoch: 685 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000089 drop: 0.000011 both: 0.003489\n",
      "Train Epoch: 685 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000001 drop: 0.000016 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.2254\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0473\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.0443\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 1.0774\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 686 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000307 drop: 0.000016 both: 0.000076\n",
      "Train Epoch: 686 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000008 drop: 0.000002 both: 0.000030\n",
      "Train Epoch: 686 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000025 drop: 0.000006 both: 0.000055\n",
      "Train Epoch: 686 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000025 drop: 0.003186 both: 0.000031\n",
      "Test set:\n",
      "default: Loss: 1.2339\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0743\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0616\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0763\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 687 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000021 drop: 0.000009 both: 0.000131\n",
      "Train Epoch: 687 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000003 both: 0.000024\n",
      "Train Epoch: 687 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000086 both: 0.000008\n",
      "Train Epoch: 687 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000161 drop: 0.000029 both: 0.000057\n",
      "Test set:\n",
      "default: Loss: 1.2422\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0563\tAccuracy: 4445.0/5000 (89%)\n",
      "drop: Loss: 1.0661\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0927\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 688 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.001465 drop: 0.000009 both: 0.000019\n",
      "Train Epoch: 688 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.004265 drop: 0.000030 both: 0.000359\n",
      "Train Epoch: 688 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000013 both: 0.000017\n",
      "Train Epoch: 688 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000063 drop: 0.000071 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.2520\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0734\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.0562\tAccuracy: 4412.0/5000 (88%)\n",
      "both: Loss: 1.0844\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 689 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000036 drop: 0.000019 both: 0.000081\n",
      "Train Epoch: 689 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000036 both: 0.000024\n",
      "Train Epoch: 689 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000014 both: 0.022641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 689 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000012 drop: 0.000016 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.2593\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0494\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0821\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0943\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 690 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000008 both: 0.000484\n",
      "Train Epoch: 690 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000027 drop: 0.000013 both: 0.000226\n",
      "Train Epoch: 690 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000023 drop: 0.000002 both: 0.000023\n",
      "Train Epoch: 690 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.2681\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0471\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.0850\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0617\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 691 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000002 both: 0.000292\n",
      "Train Epoch: 691 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000005 both: 0.000006\n",
      "Train Epoch: 691 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.026188 drop: 0.000007 both: 0.000023\n",
      "Train Epoch: 691 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000229 drop: 0.005209 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.2749\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0573\tAccuracy: 4387.0/5000 (88%)\n",
      "drop: Loss: 1.0863\tAccuracy: 4411.0/5000 (88%)\n",
      "both: Loss: 1.1041\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 692 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000261 drop: 0.000014 both: 0.000007\n",
      "Train Epoch: 692 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000141 drop: 0.001458 both: 0.000026\n",
      "Train Epoch: 692 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.005514 drop: 0.050455 both: 0.000034\n",
      "Train Epoch: 692 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000512 drop: 0.000264 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.2824\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0294\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0643\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.1286\tAccuracy: 4352.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 693 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.004831 drop: 0.000084 both: 0.004746\n",
      "Train Epoch: 693 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000066 drop: 0.000025 both: 0.000008\n",
      "Train Epoch: 693 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000382 both: 0.000019\n",
      "Train Epoch: 693 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000127 drop: 0.000020 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.2898\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 0.9977\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.0704\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0862\tAccuracy: 4368.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 694 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000746 drop: 0.000285 both: 0.000006\n",
      "Train Epoch: 694 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000099 drop: 0.000064 both: 0.000284\n",
      "Train Epoch: 694 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000117 drop: 0.000385 both: 0.000043\n",
      "Train Epoch: 694 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000054 drop: 0.000003 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2957\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0380\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.1187\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.1028\tAccuracy: 4365.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 695 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000040 both: 0.000044\n",
      "Train Epoch: 695 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000156 drop: 0.014322 both: 0.000082\n",
      "Train Epoch: 695 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000560 drop: 0.000639 both: 0.000163\n",
      "Train Epoch: 695 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000105 both: 0.010916\n",
      "Test set:\n",
      "default: Loss: 1.3028\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0541\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.0635\tAccuracy: 4407.0/5000 (88%)\n",
      "both: Loss: 1.0923\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 696 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000027 both: 0.000010\n",
      "Train Epoch: 696 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.002877 both: 0.014701\n",
      "Train Epoch: 696 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.027591 both: 0.000010\n",
      "Train Epoch: 696 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000020 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.3093\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0574\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.0944\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.1250\tAccuracy: 4357.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 697 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000194 both: 0.000130\n",
      "Train Epoch: 697 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000055 drop: 0.000131 both: 0.000535\n",
      "Train Epoch: 697 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000132 both: 0.000220\n",
      "Train Epoch: 697 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000027 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3155\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0234\tAccuracy: 4450.0/5000 (89%)\n",
      "drop: Loss: 1.0666\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0760\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 698 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000247 drop: 0.000019 both: 0.008751\n",
      "Train Epoch: 698 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000014 both: 0.000020\n",
      "Train Epoch: 698 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000191 drop: 0.000004 both: 0.000004\n",
      "Train Epoch: 698 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000008 both: 0.000114\n",
      "Test set:\n",
      "default: Loss: 1.3205\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0366\tAccuracy: 4456.0/5000 (89%)\n",
      "drop: Loss: 1.0961\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0850\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 699 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000009 both: 0.000010\n",
      "Train Epoch: 699 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000026 both: 0.000069\n",
      "Train Epoch: 699 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000009 both: 0.000003\n",
      "Train Epoch: 699 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000428 drop: 0.000052 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.3279\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0649\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.0840\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0574\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 700 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000018 both: 0.000059\n",
      "Train Epoch: 700 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000005 both: 0.000004\n",
      "Train Epoch: 700 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000187 drop: 0.000042 both: 0.000014\n",
      "Train Epoch: 700 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000109 drop: 0.000013 both: 0.000054\n",
      "Test set:\n",
      "default: Loss: 1.3339\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0902\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.0819\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0215\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 701 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.004142 drop: 0.000042 both: 0.000128\n",
      "Train Epoch: 701 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000040 both: 0.000350\n",
      "Train Epoch: 701 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000086 drop: 0.000022 both: 0.033502\n",
      "Train Epoch: 701 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000041 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.3378\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0580\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0902\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0873\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 702 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000022 both: 0.000017\n",
      "Train Epoch: 702 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000140 drop: 0.000007 both: 0.006123\n",
      "Train Epoch: 702 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.037797 drop: 0.000130 both: 0.000053\n",
      "Train Epoch: 702 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000038 both: 0.021687\n",
      "Test set:\n",
      "default: Loss: 1.3426\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0428\tAccuracy: 4458.0/5000 (89%)\n",
      "drop: Loss: 1.0888\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0452\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 703 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000006 both: 0.000110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 703 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000156 drop: 0.000037 both: 0.000211\n",
      "Train Epoch: 703 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000806 drop: 0.000052 both: 0.000033\n",
      "Train Epoch: 703 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000059 drop: 0.000003 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.3476\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0596\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.1092\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0203\tAccuracy: 4431.0/5000 (89%)\n",
      "\n",
      "Train Epoch: 704 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000688 drop: 0.000010 both: 0.000021\n",
      "Train Epoch: 704 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000008 both: 0.000010\n",
      "Train Epoch: 704 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000011 both: 0.000026\n",
      "Train Epoch: 704 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000019 both: 0.000071\n",
      "Test set:\n",
      "default: Loss: 1.3533\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0681\tAccuracy: 4447.0/5000 (89%)\n",
      "drop: Loss: 1.1041\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0393\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 705 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000225 drop: 0.000018 both: 0.000037\n",
      "Train Epoch: 705 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001360 drop: 0.000014 both: 0.000050\n",
      "Train Epoch: 705 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000004 both: 0.000026\n",
      "Train Epoch: 705 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000210 drop: 0.000012 both: 0.000055\n",
      "Test set:\n",
      "default: Loss: 1.3571\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0468\tAccuracy: 4451.0/5000 (89%)\n",
      "drop: Loss: 1.1022\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0712\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 706 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000001 both: 0.000309\n",
      "Train Epoch: 706 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000047 drop: 0.000019 both: 0.000016\n",
      "Train Epoch: 706 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000057 drop: 0.000004 both: 0.000764\n",
      "Train Epoch: 706 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000140 drop: 0.363790 both: 0.000078\n",
      "Test set:\n",
      "default: Loss: 1.3616\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0290\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.2504\tAccuracy: 4324.0/5000 (86%)\n",
      "both: Loss: 1.0837\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 707 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000065 both: 0.000059\n",
      "Train Epoch: 707 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.056961 both: 0.000016\n",
      "Train Epoch: 707 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.003300 both: 0.000981\n",
      "Train Epoch: 707 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.003077 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.3644\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0796\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0939\tAccuracy: 4357.0/5000 (87%)\n",
      "both: Loss: 1.0657\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 708 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001095 drop: 0.000076 both: 0.000019\n",
      "Train Epoch: 708 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000294 both: 0.000009\n",
      "Train Epoch: 708 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000055 drop: 0.000024 both: 0.000012\n",
      "Train Epoch: 708 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000028 both: 0.000024\n",
      "Test set:\n",
      "default: Loss: 1.3671\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0917\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0799\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0535\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 709 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000172 both: 0.000069\n",
      "Train Epoch: 709 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000006 both: 0.000053\n",
      "Train Epoch: 709 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000068 both: 0.000083\n",
      "Train Epoch: 709 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000705 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3687\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0857\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0858\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.1096\tAccuracy: 4368.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 710 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000070 both: 0.000015\n",
      "Train Epoch: 710 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000079 both: 0.114410\n",
      "Train Epoch: 710 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000995 both: 0.001786\n",
      "Train Epoch: 710 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000350 drop: 0.000200 both: 0.000296\n",
      "Test set:\n",
      "default: Loss: 1.3718\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0627\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0721\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0748\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 711 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000002 both: 0.000007\n",
      "Train Epoch: 711 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000005 both: 0.000016\n",
      "Train Epoch: 711 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000119 drop: 0.000012 both: 0.000006\n",
      "Train Epoch: 711 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3713\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0703\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.0512\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0709\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 712 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000033 both: 0.000006\n",
      "Train Epoch: 712 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.016812 both: 0.000016\n",
      "Train Epoch: 712 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000107 both: 0.000116\n",
      "Train Epoch: 712 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000192 both: 0.000025\n",
      "Test set:\n",
      "default: Loss: 1.3716\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.1148\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0956\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0539\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 713 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000151 both: 0.000016\n",
      "Train Epoch: 713 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001826 drop: 0.000015 both: 0.000016\n",
      "Train Epoch: 713 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000018 both: 0.000011\n",
      "Train Epoch: 713 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000215 drop: 0.000026 both: 0.000838\n",
      "Test set:\n",
      "default: Loss: 1.3740\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0552\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.0948\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0882\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 714 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000025 both: 0.000055\n",
      "Train Epoch: 714 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.087630 drop: 0.000028 both: 0.000031\n",
      "Train Epoch: 714 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.012987 drop: 0.000017 both: 0.000013\n",
      "Train Epoch: 714 [25000/25000 (100%)]\tLosses default: 0.113622 bn: 0.000006 drop: 0.000046 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.3908\tAccuracy: 4334.0/5000 (87%)\n",
      "bn: Loss: 1.0715\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0900\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0807\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 715 [0/25000 (0%)]\tLosses default: 0.059588 bn: 0.000273 drop: 0.000035 both: 0.000072\n",
      "Train Epoch: 715 [10000/25000 (40%)]\tLosses default: 0.000098 bn: 0.000159 drop: 0.000001 both: 0.003545\n",
      "Train Epoch: 715 [20000/25000 (80%)]\tLosses default: 0.000082 bn: 0.000071 drop: 0.000018 both: 0.000015\n",
      "Train Epoch: 715 [25000/25000 (100%)]\tLosses default: 0.000724 bn: 0.000251 drop: 0.000004 both: 0.000044\n",
      "Test set:\n",
      "default: Loss: 1.0662\tAccuracy: 4396.0/5000 (88%)\n",
      "bn: Loss: 1.0905\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.0945\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0840\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 716 [0/25000 (0%)]\tLosses default: 0.002666 bn: 0.000000 drop: 0.000011 both: 0.000272\n",
      "Train Epoch: 716 [10000/25000 (40%)]\tLosses default: 0.000373 bn: 0.000003 drop: 0.000008 both: 0.002139\n",
      "Train Epoch: 716 [20000/25000 (80%)]\tLosses default: 0.000187 bn: 0.000001 drop: 0.000005 both: 0.000019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 716 [25000/25000 (100%)]\tLosses default: 0.000926 bn: 0.000273 drop: 0.000002 both: 0.000673\n",
      "Test set:\n",
      "default: Loss: 1.0634\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.1027\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0901\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.1126\tAccuracy: 4360.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 717 [0/25000 (0%)]\tLosses default: 0.000036 bn: 0.000006 drop: 0.000006 both: 0.000044\n",
      "Train Epoch: 717 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000030 drop: 0.000017 both: 0.000019\n",
      "Train Epoch: 717 [20000/25000 (80%)]\tLosses default: 0.000171 bn: 0.000003 drop: 0.000010 both: 0.000021\n",
      "Train Epoch: 717 [25000/25000 (100%)]\tLosses default: 0.000012 bn: 0.000054 drop: 0.000002 both: 0.000525\n",
      "Test set:\n",
      "default: Loss: 1.0701\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0764\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0886\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.1022\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 718 [0/25000 (0%)]\tLosses default: 0.000030 bn: 0.000005 drop: 0.000011 both: 0.000018\n",
      "Train Epoch: 718 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000019 drop: 0.000040 both: 0.000005\n",
      "Train Epoch: 718 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000008 both: 0.000043\n",
      "Train Epoch: 718 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000038 drop: 0.000007 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.0807\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0837\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.0868\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0850\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 719 [0/25000 (0%)]\tLosses default: 0.000012 bn: 0.000001 drop: 0.000014 both: 0.000010\n",
      "Train Epoch: 719 [10000/25000 (40%)]\tLosses default: 0.000012 bn: 0.000009 drop: 0.000701 both: 0.000845\n",
      "Train Epoch: 719 [20000/25000 (80%)]\tLosses default: 0.000031 bn: 0.000094 drop: 0.000037 both: 0.000017\n",
      "Train Epoch: 719 [25000/25000 (100%)]\tLosses default: 0.000101 bn: 0.057307 drop: 0.000037 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.0910\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0674\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.0752\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0697\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 720 [0/25000 (0%)]\tLosses default: 0.000037 bn: 0.000041 drop: 0.000012 both: 0.000013\n",
      "Train Epoch: 720 [10000/25000 (40%)]\tLosses default: 0.000013 bn: 0.000002 drop: 0.000041 both: 0.000009\n",
      "Train Epoch: 720 [20000/25000 (80%)]\tLosses default: 0.000161 bn: 0.000003 drop: 0.000011 both: 0.003167\n",
      "Train Epoch: 720 [25000/25000 (100%)]\tLosses default: 0.000027 bn: 0.000077 drop: 0.000012 both: 0.000123\n",
      "Test set:\n",
      "default: Loss: 1.1018\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0659\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.0926\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 1.1104\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 721 [0/25000 (0%)]\tLosses default: 0.000026 bn: 0.000023 drop: 0.000043 both: 0.000344\n",
      "Train Epoch: 721 [10000/25000 (40%)]\tLosses default: 0.000064 bn: 0.000007 drop: 0.000002 both: 0.000004\n",
      "Train Epoch: 721 [20000/25000 (80%)]\tLosses default: 0.000029 bn: 0.000482 drop: 0.000007 both: 0.000197\n",
      "Train Epoch: 721 [25000/25000 (100%)]\tLosses default: 0.000019 bn: 0.000006 drop: 0.000001 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1126\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0469\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.0976\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0326\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 722 [0/25000 (0%)]\tLosses default: 0.000014 bn: 0.000071 drop: 0.000005 both: 0.000010\n",
      "Train Epoch: 722 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 722 [20000/25000 (80%)]\tLosses default: 0.000026 bn: 0.050213 drop: 0.000008 both: 0.000011\n",
      "Train Epoch: 722 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000037 drop: 0.000014 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.1229\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0546\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.1175\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0426\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 723 [0/25000 (0%)]\tLosses default: 0.000040 bn: 0.003664 drop: 0.000042 both: 0.000013\n",
      "Train Epoch: 723 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000019 drop: 0.000810 both: 0.000561\n",
      "Train Epoch: 723 [20000/25000 (80%)]\tLosses default: 0.000030 bn: 0.005729 drop: 0.000865 both: 0.000003\n",
      "Train Epoch: 723 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.003875 drop: 0.001513 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.1339\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0694\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.0785\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0635\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 724 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000158 drop: 0.000072 both: 0.000020\n",
      "Train Epoch: 724 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000124 drop: 0.000127 both: 0.000015\n",
      "Train Epoch: 724 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000010 drop: 0.000023 both: 0.000328\n",
      "Train Epoch: 724 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000014 drop: 0.000029 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.1459\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0809\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.1206\tAccuracy: 4351.0/5000 (87%)\n",
      "both: Loss: 1.1026\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 725 [0/25000 (0%)]\tLosses default: 0.000017 bn: 0.001692 drop: 0.002458 both: 0.000088\n",
      "Train Epoch: 725 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000026 drop: 0.000229 both: 0.000119\n",
      "Train Epoch: 725 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000062 drop: 0.000418 both: 0.000014\n",
      "Train Epoch: 725 [25000/25000 (100%)]\tLosses default: 0.000017 bn: 0.000039 drop: 0.000315 both: 0.003400\n",
      "Test set:\n",
      "default: Loss: 1.1549\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0743\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1303\tAccuracy: 4360.0/5000 (87%)\n",
      "both: Loss: 1.0653\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 726 [0/25000 (0%)]\tLosses default: 0.000008 bn: 0.000001 drop: 0.000016 both: 0.000008\n",
      "Train Epoch: 726 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.000003 drop: 0.000014 both: 0.000009\n",
      "Train Epoch: 726 [20000/25000 (80%)]\tLosses default: 0.000010 bn: 0.000002 drop: 0.000054 both: 0.000037\n",
      "Train Epoch: 726 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000056 drop: 0.000145 both: 0.000042\n",
      "Test set:\n",
      "default: Loss: 1.1664\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0563\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.0792\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0909\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 727 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000002 drop: 0.001945 both: 0.000059\n",
      "Train Epoch: 727 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000008 drop: 0.010447 both: 0.000008\n",
      "Train Epoch: 727 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000038 drop: 0.000025 both: 0.000011\n",
      "Train Epoch: 727 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000124 both: 0.000036\n",
      "Test set:\n",
      "default: Loss: 1.1767\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0773\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.0832\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0857\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 728 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000805 drop: 0.000006 both: 0.000039\n",
      "Train Epoch: 728 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000026 drop: 0.000018 both: 0.000008\n",
      "Train Epoch: 728 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000000 drop: 0.000017 both: 0.000026\n",
      "Train Epoch: 728 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000024 drop: 0.000017 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.1870\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0641\tAccuracy: 4444.0/5000 (89%)\n",
      "drop: Loss: 1.0756\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0784\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 729 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000034 both: 0.000006\n",
      "Train Epoch: 729 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000015 drop: 0.000034 both: 0.001242\n",
      "Train Epoch: 729 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000005 drop: 0.000007 both: 0.000505\n",
      "Train Epoch: 729 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000026 drop: 0.000008 both: 0.000024\n",
      "Test set:\n",
      "default: Loss: 1.1974\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0619\tAccuracy: 4446.0/5000 (89%)\n",
      "drop: Loss: 1.0919\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0606\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 730 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000002 both: 0.000353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 730 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000047 both: 0.000017\n",
      "Train Epoch: 730 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000007 drop: 0.000004 both: 0.000508\n",
      "Train Epoch: 730 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000071 drop: 0.000012 both: 0.000102\n",
      "Test set:\n",
      "default: Loss: 1.2064\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0734\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 1.0847\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0720\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 731 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000325 drop: 0.000155 both: 0.000017\n",
      "Train Epoch: 731 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000015 both: 0.000008\n",
      "Train Epoch: 731 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000497 drop: 0.000010 both: 0.000028\n",
      "Train Epoch: 731 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000232 drop: 0.000065 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.2162\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1113\tAccuracy: 4397.0/5000 (88%)\n",
      "drop: Loss: 1.0964\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0840\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 732 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000090 drop: 0.000054 both: 0.000080\n",
      "Train Epoch: 732 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000193 drop: 0.000012 both: 0.000004\n",
      "Train Epoch: 732 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.002296 drop: 0.000010 both: 0.101512\n",
      "Train Epoch: 732 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.010271 drop: 0.000134 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.2261\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0791\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0835\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0980\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 733 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 733 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000064 drop: 0.000009 both: 0.000015\n",
      "Train Epoch: 733 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000038 drop: 0.000038 both: 0.000022\n",
      "Train Epoch: 733 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000001 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.2348\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0559\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1235\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0805\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 734 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000127 drop: 0.000007 both: 0.000008\n",
      "Train Epoch: 734 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000190 drop: 0.000020 both: 0.024711\n",
      "Train Epoch: 734 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000073 drop: 0.000003 both: 0.000094\n",
      "Train Epoch: 734 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.000041 both: 0.000972\n",
      "Test set:\n",
      "default: Loss: 1.2437\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0409\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1117\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0421\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 735 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000042 both: 0.000691\n",
      "Train Epoch: 735 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000004 both: 0.000037\n",
      "Train Epoch: 735 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000004 both: 0.000660\n",
      "Train Epoch: 735 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000101 drop: 0.000007 both: 0.000196\n",
      "Test set:\n",
      "default: Loss: 1.2521\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1098\tAccuracy: 4393.0/5000 (88%)\n",
      "drop: Loss: 1.1069\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0902\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 736 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000098 drop: 0.000004 both: 0.000186\n",
      "Train Epoch: 736 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000005 both: 0.000006\n",
      "Train Epoch: 736 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000059 drop: 0.000008 both: 0.000003\n",
      "Train Epoch: 736 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000118 drop: 0.000001 both: 0.005749\n",
      "Test set:\n",
      "default: Loss: 1.2595\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0624\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.1198\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0673\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 737 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000003 both: 0.002091\n",
      "Train Epoch: 737 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000050 drop: 0.000007 both: 0.000159\n",
      "Train Epoch: 737 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000009 both: 0.000068\n",
      "Train Epoch: 737 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000097 drop: 0.000003 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.2681\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1340\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.1138\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0790\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 738 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000022 drop: 0.000005 both: 0.000003\n",
      "Train Epoch: 738 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000001 both: 0.000056\n",
      "Train Epoch: 738 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000011 drop: 0.000025 both: 0.000061\n",
      "Train Epoch: 738 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000050 drop: 0.000003 both: 0.000352\n",
      "Test set:\n",
      "default: Loss: 1.2756\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0937\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.1332\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0541\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 739 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000003 both: 0.000011\n",
      "Train Epoch: 739 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000032 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 739 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000466 drop: 0.000004 both: 0.000019\n",
      "Train Epoch: 739 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000057 both: 0.001675\n",
      "Test set:\n",
      "default: Loss: 1.2833\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0639\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1362\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0744\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 740 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000020 both: 0.000748\n",
      "Train Epoch: 740 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000050 drop: 0.000004 both: 0.000008\n",
      "Train Epoch: 740 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000052 both: 0.000015\n",
      "Train Epoch: 740 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000535 drop: 0.000003 both: 0.000150\n",
      "Test set:\n",
      "default: Loss: 1.2886\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0574\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1416\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.1391\tAccuracy: 4367.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 741 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.005698 drop: 0.000000 both: 0.000288\n",
      "Train Epoch: 741 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000001 both: 0.000009\n",
      "Train Epoch: 741 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000004 both: 0.000007\n",
      "Train Epoch: 741 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000007 both: 0.000254\n",
      "Test set:\n",
      "default: Loss: 1.2954\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0475\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1536\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0506\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 742 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000003 both: 0.000030\n",
      "Train Epoch: 742 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000003 both: 0.000693\n",
      "Train Epoch: 742 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000456 drop: 0.000003 both: 0.000023\n",
      "Train Epoch: 742 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000006 both: 0.002251\n",
      "Test set:\n",
      "default: Loss: 1.3019\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0807\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1735\tAccuracy: 4407.0/5000 (88%)\n",
      "both: Loss: 1.0146\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 743 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000006 both: 0.000159\n",
      "Train Epoch: 743 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001139 drop: 0.000006 both: 0.000170\n",
      "Train Epoch: 743 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000000 both: 0.000008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 743 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.037157 drop: 0.000003 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.3081\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1014\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1876\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0678\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 744 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000004 both: 0.000004\n",
      "Train Epoch: 744 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000005 both: 0.000014\n",
      "Train Epoch: 744 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000003 both: 0.000101\n",
      "Train Epoch: 744 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000008 both: 0.026321\n",
      "Test set:\n",
      "default: Loss: 1.3128\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0687\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1789\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0455\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 745 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000063 drop: 0.000000 both: 0.000028\n",
      "Train Epoch: 745 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 745 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000107 drop: 0.000008 both: 0.000041\n",
      "Train Epoch: 745 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.328782 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.3203\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0302\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.2351\tAccuracy: 4324.0/5000 (86%)\n",
      "both: Loss: 1.0518\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 746 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000047 drop: 0.006280 both: 0.000004\n",
      "Train Epoch: 746 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000171 drop: 0.011183 both: 0.000271\n",
      "Train Epoch: 746 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000103 drop: 0.000022 both: 0.000011\n",
      "Train Epoch: 746 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.052537 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.3246\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0336\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.1186\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0611\tAccuracy: 4410.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 747 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000101 both: 0.000037\n",
      "Train Epoch: 747 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000059 drop: 0.000112 both: 0.000160\n",
      "Train Epoch: 747 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000013 both: 0.000200\n",
      "Train Epoch: 747 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000027 both: 0.000063\n",
      "Test set:\n",
      "default: Loss: 1.3304\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0479\tAccuracy: 4445.0/5000 (89%)\n",
      "drop: Loss: 1.0954\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0790\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 748 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000055 both: 0.000578\n",
      "Train Epoch: 748 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000096 both: 0.000117\n",
      "Train Epoch: 748 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000060 drop: 0.000003 both: 0.000015\n",
      "Train Epoch: 748 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.145796 drop: 0.000162 both: 0.000049\n",
      "Test set:\n",
      "default: Loss: 1.3335\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0445\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.1090\tAccuracy: 4407.0/5000 (88%)\n",
      "both: Loss: 1.0607\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 749 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000358 both: 0.000091\n",
      "Train Epoch: 749 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000045 drop: 0.000112 both: 0.000016\n",
      "Train Epoch: 749 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000066 drop: 0.000119 both: 0.004518\n",
      "Train Epoch: 749 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000364 drop: 0.000067 both: 0.000053\n",
      "Test set:\n",
      "default: Loss: 1.3384\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0610\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.0974\tAccuracy: 4414.0/5000 (88%)\n",
      "both: Loss: 1.0753\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 750 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000059 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 750 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000123 both: 0.000040\n",
      "Train Epoch: 750 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000162 drop: 0.000013 both: 0.000019\n",
      "Train Epoch: 750 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000504 drop: 0.000151 both: 0.000343\n",
      "Test set:\n",
      "default: Loss: 1.3428\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0560\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.1508\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0871\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 751 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000019 both: 0.000024\n",
      "Train Epoch: 751 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000115 drop: 0.000002 both: 0.000021\n",
      "Train Epoch: 751 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.001714 both: 0.000015\n",
      "Train Epoch: 751 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000095 drop: 0.000044 both: 0.000070\n",
      "Test set:\n",
      "default: Loss: 1.3471\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0475\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1332\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0728\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 752 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000144 both: 0.001827\n",
      "Train Epoch: 752 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000006 both: 0.000024\n",
      "Train Epoch: 752 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000172 drop: 0.000431 both: 0.000137\n",
      "Train Epoch: 752 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000058 drop: 0.000799 both: 0.000591\n",
      "Test set:\n",
      "default: Loss: 1.3491\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0600\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.1620\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0529\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 753 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000125 both: 0.000004\n",
      "Train Epoch: 753 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000239 both: 0.000109\n",
      "Train Epoch: 753 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000718 both: 0.000168\n",
      "Train Epoch: 753 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000159 drop: 0.000012 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3539\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0620\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1422\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0629\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 754 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000884 both: 0.000164\n",
      "Train Epoch: 754 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.017785 both: 0.000013\n",
      "Train Epoch: 754 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000081 both: 0.001078\n",
      "Train Epoch: 754 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000002 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.3534\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0767\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.1510\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0521\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 755 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000301 drop: 0.000206 both: 0.000137\n",
      "Train Epoch: 755 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000080 both: 0.000004\n",
      "Train Epoch: 755 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000554 drop: 0.000073 both: 0.017567\n",
      "Train Epoch: 755 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000076 drop: 0.000020 both: 0.013969\n",
      "Test set:\n",
      "default: Loss: 1.3558\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0936\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.1443\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0754\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 756 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000012 both: 0.000069\n",
      "Train Epoch: 756 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000123 drop: 0.000007 both: 0.017816\n",
      "Train Epoch: 756 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000110 both: 0.011527\n",
      "Train Epoch: 756 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000749 drop: 0.000087 both: 0.001494\n",
      "Test set:\n",
      "default: Loss: 1.3558\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0733\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.1489\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0512\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 757 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000004 both: 0.000018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 757 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000881 both: 0.003412\n",
      "Train Epoch: 757 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000008 both: 0.000003\n",
      "Train Epoch: 757 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000031 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3572\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0580\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1426\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0466\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 758 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000003 both: 0.000042\n",
      "Train Epoch: 758 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000007 both: 0.000020\n",
      "Train Epoch: 758 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000120 drop: 0.000021 both: 0.000097\n",
      "Train Epoch: 758 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.004609 drop: 0.000015 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3568\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0753\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.1352\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0576\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 759 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000009 both: 0.000030\n",
      "Train Epoch: 759 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000056 both: 0.000014\n",
      "Train Epoch: 759 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000012 both: 0.000007\n",
      "Train Epoch: 759 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000003 both: 0.000078\n",
      "Test set:\n",
      "default: Loss: 1.3583\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1028\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 1.1653\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0588\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 760 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000235 drop: 0.000001 both: 0.000018\n",
      "Train Epoch: 760 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.006033 drop: 0.000010 both: 0.000014\n",
      "Train Epoch: 760 [20000/25000 (80%)]\tLosses default: 0.001487 bn: 0.000040 drop: 0.000003 both: 0.000111\n",
      "Train Epoch: 760 [25000/25000 (100%)]\tLosses default: 0.115876 bn: 0.002403 drop: 0.000002 both: 0.005604\n",
      "Test set:\n",
      "default: Loss: 1.0631\tAccuracy: 4396.0/5000 (88%)\n",
      "bn: Loss: 1.0748\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.1446\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0622\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 761 [0/25000 (0%)]\tLosses default: 0.021963 bn: 0.003730 drop: 0.000004 both: 0.000049\n",
      "Train Epoch: 761 [10000/25000 (40%)]\tLosses default: 0.000065 bn: 0.000033 drop: 0.000002 both: 0.000109\n",
      "Train Epoch: 761 [20000/25000 (80%)]\tLosses default: 0.001270 bn: 0.000302 drop: 0.000027 both: 0.000161\n",
      "Train Epoch: 761 [25000/25000 (100%)]\tLosses default: 0.000072 bn: 0.000006 drop: 0.000045 both: 0.000030\n",
      "Test set:\n",
      "default: Loss: 1.0442\tAccuracy: 4391.0/5000 (88%)\n",
      "bn: Loss: 1.0401\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.1630\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0586\tAccuracy: 4365.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 762 [0/25000 (0%)]\tLosses default: 0.001360 bn: 0.000178 drop: 0.000001 both: 0.000013\n",
      "Train Epoch: 762 [10000/25000 (40%)]\tLosses default: 0.000252 bn: 0.000002 drop: 0.000007 both: 0.000318\n",
      "Train Epoch: 762 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000012 drop: 0.000001 both: 0.000032\n",
      "Train Epoch: 762 [25000/25000 (100%)]\tLosses default: 0.000082 bn: 0.002138 drop: 0.000004 both: 0.000096\n",
      "Test set:\n",
      "default: Loss: 1.0538\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0562\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1606\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0439\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 763 [0/25000 (0%)]\tLosses default: 0.000045 bn: 0.000013 drop: 0.000009 both: 0.000007\n",
      "Train Epoch: 763 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000005 both: 0.000343\n",
      "Train Epoch: 763 [20000/25000 (80%)]\tLosses default: 0.000540 bn: 0.000150 drop: 0.000012 both: 0.000127\n",
      "Train Epoch: 763 [25000/25000 (100%)]\tLosses default: 0.000032 bn: 0.000444 drop: 0.000027 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.0669\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0624\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.1320\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0511\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 764 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000019 drop: 0.000001 both: 0.007536\n",
      "Train Epoch: 764 [10000/25000 (40%)]\tLosses default: 0.000166 bn: 0.000003 drop: 0.000007 both: 0.000078\n",
      "Train Epoch: 764 [20000/25000 (80%)]\tLosses default: 0.000022 bn: 0.000001 drop: 0.000011 both: 0.000010\n",
      "Train Epoch: 764 [25000/25000 (100%)]\tLosses default: 0.000025 bn: 0.000018 drop: 0.000013 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.0787\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.1135\tAccuracy: 4400.0/5000 (88%)\n",
      "drop: Loss: 1.1635\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0307\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 765 [0/25000 (0%)]\tLosses default: 0.000052 bn: 0.063383 drop: 0.000018 both: 0.000008\n",
      "Train Epoch: 765 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000039 both: 0.000002\n",
      "Train Epoch: 765 [20000/25000 (80%)]\tLosses default: 0.000018 bn: 0.000296 drop: 0.000020 both: 0.000012\n",
      "Train Epoch: 765 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.007481 drop: 0.002513 both: 0.000185\n",
      "Test set:\n",
      "default: Loss: 1.0921\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0184\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0898\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0161\tAccuracy: 4425.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 766 [0/25000 (0%)]\tLosses default: 0.000015 bn: 0.000030 drop: 0.005200 both: 0.000089\n",
      "Train Epoch: 766 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.003016 drop: 0.000048 both: 0.000022\n",
      "Train Epoch: 766 [20000/25000 (80%)]\tLosses default: 0.000063 bn: 0.000005 drop: 0.000295 both: 0.047198\n",
      "Train Epoch: 766 [25000/25000 (100%)]\tLosses default: 0.000040 bn: 0.000015 drop: 0.000072 both: 0.002013\n",
      "Test set:\n",
      "default: Loss: 1.1026\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0202\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.0944\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0181\tAccuracy: 4415.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 767 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000003 drop: 0.000142 both: 0.000010\n",
      "Train Epoch: 767 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000005 drop: 0.000022 both: 0.000014\n",
      "Train Epoch: 767 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000355 drop: 0.000003 both: 0.000222\n",
      "Train Epoch: 767 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000023 drop: 0.000011 both: 0.000506\n",
      "Test set:\n",
      "default: Loss: 1.1135\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0161\tAccuracy: 4447.0/5000 (89%)\n",
      "drop: Loss: 1.0854\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0201\tAccuracy: 4416.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 768 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.000391 both: 0.001391\n",
      "Train Epoch: 768 [10000/25000 (40%)]\tLosses default: 0.000022 bn: 0.000016 drop: 0.000002 both: 0.058866\n",
      "Train Epoch: 768 [20000/25000 (80%)]\tLosses default: 0.000023 bn: 0.000080 drop: 0.000003 both: 0.000017\n",
      "Train Epoch: 768 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000001 drop: 0.000006 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.1260\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0309\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.0897\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 1.0447\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 769 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000016 both: 0.000004\n",
      "Train Epoch: 769 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000019 drop: 0.000062 both: 0.000135\n",
      "Train Epoch: 769 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000067 drop: 0.000004 both: 0.000031\n",
      "Train Epoch: 769 [25000/25000 (100%)]\tLosses default: 0.000068 bn: 0.000077 drop: 0.000007 both: 0.000067\n",
      "Test set:\n",
      "default: Loss: 1.1362\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0582\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.0828\tAccuracy: 4414.0/5000 (88%)\n",
      "both: Loss: 1.0587\tAccuracy: 4412.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 770 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000001 drop: 0.000048 both: 0.000051\n",
      "Train Epoch: 770 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.058425 drop: 0.000074 both: 0.000397\n",
      "Train Epoch: 770 [20000/25000 (80%)]\tLosses default: 0.000009 bn: 0.000137 drop: 0.000004 both: 0.000016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 770 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000023 drop: 0.000001 both: 0.000048\n",
      "Test set:\n",
      "default: Loss: 1.1467\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0725\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.0843\tAccuracy: 4412.0/5000 (88%)\n",
      "both: Loss: 1.0406\tAccuracy: 4420.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 771 [0/25000 (0%)]\tLosses default: 0.000012 bn: 0.000020 drop: 0.000025 both: 0.000014\n",
      "Train Epoch: 771 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000009 both: 0.000030\n",
      "Train Epoch: 771 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000000 drop: 0.000020 both: 0.000006\n",
      "Train Epoch: 771 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000001 drop: 0.000210 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.1592\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0694\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1124\tAccuracy: 4408.0/5000 (88%)\n",
      "both: Loss: 1.0885\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 772 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000002 both: 0.001206\n",
      "Train Epoch: 772 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000005 drop: 0.000009 both: 0.000089\n",
      "Train Epoch: 772 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000011 both: 0.072409\n",
      "Train Epoch: 772 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000396 drop: 0.000108 both: 0.004762\n",
      "Test set:\n",
      "default: Loss: 1.1719\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0725\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1214\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0666\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 773 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000017 drop: 0.000048 both: 0.001561\n",
      "Train Epoch: 773 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000003 drop: 0.000147 both: 0.000013\n",
      "Train Epoch: 773 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000006 both: 0.005260\n",
      "Train Epoch: 773 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000023 drop: 0.000138 both: 0.000953\n",
      "Test set:\n",
      "default: Loss: 1.1815\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0825\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.0725\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0604\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 774 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000722 drop: 0.000242 both: 0.000136\n",
      "Train Epoch: 774 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.001744 drop: 0.000011 both: 0.000072\n",
      "Train Epoch: 774 [20000/25000 (80%)]\tLosses default: 0.000010 bn: 0.001165 drop: 0.000036 both: 0.000158\n",
      "Train Epoch: 774 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000002 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.1914\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0632\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.1337\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0775\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 775 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000555 both: 0.000748\n",
      "Train Epoch: 775 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000003 drop: 0.000013 both: 0.000667\n",
      "Train Epoch: 775 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000054 drop: 0.000067 both: 0.000403\n",
      "Train Epoch: 775 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.001486 drop: 0.000928 both: 0.004717\n",
      "Test set:\n",
      "default: Loss: 1.2026\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0623\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.1133\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0802\tAccuracy: 4358.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 776 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000044 drop: 0.000374 both: 0.000026\n",
      "Train Epoch: 776 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000005 both: 0.000007\n",
      "Train Epoch: 776 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000034 drop: 0.000019 both: 0.000117\n",
      "Train Epoch: 776 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000108 drop: 0.000121 both: 0.000055\n",
      "Test set:\n",
      "default: Loss: 1.2126\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1051\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1147\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0465\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 777 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000050 both: 0.000012\n",
      "Train Epoch: 777 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000656 drop: 0.015330 both: 0.000088\n",
      "Train Epoch: 777 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000003 both: 0.000006\n",
      "Train Epoch: 777 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000093 drop: 0.000045 both: 0.000028\n",
      "Test set:\n",
      "default: Loss: 1.2227\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0849\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.1601\tAccuracy: 4362.0/5000 (87%)\n",
      "both: Loss: 1.0479\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 778 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.001071 drop: 0.000073 both: 0.000078\n",
      "Train Epoch: 778 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000028 drop: 0.000197 both: 0.000139\n",
      "Train Epoch: 778 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000011 drop: 0.009509 both: 0.000007\n",
      "Train Epoch: 778 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000009 drop: 0.000132 both: 0.001624\n",
      "Test set:\n",
      "default: Loss: 1.2326\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1111\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.1127\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0725\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 779 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000031 both: 0.000006\n",
      "Train Epoch: 779 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000007 both: 0.000010\n",
      "Train Epoch: 779 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000264 drop: 0.000005 both: 0.000019\n",
      "Train Epoch: 779 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000016 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.2434\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1243\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1033\tAccuracy: 4409.0/5000 (88%)\n",
      "both: Loss: 1.0539\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 780 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000030 both: 0.000041\n",
      "Train Epoch: 780 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000224 drop: 0.000010 both: 0.000024\n",
      "Train Epoch: 780 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000002 drop: 0.000018 both: 0.000008\n",
      "Train Epoch: 780 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001826 drop: 0.000001 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.2521\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1588\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.1102\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0527\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 781 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000141 drop: 0.000193 both: 0.000157\n",
      "Train Epoch: 781 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.004202 drop: 0.000056 both: 0.000009\n",
      "Train Epoch: 781 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000181 drop: 0.000023 both: 0.000032\n",
      "Train Epoch: 781 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.007665 drop: 0.000007 both: 0.035882\n",
      "Test set:\n",
      "default: Loss: 1.2603\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1199\tAccuracy: 4396.0/5000 (88%)\n",
      "drop: Loss: 1.1415\tAccuracy: 4407.0/5000 (88%)\n",
      "both: Loss: 0.9961\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 782 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000095 drop: 0.000002 both: 0.000002\n",
      "Train Epoch: 782 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000004 both: 0.000062\n",
      "Train Epoch: 782 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001441 drop: 0.000007 both: 0.000031\n",
      "Train Epoch: 782 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000118 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.2690\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0849\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.1103\tAccuracy: 4419.0/5000 (88%)\n",
      "both: Loss: 1.0281\tAccuracy: 4422.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 783 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000365 drop: 0.000006 both: 0.000055\n",
      "Train Epoch: 783 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000096 drop: 0.000031 both: 0.000039\n",
      "Train Epoch: 783 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001278 drop: 0.000097 both: 0.004114\n",
      "Train Epoch: 783 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000249 drop: 0.000004 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.2773\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0764\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1207\tAccuracy: 4408.0/5000 (88%)\n",
      "both: Loss: 1.0770\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 784 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000266 both: 0.000009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 784 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000460 drop: 0.000015 both: 0.000011\n",
      "Train Epoch: 784 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000245 drop: 0.000025 both: 0.000300\n",
      "Train Epoch: 784 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000145 drop: 0.000006 both: 0.000030\n",
      "Test set:\n",
      "default: Loss: 1.2854\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0602\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1317\tAccuracy: 4413.0/5000 (88%)\n",
      "both: Loss: 1.0913\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 785 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000011\n",
      "Train Epoch: 785 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000004 both: 0.001142\n",
      "Train Epoch: 785 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000011 both: 0.000021\n",
      "Train Epoch: 785 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000014 both: 0.000236\n",
      "Test set:\n",
      "default: Loss: 1.2927\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0720\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.1318\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0455\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 786 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 786 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001122 drop: 0.000012 both: 0.000009\n",
      "Train Epoch: 786 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001832 drop: 0.000002 both: 0.000007\n",
      "Train Epoch: 786 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000025 both: 0.000044\n",
      "Test set:\n",
      "default: Loss: 1.2990\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0732\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1242\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0434\tAccuracy: 4417.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 787 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000070 drop: 0.000001 both: 0.000009\n",
      "Train Epoch: 787 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 787 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000002 both: 0.000009\n",
      "Train Epoch: 787 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000018 drop: 0.000006 both: 0.000031\n",
      "Test set:\n",
      "default: Loss: 1.3061\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0696\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.1380\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.0594\tAccuracy: 4417.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 788 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001679 drop: 0.000002 both: 0.132757\n",
      "Train Epoch: 788 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000027 both: 0.000126\n",
      "Train Epoch: 788 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000449 drop: 0.000024 both: 0.000177\n",
      "Train Epoch: 788 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.028298 drop: 0.000005 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.3121\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.1063\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 1.1521\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0491\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 789 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.011902 drop: 0.000006 both: 0.000012\n",
      "Train Epoch: 789 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000004 both: 0.000122\n",
      "Train Epoch: 789 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.159763 both: 0.000017\n",
      "Train Epoch: 789 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000028 drop: 0.034214 both: 0.000054\n",
      "Test set:\n",
      "default: Loss: 1.3180\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0522\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.1562\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.0394\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 790 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000047 drop: 0.000432 both: 0.000152\n",
      "Train Epoch: 790 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000039 drop: 0.000219 both: 0.000006\n",
      "Train Epoch: 790 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000060 both: 0.000007\n",
      "Train Epoch: 790 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000116 both: 0.000024\n",
      "Test set:\n",
      "default: Loss: 1.3237\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0494\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1321\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0726\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 791 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000036 both: 0.000055\n",
      "Train Epoch: 791 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000012 both: 0.000165\n",
      "Train Epoch: 791 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.030392 drop: 0.000103 both: 0.000191\n",
      "Train Epoch: 791 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.026862 drop: 0.000139 both: 0.000040\n",
      "Test set:\n",
      "default: Loss: 1.3298\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0721\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1166\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0543\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 792 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000149 both: 0.000222\n",
      "Train Epoch: 792 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000009 both: 0.000054\n",
      "Train Epoch: 792 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000106 both: 0.000048\n",
      "Train Epoch: 792 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000011 both: 0.000118\n",
      "Test set:\n",
      "default: Loss: 1.3319\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0489\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1144\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0807\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 793 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000053 drop: 0.000050 both: 0.000004\n",
      "Train Epoch: 793 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000021 both: 0.000036\n",
      "Train Epoch: 793 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000023 both: 0.000161\n",
      "Train Epoch: 793 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000004 both: 0.000256\n",
      "Test set:\n",
      "default: Loss: 1.3366\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0497\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1274\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0798\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 794 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000028 both: 0.000173\n",
      "Train Epoch: 794 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000059 both: 0.000006\n",
      "Train Epoch: 794 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000068 drop: 0.000006 both: 0.000035\n",
      "Train Epoch: 794 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000006 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.3406\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0748\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1514\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0761\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 795 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.004275 drop: 0.000033 both: 0.000041\n",
      "Train Epoch: 795 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000064 both: 0.000037\n",
      "Train Epoch: 795 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.004644 both: 0.045852\n",
      "Train Epoch: 795 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.007001 both: 0.000118\n",
      "Test set:\n",
      "default: Loss: 1.3456\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0702\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1603\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0952\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 796 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000020 both: 0.000054\n",
      "Train Epoch: 796 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.002243 both: 0.000066\n",
      "Train Epoch: 796 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000029 both: 0.002653\n",
      "Train Epoch: 796 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000013 both: 0.000316\n",
      "Test set:\n",
      "default: Loss: 1.3494\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1121\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1259\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0853\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 797 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001313 drop: 0.000234 both: 0.000035\n",
      "Train Epoch: 797 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000527 drop: 0.000039 both: 0.000028\n",
      "Train Epoch: 797 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000069 both: 0.000008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 797 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.002927 both: 0.005759\n",
      "Test set:\n",
      "default: Loss: 1.3527\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1101\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 1.1218\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1204\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 798 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000217 drop: 0.000007 both: 0.000357\n",
      "Train Epoch: 798 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000072 drop: 0.000286 both: 0.003358\n",
      "Train Epoch: 798 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000013 both: 0.000108\n",
      "Train Epoch: 798 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000058 drop: 0.000039 both: 0.000063\n",
      "Test set:\n",
      "default: Loss: 1.3545\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0895\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1313\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0529\tAccuracy: 4370.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 799 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000009 both: 0.000043\n",
      "Train Epoch: 799 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000008 both: 0.000003\n",
      "Train Epoch: 799 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000046 both: 0.000138\n",
      "Train Epoch: 799 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000151 drop: 0.000018 both: 0.000070\n",
      "Test set:\n",
      "default: Loss: 1.3577\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0693\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1347\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0436\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 800 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000003 both: 0.000012\n",
      "Train Epoch: 800 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000213 drop: 0.000037 both: 0.000070\n",
      "Train Epoch: 800 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000011 both: 0.000002\n",
      "Train Epoch: 800 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000004 both: 0.000288\n",
      "Test set:\n",
      "default: Loss: 1.3565\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0794\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.1472\tAccuracy: 4408.0/5000 (88%)\n",
      "both: Loss: 1.0663\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 801 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000007 both: 0.000354\n",
      "Train Epoch: 801 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000040 both: 0.000258\n",
      "Train Epoch: 801 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000011 both: 0.000020\n",
      "Train Epoch: 801 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000075 drop: 0.000010 both: 0.000155\n",
      "Test set:\n",
      "default: Loss: 1.3584\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0976\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1278\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0565\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 802 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.034934 drop: 0.000007 both: 0.000606\n",
      "Train Epoch: 802 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000007 both: 0.010619\n",
      "Train Epoch: 802 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000002 both: 0.000009\n",
      "Train Epoch: 802 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000002 both: 0.000578\n",
      "Test set:\n",
      "default: Loss: 1.3580\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0660\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1362\tAccuracy: 4409.0/5000 (88%)\n",
      "both: Loss: 1.0397\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 803 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000035 drop: 0.000008 both: 0.000650\n",
      "Train Epoch: 803 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000046 drop: 0.000002 both: 0.000011\n",
      "Train Epoch: 803 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000075 both: 0.000016\n",
      "Train Epoch: 803 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000007 both: 0.009857\n",
      "Test set:\n",
      "default: Loss: 1.3555\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0594\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1383\tAccuracy: 4418.0/5000 (88%)\n",
      "both: Loss: 1.0636\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 804 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000002 both: 0.000650\n",
      "Train Epoch: 804 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000380 drop: 0.000029 both: 0.021294\n",
      "Train Epoch: 804 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000004 both: 0.000139\n",
      "Train Epoch: 804 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.002567\n",
      "Test set:\n",
      "default: Loss: 1.3614\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0652\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1397\tAccuracy: 4411.0/5000 (88%)\n",
      "both: Loss: 1.0767\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 805 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000060 drop: 0.000013 both: 0.000383\n",
      "Train Epoch: 805 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000004 both: 0.000233\n",
      "Train Epoch: 805 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000004 both: 0.000010\n",
      "Train Epoch: 805 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000018 both: 0.000330\n",
      "Test set:\n",
      "default: Loss: 1.3673\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0459\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.1681\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0837\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 806 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000009 both: 0.000006\n",
      "Train Epoch: 806 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000005 both: 0.000311\n",
      "Train Epoch: 806 [20000/25000 (80%)]\tLosses default: 0.000941 bn: 0.000041 drop: 0.000005 both: 0.000038\n",
      "Train Epoch: 806 [25000/25000 (100%)]\tLosses default: 0.001459 bn: 0.000001 drop: 0.000002 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 0.9839\tAccuracy: 4395.0/5000 (88%)\n",
      "bn: Loss: 1.0592\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1715\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0952\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 807 [0/25000 (0%)]\tLosses default: 0.046289 bn: 0.000006 drop: 0.000003 both: 0.000039\n",
      "Train Epoch: 807 [10000/25000 (40%)]\tLosses default: 0.000103 bn: 0.000298 drop: 0.000017 both: 0.001487\n",
      "Train Epoch: 807 [20000/25000 (80%)]\tLosses default: 0.001108 bn: 0.000031 drop: 0.000005 both: 0.000039\n",
      "Train Epoch: 807 [25000/25000 (100%)]\tLosses default: 0.000197 bn: 0.000017 drop: 0.000005 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.0438\tAccuracy: 4408.0/5000 (88%)\n",
      "bn: Loss: 1.0709\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1812\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 1.0403\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 808 [0/25000 (0%)]\tLosses default: 0.005249 bn: 0.000005 drop: 0.000015 both: 0.000004\n",
      "Train Epoch: 808 [10000/25000 (40%)]\tLosses default: 0.000085 bn: 0.000003 drop: 0.000001 both: 0.000012\n",
      "Train Epoch: 808 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000014 drop: 0.000004 both: 0.000003\n",
      "Train Epoch: 808 [25000/25000 (100%)]\tLosses default: 0.000495 bn: 0.000002 drop: 0.000008 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.0412\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1128\tAccuracy: 4391.0/5000 (88%)\n",
      "drop: Loss: 1.1823\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0773\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 809 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.002771 drop: 0.000046 both: 0.000053\n",
      "Train Epoch: 809 [10000/25000 (40%)]\tLosses default: 0.000050 bn: 0.000002 drop: 0.001322 both: 0.000015\n",
      "Train Epoch: 809 [20000/25000 (80%)]\tLosses default: 0.000017 bn: 0.000083 drop: 0.000168 both: 0.000032\n",
      "Train Epoch: 809 [25000/25000 (100%)]\tLosses default: 0.000011 bn: 0.016343 drop: 0.001185 both: 0.000040\n",
      "Test set:\n",
      "default: Loss: 1.0807\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1114\tAccuracy: 4388.0/5000 (88%)\n",
      "drop: Loss: 1.1204\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0372\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 810 [0/25000 (0%)]\tLosses default: 0.000014 bn: 0.000003 drop: 0.000374 both: 0.000021\n",
      "Train Epoch: 810 [10000/25000 (40%)]\tLosses default: 0.000227 bn: 0.000058 drop: 0.000292 both: 0.000007\n",
      "Train Epoch: 810 [20000/25000 (80%)]\tLosses default: 0.000023 bn: 0.000005 drop: 0.000579 both: 0.000011\n",
      "Train Epoch: 810 [25000/25000 (100%)]\tLosses default: 0.000034 bn: 0.000007 drop: 0.000014 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.0801\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0679\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.1445\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0255\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 811 [0/25000 (0%)]\tLosses default: 0.000020 bn: 0.003368 drop: 0.000591 both: 0.000254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 811 [10000/25000 (40%)]\tLosses default: 0.000046 bn: 0.000146 drop: 0.000466 both: 0.000021\n",
      "Train Epoch: 811 [20000/25000 (80%)]\tLosses default: 0.000021 bn: 0.000039 drop: 0.000020 both: 0.000107\n",
      "Train Epoch: 811 [25000/25000 (100%)]\tLosses default: 0.000107 bn: 0.000013 drop: 0.000085 both: 0.000043\n",
      "Test set:\n",
      "default: Loss: 1.0858\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0645\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1311\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0634\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 812 [0/25000 (0%)]\tLosses default: 0.000069 bn: 0.000057 drop: 0.000088 both: 0.000077\n",
      "Train Epoch: 812 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000032 drop: 0.000015 both: 0.000011\n",
      "Train Epoch: 812 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000017 drop: 0.000018 both: 0.000133\n",
      "Train Epoch: 812 [25000/25000 (100%)]\tLosses default: 0.000025 bn: 0.000001 drop: 0.000034 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.0923\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0315\tAccuracy: 4457.0/5000 (89%)\n",
      "drop: Loss: 1.1289\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0610\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 813 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000006 both: 0.000002\n",
      "Train Epoch: 813 [10000/25000 (40%)]\tLosses default: 0.000033 bn: 0.000005 drop: 0.000015 both: 0.000343\n",
      "Train Epoch: 813 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000003 drop: 0.000056 both: 0.000284\n",
      "Train Epoch: 813 [25000/25000 (100%)]\tLosses default: 0.000020 bn: 0.000019 drop: 0.000005 both: 0.011565\n",
      "Test set:\n",
      "default: Loss: 1.0994\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0325\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.1340\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0516\tAccuracy: 4410.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 814 [0/25000 (0%)]\tLosses default: 0.000029 bn: 0.000512 drop: 0.000010 both: 0.006274\n",
      "Train Epoch: 814 [10000/25000 (40%)]\tLosses default: 0.000045 bn: 0.000078 drop: 0.000014 both: 0.000766\n",
      "Train Epoch: 814 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000015 drop: 0.003268 both: 0.000009\n",
      "Train Epoch: 814 [25000/25000 (100%)]\tLosses default: 0.000032 bn: 0.021318 drop: 0.000104 both: 0.000119\n",
      "Test set:\n",
      "default: Loss: 1.1062\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0400\tAccuracy: 4445.0/5000 (89%)\n",
      "drop: Loss: 1.1843\tAccuracy: 4353.0/5000 (87%)\n",
      "both: Loss: 1.0583\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 815 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000047 drop: 0.000004 both: 0.000738\n",
      "Train Epoch: 815 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000002 drop: 0.001683 both: 0.000056\n",
      "Train Epoch: 815 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000020 drop: 0.000513 both: 0.000777\n",
      "Train Epoch: 815 [25000/25000 (100%)]\tLosses default: 0.000012 bn: 0.000008 drop: 0.000104 both: 0.000074\n",
      "Test set:\n",
      "default: Loss: 1.1151\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0802\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.1440\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0772\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 816 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000017 both: 0.000255\n",
      "Train Epoch: 816 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.002679 drop: 0.000928 both: 0.000057\n",
      "Train Epoch: 816 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000051 drop: 0.000083 both: 0.000061\n",
      "Train Epoch: 816 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000021 drop: 0.000024 both: 0.000066\n",
      "Test set:\n",
      "default: Loss: 1.1228\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0550\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.1465\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0385\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 817 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000097 drop: 0.000052 both: 0.000030\n",
      "Train Epoch: 817 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000604 drop: 0.000048 both: 0.000002\n",
      "Train Epoch: 817 [20000/25000 (80%)]\tLosses default: 0.000015 bn: 0.003012 drop: 0.000122 both: 0.000043\n",
      "Train Epoch: 817 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000003 drop: 0.000049 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.1311\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0650\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.1236\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0515\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 818 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000005 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 818 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000006 both: 0.000012\n",
      "Train Epoch: 818 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000013 both: 0.000136\n",
      "Train Epoch: 818 [25000/25000 (100%)]\tLosses default: 0.000011 bn: 0.000002 drop: 0.000003 both: 0.001082\n",
      "Test set:\n",
      "default: Loss: 1.1396\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0669\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1220\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0914\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 819 [0/25000 (0%)]\tLosses default: 0.000014 bn: 0.009537 drop: 0.000004 both: 0.001669\n",
      "Train Epoch: 819 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000020 drop: 0.000040 both: 0.009270\n",
      "Train Epoch: 819 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000025 drop: 0.000043 both: 0.000581\n",
      "Train Epoch: 819 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000001 drop: 0.000015 both: 0.000317\n",
      "Test set:\n",
      "default: Loss: 1.1472\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0986\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1291\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0759\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 820 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000007 both: 0.000067\n",
      "Train Epoch: 820 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000003 drop: 0.000028 both: 0.000011\n",
      "Train Epoch: 820 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000200 drop: 0.000112 both: 0.000022\n",
      "Train Epoch: 820 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000005 drop: 0.000009 both: 0.000238\n",
      "Test set:\n",
      "default: Loss: 1.1566\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0715\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.1309\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0334\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 821 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000013 drop: 0.000029 both: 0.000020\n",
      "Train Epoch: 821 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000012 both: 0.000004\n",
      "Train Epoch: 821 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000006 both: 0.000003\n",
      "Train Epoch: 821 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.017039 drop: 0.000096 both: 0.000057\n",
      "Test set:\n",
      "default: Loss: 1.1653\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0896\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1406\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0276\tAccuracy: 4417.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 822 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000048 drop: 0.000007 both: 0.000006\n",
      "Train Epoch: 822 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000130 both: 0.000411\n",
      "Train Epoch: 822 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000661 drop: 0.000003 both: 0.001375\n",
      "Train Epoch: 822 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000116 drop: 0.000012 both: 0.000101\n",
      "Test set:\n",
      "default: Loss: 1.1737\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0732\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.1309\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0307\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 823 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000181 drop: 0.000003 both: 0.000011\n",
      "Train Epoch: 823 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000008 drop: 0.000003 both: 0.000008\n",
      "Train Epoch: 823 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000023 both: 0.000003\n",
      "Train Epoch: 823 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000177 drop: 0.000028 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.1827\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.1101\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.1592\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0530\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 824 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000005 both: 0.000064\n",
      "Train Epoch: 824 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000103 drop: 0.000009 both: 0.000160\n",
      "Train Epoch: 824 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000002 both: 0.000027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 824 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001223 drop: 0.000033 both: 0.000200\n",
      "Test set:\n",
      "default: Loss: 1.1906\tAccuracy: 4448.0/5000 (89%)\n",
      "bn: Loss: 1.0657\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1463\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0304\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 825 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000060 drop: 0.000008 both: 0.006481\n",
      "Train Epoch: 825 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000008 both: 0.000039\n",
      "Train Epoch: 825 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000008 drop: 0.000009 both: 0.000017\n",
      "Train Epoch: 825 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000079 drop: 0.000012 both: 0.000315\n",
      "Test set:\n",
      "default: Loss: 1.1999\tAccuracy: 4448.0/5000 (89%)\n",
      "bn: Loss: 1.0759\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.1573\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0551\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 826 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000311 drop: 0.000001 both: 0.000089\n",
      "Train Epoch: 826 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.000003 both: 0.006557\n",
      "Train Epoch: 826 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000439 drop: 0.000002 both: 0.000004\n",
      "Train Epoch: 826 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000029 drop: 0.000328 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.2083\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.1366\tAccuracy: 4397.0/5000 (88%)\n",
      "drop: Loss: 1.1765\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0577\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 827 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000118 drop: 0.000002 both: 0.000009\n",
      "Train Epoch: 827 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 827 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.001062\n",
      "Train Epoch: 827 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000013 both: 0.000023\n",
      "Test set:\n",
      "default: Loss: 1.2168\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0830\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.1595\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0655\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 828 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000313 drop: 0.000063 both: 0.000034\n",
      "Train Epoch: 828 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000117 drop: 0.001932 both: 0.000133\n",
      "Train Epoch: 828 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000420 drop: 0.000761 both: 0.000051\n",
      "Train Epoch: 828 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000204 drop: 0.000164 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.2246\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0841\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1382\tAccuracy: 4360.0/5000 (87%)\n",
      "both: Loss: 1.0831\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 829 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.101694 both: 0.000027\n",
      "Train Epoch: 829 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000028 both: 0.000016\n",
      "Train Epoch: 829 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.015267 drop: 0.000085 both: 0.000033\n",
      "Train Epoch: 829 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000528 drop: 0.000017 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.2318\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.0514\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1372\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0475\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 830 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000052 both: 0.000005\n",
      "Train Epoch: 830 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000883 drop: 0.000021 both: 0.000120\n",
      "Train Epoch: 830 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000125 drop: 0.000067 both: 0.000117\n",
      "Train Epoch: 830 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000188 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.2392\tAccuracy: 4451.0/5000 (89%)\n",
      "bn: Loss: 1.0386\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 1.1307\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0635\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 831 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000160 drop: 0.000037 both: 0.000051\n",
      "Train Epoch: 831 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000122 drop: 0.000088 both: 0.000003\n",
      "Train Epoch: 831 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000052 drop: 0.000008 both: 0.000649\n",
      "Train Epoch: 831 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000073 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.2473\tAccuracy: 4448.0/5000 (89%)\n",
      "bn: Loss: 1.0641\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1177\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0498\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 832 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000073 drop: 0.000014 both: 0.000199\n",
      "Train Epoch: 832 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000014 both: 0.004294\n",
      "Train Epoch: 832 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000022 drop: 0.000011 both: 0.000059\n",
      "Train Epoch: 832 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000029 both: 0.000446\n",
      "Test set:\n",
      "default: Loss: 1.2546\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.1065\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1357\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0121\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 833 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000054 drop: 0.000009 both: 0.000016\n",
      "Train Epoch: 833 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000892 drop: 0.000034 both: 0.000170\n",
      "Train Epoch: 833 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000562 both: 0.000314\n",
      "Train Epoch: 833 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000193 drop: 0.000006 both: 0.024490\n",
      "Test set:\n",
      "default: Loss: 1.2611\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.0847\tAccuracy: 4395.0/5000 (88%)\n",
      "drop: Loss: 1.1388\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0666\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 834 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.012891 drop: 0.000008 both: 0.000253\n",
      "Train Epoch: 834 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000014 both: 0.000077\n",
      "Train Epoch: 834 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000043 both: 0.000016\n",
      "Train Epoch: 834 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000517 both: 0.000036\n",
      "Test set:\n",
      "default: Loss: 1.2665\tAccuracy: 4449.0/5000 (89%)\n",
      "bn: Loss: 1.0853\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.1451\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0641\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 835 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000044 both: 0.000130\n",
      "Train Epoch: 835 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000009 both: 0.000687\n",
      "Train Epoch: 835 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.039376 drop: 0.000026 both: 0.001189\n",
      "Train Epoch: 835 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000056 drop: 0.000057 both: 0.000025\n",
      "Test set:\n",
      "default: Loss: 1.2727\tAccuracy: 4451.0/5000 (89%)\n",
      "bn: Loss: 1.0793\tAccuracy: 4400.0/5000 (88%)\n",
      "drop: Loss: 1.1418\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0716\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 836 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000114 both: 0.000006\n",
      "Train Epoch: 836 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.013052 drop: 0.000061 both: 0.000203\n",
      "Train Epoch: 836 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000863 drop: 0.000044 both: 0.000088\n",
      "Train Epoch: 836 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.001270 both: 0.000302\n",
      "Test set:\n",
      "default: Loss: 1.2785\tAccuracy: 4449.0/5000 (89%)\n",
      "bn: Loss: 1.0524\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1685\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0599\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 837 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000074 drop: 0.000028 both: 0.000113\n",
      "Train Epoch: 837 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000012 both: 0.000050\n",
      "Train Epoch: 837 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000002 both: 0.000374\n",
      "Train Epoch: 837 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000119 drop: 0.000021 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.2828\tAccuracy: 4449.0/5000 (89%)\n",
      "bn: Loss: 1.0966\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.1616\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0474\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 838 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000008 both: 0.000190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 838 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000702 drop: 0.000002 both: 0.000023\n",
      "Train Epoch: 838 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000402 both: 0.000017\n",
      "Train Epoch: 838 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000033 both: 0.000052\n",
      "Test set:\n",
      "default: Loss: 1.2880\tAccuracy: 4448.0/5000 (89%)\n",
      "bn: Loss: 1.0793\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.0909\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0207\tAccuracy: 4410.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 839 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000048 both: 0.000007\n",
      "Train Epoch: 839 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000161 both: 0.000150\n",
      "Train Epoch: 839 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000853 both: 0.000009\n",
      "Train Epoch: 839 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000040 both: 0.000084\n",
      "Test set:\n",
      "default: Loss: 1.2934\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0565\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.0786\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0377\tAccuracy: 4412.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 840 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000075 both: 0.000006\n",
      "Train Epoch: 840 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000345 drop: 0.000024 both: 0.000601\n",
      "Train Epoch: 840 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.002569 drop: 0.000010 both: 0.000004\n",
      "Train Epoch: 840 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000016 both: 0.000086\n",
      "Test set:\n",
      "default: Loss: 1.3002\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0978\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.0843\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0648\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 841 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.003771 drop: 0.000140 both: 0.000044\n",
      "Train Epoch: 841 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.001545 both: 0.000185\n",
      "Train Epoch: 841 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000121 both: 0.000010\n",
      "Train Epoch: 841 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000016 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.3029\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.0566\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1306\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0617\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 842 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000476 both: 0.000008\n",
      "Train Epoch: 842 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.037144 drop: 0.000088 both: 0.000154\n",
      "Train Epoch: 842 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.009073 both: 0.000010\n",
      "Train Epoch: 842 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000038 drop: 0.000010 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.3077\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0844\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.1214\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0399\tAccuracy: 4410.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 843 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000171 drop: 0.000212 both: 0.000050\n",
      "Train Epoch: 843 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000008 both: 0.000056\n",
      "Train Epoch: 843 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001134 drop: 0.000028 both: 0.000009\n",
      "Train Epoch: 843 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000116 drop: 0.000032 both: 0.000170\n",
      "Test set:\n",
      "default: Loss: 1.3112\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0906\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.1446\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0936\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 844 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000004 both: 0.000046\n",
      "Train Epoch: 844 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000006 both: 0.000056\n",
      "Train Epoch: 844 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000009 both: 0.000212\n",
      "Train Epoch: 844 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000024 both: 0.003756\n",
      "Test set:\n",
      "default: Loss: 1.3167\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0664\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1262\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0794\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 845 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000012 both: 0.000036\n",
      "Train Epoch: 845 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000014 both: 0.000287\n",
      "Train Epoch: 845 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000016 both: 0.000098\n",
      "Train Epoch: 845 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000080 drop: 0.000009 both: 0.000030\n",
      "Test set:\n",
      "default: Loss: 1.3192\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.0628\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1359\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0362\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 846 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000075 drop: 0.000013 both: 0.011573\n",
      "Train Epoch: 846 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000017 both: 0.000122\n",
      "Train Epoch: 846 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000148 both: 0.000011\n",
      "Train Epoch: 846 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000039 both: 0.000025\n",
      "Test set:\n",
      "default: Loss: 1.3198\tAccuracy: 4449.0/5000 (89%)\n",
      "bn: Loss: 1.0698\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.1492\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0448\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 847 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000014 both: 0.000030\n",
      "Train Epoch: 847 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000239 drop: 0.000031 both: 0.000004\n",
      "Train Epoch: 847 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000316 drop: 0.000003 both: 0.001392\n",
      "Train Epoch: 847 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000015 both: 0.000835\n",
      "Test set:\n",
      "default: Loss: 1.3212\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0497\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1449\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0355\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 848 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000376 both: 0.000049\n",
      "Train Epoch: 848 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000061 drop: 0.000001 both: 0.003899\n",
      "Train Epoch: 848 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000101 drop: 0.000017 both: 0.000020\n",
      "Train Epoch: 848 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.024307 drop: 0.000014 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.3270\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0405\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.1444\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0547\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 849 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000309 drop: 0.000021 both: 0.000561\n",
      "Train Epoch: 849 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000299 drop: 0.000005 both: 0.000009\n",
      "Train Epoch: 849 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000418 drop: 0.000003 both: 0.000822\n",
      "Train Epoch: 849 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000003 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.3225\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0431\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1527\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0438\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 850 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000025 both: 0.000020\n",
      "Train Epoch: 850 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000002 both: 0.000014\n",
      "Train Epoch: 850 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000007 both: 0.000063\n",
      "Train Epoch: 850 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000001 both: 0.000276\n",
      "Test set:\n",
      "default: Loss: 1.3293\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0647\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.1505\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0500\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 851 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000000 both: 0.045791\n",
      "Train Epoch: 851 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000036 drop: 0.000004 both: 0.000054\n",
      "Train Epoch: 851 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 851 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000002 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3347\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.0813\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1720\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0576\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 852 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000084 drop: 0.000009 both: 0.000018\n",
      "Train Epoch: 852 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000561 drop: 0.000035 both: 0.000017\n",
      "Train Epoch: 852 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000130 drop: 0.000008 both: 0.001573\n",
      "Train Epoch: 852 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000726\n",
      "Test set:\n",
      "default: Loss: 1.3284\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0762\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1614\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0788\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 853 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000136 drop: 0.000004 both: 0.000021\n",
      "Train Epoch: 853 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.033134 both: 0.000010\n",
      "Train Epoch: 853 [20000/25000 (80%)]\tLosses default: 0.437878 bn: 0.000294 drop: 0.038087 both: 0.000276\n",
      "Train Epoch: 853 [25000/25000 (100%)]\tLosses default: 0.037546 bn: 0.001424 drop: 0.000362 both: 0.004150\n",
      "Test set:\n",
      "default: Loss: 1.0177\tAccuracy: 4397.0/5000 (88%)\n",
      "bn: Loss: 1.0953\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 1.1176\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0873\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 854 [0/25000 (0%)]\tLosses default: 0.054058 bn: 0.000151 drop: 0.000060 both: 0.000107\n",
      "Train Epoch: 854 [10000/25000 (40%)]\tLosses default: 0.000291 bn: 0.001199 drop: 0.001218 both: 0.027568\n",
      "Train Epoch: 854 [20000/25000 (80%)]\tLosses default: 0.004700 bn: 0.012292 drop: 0.000219 both: 0.000004\n",
      "Train Epoch: 854 [25000/25000 (100%)]\tLosses default: 0.000704 bn: 0.000017 drop: 0.000002 both: 0.000054\n",
      "Test set:\n",
      "default: Loss: 1.0380\tAccuracy: 4403.0/5000 (88%)\n",
      "bn: Loss: 1.0852\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1065\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0859\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 855 [0/25000 (0%)]\tLosses default: 0.005369 bn: 0.015579 drop: 0.000185 both: 0.006541\n",
      "Train Epoch: 855 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000038 drop: 0.000141 both: 0.000007\n",
      "Train Epoch: 855 [20000/25000 (80%)]\tLosses default: 0.000128 bn: 0.000528 drop: 0.000307 both: 0.000051\n",
      "Train Epoch: 855 [25000/25000 (100%)]\tLosses default: 0.000242 bn: 0.000183 drop: 0.000008 both: 0.000050\n",
      "Test set:\n",
      "default: Loss: 1.0660\tAccuracy: 4414.0/5000 (88%)\n",
      "bn: Loss: 1.0538\tAccuracy: 4446.0/5000 (89%)\n",
      "drop: Loss: 1.1128\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0933\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 856 [0/25000 (0%)]\tLosses default: 0.000132 bn: 0.000018 drop: 0.000098 both: 0.000028\n",
      "Train Epoch: 856 [10000/25000 (40%)]\tLosses default: 0.000014 bn: 0.000001 drop: 0.003062 both: 0.000122\n",
      "Train Epoch: 856 [20000/25000 (80%)]\tLosses default: 0.000021 bn: 0.000009 drop: 0.000005 both: 0.000055\n",
      "Train Epoch: 856 [25000/25000 (100%)]\tLosses default: 0.000027 bn: 0.000007 drop: 0.000003 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.0747\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0573\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1275\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0795\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 857 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000007 drop: 0.000003 both: 0.000007\n",
      "Train Epoch: 857 [10000/25000 (40%)]\tLosses default: 0.000035 bn: 0.000036 drop: 0.000027 both: 0.000003\n",
      "Train Epoch: 857 [20000/25000 (80%)]\tLosses default: 0.000016 bn: 0.000019 drop: 0.000010 both: 0.000007\n",
      "Train Epoch: 857 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000000 drop: 0.000040 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.0857\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.0706\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1290\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0929\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 858 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000011 drop: 0.000016 both: 0.000031\n",
      "Train Epoch: 858 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000153 drop: 0.000007 both: 0.000003\n",
      "Train Epoch: 858 [20000/25000 (80%)]\tLosses default: 0.000041 bn: 0.000002 drop: 0.000061 both: 0.000034\n",
      "Train Epoch: 858 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000012 drop: 0.000058 both: 0.002213\n",
      "Test set:\n",
      "default: Loss: 1.0940\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0580\tAccuracy: 4444.0/5000 (89%)\n",
      "drop: Loss: 1.1162\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.1087\tAccuracy: 4346.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 859 [0/25000 (0%)]\tLosses default: 0.000017 bn: 0.000002 drop: 0.000004 both: 0.000063\n",
      "Train Epoch: 859 [10000/25000 (40%)]\tLosses default: 0.000011 bn: 0.000028 drop: 0.000004 both: 0.000007\n",
      "Train Epoch: 859 [20000/25000 (80%)]\tLosses default: 0.000024 bn: 0.000055 drop: 0.000006 both: 0.001951\n",
      "Train Epoch: 859 [25000/25000 (100%)]\tLosses default: 0.000133 bn: 0.000190 drop: 0.000037 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.1038\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0565\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1206\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.1054\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 860 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000032 both: 0.000024\n",
      "Train Epoch: 860 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000001 drop: 0.000004 both: 0.000059\n",
      "Train Epoch: 860 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000129 drop: 0.000008 both: 0.000099\n",
      "Train Epoch: 860 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000058 drop: 0.000005 both: 0.000031\n",
      "Test set:\n",
      "default: Loss: 1.1132\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0869\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.1348\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0939\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 861 [0/25000 (0%)]\tLosses default: 0.000081 bn: 0.000015 drop: 0.000009 both: 0.000043\n",
      "Train Epoch: 861 [10000/25000 (40%)]\tLosses default: 0.000043 bn: 0.056815 drop: 0.000006 both: 0.001850\n",
      "Train Epoch: 861 [20000/25000 (80%)]\tLosses default: 0.000045 bn: 0.000000 drop: 0.000003 both: 0.000050\n",
      "Train Epoch: 861 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000000 drop: 0.000002 both: 0.000041\n",
      "Test set:\n",
      "default: Loss: 1.1216\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0537\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.1213\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0867\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 862 [0/25000 (0%)]\tLosses default: 0.000045 bn: 0.000013 drop: 0.000009 both: 0.005736\n",
      "Train Epoch: 862 [10000/25000 (40%)]\tLosses default: 0.000048 bn: 0.000005 drop: 0.000059 both: 0.000006\n",
      "Train Epoch: 862 [20000/25000 (80%)]\tLosses default: 0.000035 bn: 0.000224 drop: 0.000108 both: 0.000032\n",
      "Train Epoch: 862 [25000/25000 (100%)]\tLosses default: 0.000018 bn: 0.000000 drop: 0.000006 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.1306\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0880\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.1391\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0755\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 863 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000012 drop: 0.000003 both: 0.000008\n",
      "Train Epoch: 863 [10000/25000 (40%)]\tLosses default: 0.000019 bn: 0.000013 drop: 0.000009 both: 0.000522\n",
      "Train Epoch: 863 [20000/25000 (80%)]\tLosses default: 0.000012 bn: 0.000009 drop: 0.000005 both: 0.000028\n",
      "Train Epoch: 863 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000001 drop: 0.000059 both: 0.002736\n",
      "Test set:\n",
      "default: Loss: 1.1393\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0524\tAccuracy: 4457.0/5000 (89%)\n",
      "drop: Loss: 1.1439\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0835\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 864 [0/25000 (0%)]\tLosses default: 0.000018 bn: 0.000004 drop: 0.000188 both: 0.000038\n",
      "Train Epoch: 864 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000183 drop: 0.000029 both: 0.000398\n",
      "Train Epoch: 864 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000091 drop: 0.000004 both: 0.000007\n",
      "Train Epoch: 864 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000003 drop: 0.000004 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.1480\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0895\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1487\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0872\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 865 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000045 drop: 0.000018 both: 0.000077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 865 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000005 both: 0.000053\n",
      "Train Epoch: 865 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.001642 drop: 0.000004 both: 0.000051\n",
      "Train Epoch: 865 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000009 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.1573\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0741\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.1644\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.1151\tAccuracy: 4364.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 866 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000435 drop: 0.000001 both: 0.071336\n",
      "Train Epoch: 866 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.009576 drop: 0.000025 both: 0.000032\n",
      "Train Epoch: 866 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000184 drop: 0.000055 both: 0.000018\n",
      "Train Epoch: 866 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000003 both: 0.000135\n",
      "Test set:\n",
      "default: Loss: 1.1662\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0971\tAccuracy: 4404.0/5000 (88%)\n",
      "drop: Loss: 1.1523\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.1416\tAccuracy: 4358.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 867 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000230 drop: 0.000008 both: 0.000006\n",
      "Train Epoch: 867 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000032 both: 0.000079\n",
      "Train Epoch: 867 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000083 drop: 0.000017 both: 0.000048\n",
      "Train Epoch: 867 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000414 drop: 0.000023 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.1736\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0710\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1653\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0836\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 868 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000595 drop: 0.000011 both: 0.000008\n",
      "Train Epoch: 868 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000005 both: 0.013064\n",
      "Train Epoch: 868 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000068 drop: 0.000060 both: 0.000078\n",
      "Train Epoch: 868 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000020 drop: 0.000002 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.1823\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0801\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.1791\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0856\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 869 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000001 both: 0.000022\n",
      "Train Epoch: 869 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000488 drop: 0.000004 both: 0.000022\n",
      "Train Epoch: 869 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000059 drop: 0.000054 both: 0.002165\n",
      "Train Epoch: 869 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.016208 drop: 0.000002 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.1904\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.0938\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1816\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 1.0877\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 870 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 870 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000005 both: 0.000008\n",
      "Train Epoch: 870 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000001 both: 0.000005\n",
      "Train Epoch: 870 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000001 both: 0.014134\n",
      "Test set:\n",
      "default: Loss: 1.1987\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.0925\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.1914\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0717\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 871 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000046\n",
      "Train Epoch: 871 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000026 drop: 0.000016 both: 0.000102\n",
      "Train Epoch: 871 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000011 drop: 0.000005 both: 0.000014\n",
      "Train Epoch: 871 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.002222 drop: 0.000000 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.2062\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1163\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.2014\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0761\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 872 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000673 drop: 0.000001 both: 0.000008\n",
      "Train Epoch: 872 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000011 both: 0.000098\n",
      "Train Epoch: 872 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000164 drop: 0.000008 both: 0.000057\n",
      "Train Epoch: 872 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000032 drop: 0.000001 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.2133\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0979\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.1995\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0705\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 873 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000115 drop: 0.000002 both: 0.022964\n",
      "Train Epoch: 873 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000000 both: 0.000613\n",
      "Train Epoch: 873 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.227143 both: 0.000007\n",
      "Train Epoch: 873 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000512 drop: 0.022787 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.2217\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0900\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 1.2698\tAccuracy: 4304.0/5000 (86%)\n",
      "both: Loss: 1.1039\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 874 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000079 both: 0.000021\n",
      "Train Epoch: 874 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000159 both: 0.001063\n",
      "Train Epoch: 874 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000071 drop: 0.000703 both: 0.001385\n",
      "Train Epoch: 874 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000042 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2291\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0774\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.1388\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0753\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 875 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000358 drop: 0.000009 both: 0.000355\n",
      "Train Epoch: 875 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000492 both: 0.000009\n",
      "Train Epoch: 875 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000129 both: 0.081486\n",
      "Train Epoch: 875 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.029947 drop: 0.000043 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.2379\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0734\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1205\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0333\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 876 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000432 drop: 0.000030 both: 0.000012\n",
      "Train Epoch: 876 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000167 drop: 0.000014 both: 0.000249\n",
      "Train Epoch: 876 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.010558 drop: 0.000002 both: 0.000022\n",
      "Train Epoch: 876 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000587 drop: 0.000013 both: 0.000119\n",
      "Test set:\n",
      "default: Loss: 1.2437\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0836\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1374\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0608\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 877 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000854 drop: 0.000009 both: 0.000029\n",
      "Train Epoch: 877 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000102 drop: 0.000003 both: 0.000006\n",
      "Train Epoch: 877 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000065 both: 0.000162\n",
      "Train Epoch: 877 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.000109 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.2498\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1214\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.1466\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0595\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 878 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.008461 drop: 0.000265 both: 0.000030\n",
      "Train Epoch: 878 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000005 both: 0.000030\n",
      "Train Epoch: 878 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000004 both: 0.000068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 878 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000009 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.2564\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0839\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1494\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0809\tAccuracy: 4365.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 879 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000141 drop: 0.000020 both: 0.000008\n",
      "Train Epoch: 879 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000748 both: 0.000003\n",
      "Train Epoch: 879 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000408 drop: 0.000042 both: 0.000012\n",
      "Train Epoch: 879 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000023 both: 0.003971\n",
      "Test set:\n",
      "default: Loss: 1.2621\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1016\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.1243\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0556\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 880 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000052 drop: 0.000003 both: 0.000124\n",
      "Train Epoch: 880 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000063 drop: 0.000013 both: 0.028131\n",
      "Train Epoch: 880 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000015 both: 0.000008\n",
      "Train Epoch: 880 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000001 both: 0.001425\n",
      "Test set:\n",
      "default: Loss: 1.2685\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0989\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.1808\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0588\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 881 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000058 both: 0.000008\n",
      "Train Epoch: 881 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.063868 both: 0.000052\n",
      "Train Epoch: 881 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000212 drop: 0.000075 both: 0.000008\n",
      "Train Epoch: 881 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000146 drop: 0.000574 both: 0.000038\n",
      "Test set:\n",
      "default: Loss: 1.2743\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0870\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.2020\tAccuracy: 4357.0/5000 (87%)\n",
      "both: Loss: 1.0772\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 882 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000256 both: 0.000658\n",
      "Train Epoch: 882 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000210 both: 0.000643\n",
      "Train Epoch: 882 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000153 drop: 0.000030 both: 0.003397\n",
      "Train Epoch: 882 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.002667 both: 0.000033\n",
      "Test set:\n",
      "default: Loss: 1.2806\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0959\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1378\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0528\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 883 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000911 both: 0.000006\n",
      "Train Epoch: 883 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000014 both: 0.000052\n",
      "Train Epoch: 883 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000048 both: 0.000266\n",
      "Train Epoch: 883 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000154 drop: 0.000008 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.2850\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.1141\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.1388\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0573\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 884 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000036 both: 0.000055\n",
      "Train Epoch: 884 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000033 both: 0.000022\n",
      "Train Epoch: 884 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000085 drop: 0.000019 both: 0.002676\n",
      "Train Epoch: 884 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000021 both: 0.000028\n",
      "Test set:\n",
      "default: Loss: 1.2898\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1476\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1540\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0794\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 885 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000254 drop: 0.000006 both: 0.000773\n",
      "Train Epoch: 885 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.002228 drop: 0.000079 both: 0.000071\n",
      "Train Epoch: 885 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000036 both: 0.002565\n",
      "Train Epoch: 885 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000002 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2964\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0936\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1238\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0538\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 886 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000008 both: 0.000012\n",
      "Train Epoch: 886 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000006 both: 0.000033\n",
      "Train Epoch: 886 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.012116 drop: 0.000007 both: 0.000023\n",
      "Train Epoch: 886 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000018 both: 0.001670\n",
      "Test set:\n",
      "default: Loss: 1.2992\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0839\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.1391\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0540\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 887 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.000219\n",
      "Train Epoch: 887 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000004 both: 0.005226\n",
      "Train Epoch: 887 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000611 drop: 0.000003 both: 0.000002\n",
      "Train Epoch: 887 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000016 both: 0.000079\n",
      "Test set:\n",
      "default: Loss: 1.3046\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0673\tAccuracy: 4453.0/5000 (89%)\n",
      "drop: Loss: 1.1618\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0544\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 888 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000001 both: 0.000048\n",
      "Train Epoch: 888 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000061 drop: 0.000005 both: 0.000027\n",
      "Train Epoch: 888 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000077 drop: 0.000038 both: 0.000009\n",
      "Train Epoch: 888 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.002398 drop: 0.000027 both: 0.000180\n",
      "Test set:\n",
      "default: Loss: 1.3110\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0968\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1423\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0765\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 889 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000002 both: 0.000117\n",
      "Train Epoch: 889 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000006 both: 0.000076\n",
      "Train Epoch: 889 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000009 both: 0.000009\n",
      "Train Epoch: 889 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000152 drop: 0.000051 both: 0.000119\n",
      "Test set:\n",
      "default: Loss: 1.3144\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1335\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.1588\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0739\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 890 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.023804 both: 0.000191\n",
      "Train Epoch: 890 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000032 both: 0.000005\n",
      "Train Epoch: 890 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.042907 drop: 0.000017 both: 0.000005\n",
      "Train Epoch: 890 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.3173\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1154\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.1623\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0373\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 891 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000081 drop: 0.000382 both: 0.000045\n",
      "Train Epoch: 891 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000341 drop: 0.000004 both: 0.000021\n",
      "Train Epoch: 891 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000009 both: 0.000052\n",
      "Train Epoch: 891 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000009 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.3188\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0862\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1604\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0733\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 892 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000159 both: 0.003266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 892 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000048\n",
      "Train Epoch: 892 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000006 both: 0.000054\n",
      "Train Epoch: 892 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000292 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.3220\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0807\tAccuracy: 4445.0/5000 (89%)\n",
      "drop: Loss: 1.1949\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0753\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 893 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000003 both: 0.000006\n",
      "Train Epoch: 893 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000084 drop: 0.000004 both: 0.000037\n",
      "Train Epoch: 893 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000056 drop: 0.000006 both: 0.000078\n",
      "Train Epoch: 893 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000005 both: 0.000120\n",
      "Test set:\n",
      "default: Loss: 1.3221\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1261\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.2158\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0776\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 894 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000006 both: 0.000033\n",
      "Train Epoch: 894 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000008 both: 0.000050\n",
      "Train Epoch: 894 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000234 drop: 0.000002 both: 0.000015\n",
      "Train Epoch: 894 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000013 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.3248\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1631\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.1881\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0891\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 895 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000057 drop: 0.000017 both: 0.000015\n",
      "Train Epoch: 895 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000337 drop: 0.000000 both: 0.000043\n",
      "Train Epoch: 895 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.000032\n",
      "Train Epoch: 895 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.003723 drop: 0.000006 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3291\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1000\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.2115\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.1169\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 896 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000014 both: 0.000026\n",
      "Train Epoch: 896 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000060 drop: 0.000002 both: 0.000125\n",
      "Train Epoch: 896 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000001 both: 0.000322\n",
      "Train Epoch: 896 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000003 both: 0.000039\n",
      "Test set:\n",
      "default: Loss: 1.3260\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0966\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.2166\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.1003\tAccuracy: 4350.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 897 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001180 drop: 0.000001 both: 0.007702\n",
      "Train Epoch: 897 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000001 both: 0.000011\n",
      "Train Epoch: 897 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000001 both: 0.000009\n",
      "Train Epoch: 897 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000007 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.3349\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0965\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.2258\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0675\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 898 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000008 both: 0.001167\n",
      "Train Epoch: 898 [10000/25000 (40%)]\tLosses default: 0.138136 bn: 0.000005 drop: 0.000001 both: 0.000021\n",
      "Train Epoch: 898 [20000/25000 (80%)]\tLosses default: 0.021714 bn: 0.000005 drop: 0.000001 both: 0.000333\n",
      "Train Epoch: 898 [25000/25000 (100%)]\tLosses default: 0.001454 bn: 0.000001 drop: 0.000018 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 0.9622\tAccuracy: 4409.0/5000 (88%)\n",
      "bn: Loss: 1.1132\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.2446\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0370\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 899 [0/25000 (0%)]\tLosses default: 0.000421 bn: 0.000008 drop: 0.000001 both: 0.000007\n",
      "Train Epoch: 899 [10000/25000 (40%)]\tLosses default: 0.000425 bn: 0.000010 drop: 0.000001 both: 0.000001\n",
      "Train Epoch: 899 [20000/25000 (80%)]\tLosses default: 0.000211 bn: 0.000002 drop: 0.000033 both: 0.000003\n",
      "Train Epoch: 899 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000001 drop: 0.000001 both: 0.000035\n",
      "Test set:\n",
      "default: Loss: 0.9805\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.1474\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 1.2408\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0515\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 900 [0/25000 (0%)]\tLosses default: 0.000102 bn: 0.004225 drop: 0.000003 both: 0.000015\n",
      "Train Epoch: 900 [10000/25000 (40%)]\tLosses default: 0.000074 bn: 0.000673 drop: 0.000000 both: 0.000006\n",
      "Train Epoch: 900 [20000/25000 (80%)]\tLosses default: 0.000020 bn: 0.006851 drop: 0.000005 both: 0.000013\n",
      "Train Epoch: 900 [25000/25000 (100%)]\tLosses default: 0.000019 bn: 0.000132 drop: 0.000007 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.0171\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1118\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 1.2363\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0867\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 901 [0/25000 (0%)]\tLosses default: 0.000008 bn: 0.000028 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 901 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000204 drop: 0.000001 both: 0.000042\n",
      "Train Epoch: 901 [20000/25000 (80%)]\tLosses default: 0.000101 bn: 0.007921 drop: 0.000009 both: 0.000535\n",
      "Train Epoch: 901 [25000/25000 (100%)]\tLosses default: 0.000094 bn: 0.000007 drop: 0.000002 both: 0.000023\n",
      "Test set:\n",
      "default: Loss: 1.0356\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1004\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.2635\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0593\tAccuracy: 4366.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 902 [0/25000 (0%)]\tLosses default: 0.000037 bn: 0.000248 drop: 0.000001 both: 0.001542\n",
      "Train Epoch: 902 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000000 drop: 0.000001 both: 0.000098\n",
      "Train Epoch: 902 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000027 drop: 0.000000 both: 0.000010\n",
      "Train Epoch: 902 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000003 drop: 0.000000 both: 0.000189\n",
      "Test set:\n",
      "default: Loss: 1.0516\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0822\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.2585\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0659\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 903 [0/25000 (0%)]\tLosses default: 0.000028 bn: 0.000038 drop: 0.000001 both: 0.000008\n",
      "Train Epoch: 903 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000036 drop: 0.000009 both: 0.000120\n",
      "Train Epoch: 903 [20000/25000 (80%)]\tLosses default: 0.000047 bn: 0.000056 drop: 0.000001 both: 0.000019\n",
      "Train Epoch: 903 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000001 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.0657\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0762\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.2697\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0488\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 904 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000063 drop: 0.000002 both: 0.000008\n",
      "Train Epoch: 904 [10000/25000 (40%)]\tLosses default: 0.000013 bn: 0.000004 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 904 [20000/25000 (80%)]\tLosses default: 0.000021 bn: 0.011476 drop: 0.000001 both: 0.183985\n",
      "Train Epoch: 904 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000304 drop: 0.000001 both: 0.000334\n",
      "Test set:\n",
      "default: Loss: 1.0792\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1350\tAccuracy: 4400.0/5000 (88%)\n",
      "drop: Loss: 1.2678\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0490\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 905 [0/25000 (0%)]\tLosses default: 0.000077 bn: 0.022669 drop: 0.000002 both: 0.001481\n",
      "Train Epoch: 905 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000378 drop: 0.000001 both: 0.000082\n",
      "Train Epoch: 905 [20000/25000 (80%)]\tLosses default: 0.000074 bn: 0.000723 drop: 0.000002 both: 0.000013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 905 [25000/25000 (100%)]\tLosses default: 0.000063 bn: 0.000019 drop: 0.000010 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.0926\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0852\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2864\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0335\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 906 [0/25000 (0%)]\tLosses default: 0.000018 bn: 0.003332 drop: 0.000001 both: 0.000034\n",
      "Train Epoch: 906 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000030 drop: 0.000002 both: 0.000012\n",
      "Train Epoch: 906 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000013 drop: 0.000001 both: 0.000060\n",
      "Train Epoch: 906 [25000/25000 (100%)]\tLosses default: 0.000026 bn: 0.000398 drop: 0.000001 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.1055\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0887\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.2971\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0791\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 907 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000806 drop: 0.000003 both: 0.000024\n",
      "Train Epoch: 907 [10000/25000 (40%)]\tLosses default: 0.000019 bn: 0.000437 drop: 0.000004 both: 0.000436\n",
      "Train Epoch: 907 [20000/25000 (80%)]\tLosses default: 0.000012 bn: 0.000005 drop: 0.000000 both: 0.000018\n",
      "Train Epoch: 907 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000000 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.1174\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.1230\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.2756\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.0668\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 908 [0/25000 (0%)]\tLosses default: 0.000011 bn: 0.000026 drop: 0.000003 both: 0.000033\n",
      "Train Epoch: 908 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000000 both: 0.000026\n",
      "Train Epoch: 908 [20000/25000 (80%)]\tLosses default: 0.000012 bn: 0.000002 drop: 0.000001 both: 0.000048\n",
      "Train Epoch: 908 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000005 drop: 0.000001 both: 0.000915\n",
      "Test set:\n",
      "default: Loss: 1.1297\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0869\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.3245\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0667\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 909 [0/25000 (0%)]\tLosses default: 0.000016 bn: 0.000002 drop: 0.000003 both: 0.000002\n",
      "Train Epoch: 909 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.000078 drop: 0.001139 both: 0.014231\n",
      "Train Epoch: 909 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000553 drop: 0.000019 both: 0.000006\n",
      "Train Epoch: 909 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000043 drop: 0.007144 both: 0.000519\n",
      "Test set:\n",
      "default: Loss: 1.1411\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0892\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.2974\tAccuracy: 4344.0/5000 (87%)\n",
      "both: Loss: 1.0266\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 910 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000002 both: 0.000043\n",
      "Train Epoch: 910 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000005 drop: 0.000010 both: 0.000062\n",
      "Train Epoch: 910 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000039 drop: 0.000005 both: 0.000023\n",
      "Train Epoch: 910 [25000/25000 (100%)]\tLosses default: 0.000013 bn: 0.001678 drop: 0.005152 both: 0.000319\n",
      "Test set:\n",
      "default: Loss: 1.1518\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0682\tAccuracy: 4448.0/5000 (89%)\n",
      "drop: Loss: 1.2834\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0334\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 911 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000079 drop: 0.000018 both: 0.000082\n",
      "Train Epoch: 911 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000054 drop: 0.000461 both: 0.000608\n",
      "Train Epoch: 911 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000021 both: 0.000156\n",
      "Train Epoch: 911 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000169 drop: 0.000036 both: 0.000178\n",
      "Test set:\n",
      "default: Loss: 1.1631\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0890\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.2642\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0978\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 912 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000013 both: 0.005092\n",
      "Train Epoch: 912 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000014 drop: 0.000044 both: 0.004997\n",
      "Train Epoch: 912 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000999 drop: 0.000016 both: 0.000036\n",
      "Train Epoch: 912 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000906 drop: 0.000122 both: 0.006567\n",
      "Test set:\n",
      "default: Loss: 1.1739\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.1213\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.2441\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0379\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 913 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000017 drop: 0.000005 both: 0.000017\n",
      "Train Epoch: 913 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000159 drop: 0.000014 both: 0.000093\n",
      "Train Epoch: 913 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000011 drop: 0.000002 both: 0.000003\n",
      "Train Epoch: 913 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000123 drop: 0.000008 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.1840\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0857\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2532\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0360\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 914 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000001 both: 0.000044\n",
      "Train Epoch: 914 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000008 both: 0.000659\n",
      "Train Epoch: 914 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001283 drop: 0.000004 both: 0.005970\n",
      "Train Epoch: 914 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.055374 drop: 0.000002 both: 0.000231\n",
      "Test set:\n",
      "default: Loss: 1.1933\tAccuracy: 4448.0/5000 (89%)\n",
      "bn: Loss: 1.0924\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.2543\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.0465\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 915 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000002 both: 0.000014\n",
      "Train Epoch: 915 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000001 both: 0.000024\n",
      "Train Epoch: 915 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000356 drop: 0.000001 both: 0.000069\n",
      "Train Epoch: 915 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000065 drop: 0.000003 both: 0.000071\n",
      "Test set:\n",
      "default: Loss: 1.2023\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.1015\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.2336\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0522\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 916 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000004 both: 0.000008\n",
      "Train Epoch: 916 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000001 both: 0.000021\n",
      "Train Epoch: 916 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000078 drop: 0.000208 both: 0.000034\n",
      "Train Epoch: 916 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000005 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 1.2127\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.1078\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2357\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0347\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 917 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000020 both: 0.000046\n",
      "Train Epoch: 917 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000004 both: 0.001714\n",
      "Train Epoch: 917 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000031 drop: 0.000012 both: 0.001523\n",
      "Train Epoch: 917 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000103 both: 0.000024\n",
      "Test set:\n",
      "default: Loss: 1.2211\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0974\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2598\tAccuracy: 4345.0/5000 (87%)\n",
      "both: Loss: 1.0581\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 918 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000401 both: 0.000058\n",
      "Train Epoch: 918 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000173 both: 0.000266\n",
      "Train Epoch: 918 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.095119 both: 0.000199\n",
      "Train Epoch: 918 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000020 drop: 0.000036 both: 0.000043\n",
      "Test set:\n",
      "default: Loss: 1.2291\tAccuracy: 4448.0/5000 (89%)\n",
      "bn: Loss: 1.1016\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.2349\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0404\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 919 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000022 both: 0.000306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 919 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000004 both: 0.000088\n",
      "Train Epoch: 919 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.002642 drop: 0.000032 both: 0.008520\n",
      "Train Epoch: 919 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.002951 drop: 0.000019 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.2383\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.1293\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.2258\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0603\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 920 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000020 both: 0.000008\n",
      "Train Epoch: 920 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.047938 drop: 0.000125 both: 0.000019\n",
      "Train Epoch: 920 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000704\n",
      "Train Epoch: 920 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000311 both: 0.000053\n",
      "Test set:\n",
      "default: Loss: 1.2455\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.0852\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2508\tAccuracy: 4372.0/5000 (87%)\n",
      "both: Loss: 1.0717\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 921 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000003 both: 0.000004\n",
      "Train Epoch: 921 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000013 both: 0.000010\n",
      "Train Epoch: 921 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000038 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 921 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000003 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.2532\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.1226\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.2276\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.0654\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 922 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000002 both: 0.000009\n",
      "Train Epoch: 922 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000140 drop: 0.000016 both: 0.000059\n",
      "Train Epoch: 922 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000333 drop: 0.000026 both: 0.000024\n",
      "Train Epoch: 922 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000114 drop: 0.000001 both: 0.000075\n",
      "Test set:\n",
      "default: Loss: 1.2604\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.1016\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2337\tAccuracy: 4372.0/5000 (87%)\n",
      "both: Loss: 1.0633\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 923 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000000 both: 0.000002\n",
      "Train Epoch: 923 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000002 both: 0.000587\n",
      "Train Epoch: 923 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001406 drop: 0.000002 both: 0.000190\n",
      "Train Epoch: 923 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000001 both: 0.000813\n",
      "Test set:\n",
      "default: Loss: 1.2676\tAccuracy: 4450.0/5000 (89%)\n",
      "bn: Loss: 1.0896\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.2336\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0474\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 924 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001003 drop: 0.000010 both: 0.000019\n",
      "Train Epoch: 924 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000055 both: 0.000202\n",
      "Train Epoch: 924 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000013 both: 0.000014\n",
      "Train Epoch: 924 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000556 drop: 0.000002 both: 0.000074\n",
      "Test set:\n",
      "default: Loss: 1.2736\tAccuracy: 4448.0/5000 (89%)\n",
      "bn: Loss: 1.0704\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.2523\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0597\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 925 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000029 both: 0.000019\n",
      "Train Epoch: 925 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000157 drop: 0.000017 both: 0.000317\n",
      "Train Epoch: 925 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000010 both: 0.000063\n",
      "Train Epoch: 925 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.057622\n",
      "Test set:\n",
      "default: Loss: 1.2802\tAccuracy: 4447.0/5000 (89%)\n",
      "bn: Loss: 1.0662\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.2387\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0657\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 926 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000007 both: 0.000006\n",
      "Train Epoch: 926 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000000 both: 0.000019\n",
      "Train Epoch: 926 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000001 both: 0.000006\n",
      "Train Epoch: 926 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000002 both: 0.002709\n",
      "Test set:\n",
      "default: Loss: 1.2847\tAccuracy: 4449.0/5000 (89%)\n",
      "bn: Loss: 1.0995\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.2517\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0490\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 927 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000020 both: 0.000011\n",
      "Train Epoch: 927 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000002 both: 0.000010\n",
      "Train Epoch: 927 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000212 drop: 0.000008 both: 0.000021\n",
      "Train Epoch: 927 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000530 drop: 0.000016 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.2900\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.1157\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.2520\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0951\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 928 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000002 both: 0.000012\n",
      "Train Epoch: 928 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000138 drop: 0.000003 both: 0.000140\n",
      "Train Epoch: 928 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000107 drop: 0.000001 both: 0.000326\n",
      "Train Epoch: 928 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.010619 drop: 0.000000 both: 0.000195\n",
      "Test set:\n",
      "default: Loss: 1.2949\tAccuracy: 4449.0/5000 (89%)\n",
      "bn: Loss: 1.1087\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 1.2524\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0747\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 929 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000091 drop: 0.000002 both: 0.000005\n",
      "Train Epoch: 929 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000020 both: 0.000040\n",
      "Train Epoch: 929 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000227 drop: 0.000001 both: 0.000012\n",
      "Train Epoch: 929 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000004 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.3003\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.0708\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.2574\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0614\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 930 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001488 drop: 0.000009 both: 0.000002\n",
      "Train Epoch: 930 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000003 both: 0.000004\n",
      "Train Epoch: 930 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001964 drop: 0.000002 both: 0.000003\n",
      "Train Epoch: 930 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.020227 drop: 0.000001 both: 0.000138\n",
      "Test set:\n",
      "default: Loss: 1.3048\tAccuracy: 4446.0/5000 (89%)\n",
      "bn: Loss: 1.0751\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2754\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0580\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 931 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000002 both: 0.003868\n",
      "Train Epoch: 931 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000002 both: 0.000024\n",
      "Train Epoch: 931 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001629 drop: 0.000000 both: 0.000003\n",
      "Train Epoch: 931 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000000 both: 0.000230\n",
      "Test set:\n",
      "default: Loss: 1.3085\tAccuracy: 4449.0/5000 (89%)\n",
      "bn: Loss: 1.0831\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.2600\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0554\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 932 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000016 both: 0.000797\n",
      "Train Epoch: 932 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000035 drop: 0.000002 both: 0.000026\n",
      "Train Epoch: 932 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 932 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000000 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.3119\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.0825\tAccuracy: 4404.0/5000 (88%)\n",
      "drop: Loss: 1.2671\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0809\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 933 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000196 drop: 0.000002 both: 0.000028\n",
      "Train Epoch: 933 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000005\n",
      "Train Epoch: 933 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000132 drop: 0.000010 both: 0.000021\n",
      "Train Epoch: 933 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.036386 drop: 0.000009 both: 0.011686\n",
      "Test set:\n",
      "default: Loss: 1.3150\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.1323\tAccuracy: 4381.0/5000 (88%)\n",
      "drop: Loss: 1.2828\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.1100\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 934 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000000 both: 0.014603\n",
      "Train Epoch: 934 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000001 both: 0.000012\n",
      "Train Epoch: 934 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000102 drop: 0.000017 both: 0.000550\n",
      "Train Epoch: 934 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000102 drop: 0.000002 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.3177\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1077\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.2891\tAccuracy: 4347.0/5000 (87%)\n",
      "both: Loss: 1.0703\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 935 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.005776 both: 0.000008\n",
      "Train Epoch: 935 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.004254 both: 0.000042\n",
      "Train Epoch: 935 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.002459 drop: 0.000039 both: 0.000032\n",
      "Train Epoch: 935 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000024 both: 0.000104\n",
      "Test set:\n",
      "default: Loss: 1.3207\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0946\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.2071\tAccuracy: 4372.0/5000 (87%)\n",
      "both: Loss: 1.0647\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 936 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000050 both: 0.000077\n",
      "Train Epoch: 936 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.002985 drop: 0.000006 both: 0.000002\n",
      "Train Epoch: 936 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000990 both: 0.000019\n",
      "Train Epoch: 936 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000012 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.3193\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0979\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.2008\tAccuracy: 4358.0/5000 (87%)\n",
      "both: Loss: 1.0926\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 937 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000037 both: 0.000016\n",
      "Train Epoch: 937 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000249 drop: 0.000004 both: 0.000005\n",
      "Train Epoch: 937 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000130 drop: 0.000034 both: 0.000998\n",
      "Train Epoch: 937 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000068 both: 0.000043\n",
      "Test set:\n",
      "default: Loss: 1.3180\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1281\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.2281\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0626\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 938 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000100 both: 0.000044\n",
      "Train Epoch: 938 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000018 both: 0.000017\n",
      "Train Epoch: 938 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000037 both: 0.000020\n",
      "Train Epoch: 938 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.035427 both: 0.000104\n",
      "Test set:\n",
      "default: Loss: 1.3203\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.1112\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.2274\tAccuracy: 4354.0/5000 (87%)\n",
      "both: Loss: 1.1205\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 939 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000323 drop: 0.000102 both: 0.000006\n",
      "Train Epoch: 939 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.006047 both: 0.000039\n",
      "Train Epoch: 939 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000012 both: 0.000016\n",
      "Train Epoch: 939 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000525 both: 0.000113\n",
      "Test set:\n",
      "default: Loss: 1.3188\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1062\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2445\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0674\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 940 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000052 both: 0.000014\n",
      "Train Epoch: 940 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000135 drop: 0.000007 both: 0.000242\n",
      "Train Epoch: 940 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000173 both: 0.000007\n",
      "Train Epoch: 940 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000100 drop: 0.000791 both: 0.000092\n",
      "Test set:\n",
      "default: Loss: 1.3211\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0976\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.2487\tAccuracy: 4357.0/5000 (87%)\n",
      "both: Loss: 1.0697\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 941 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.010996 drop: 0.000017 both: 0.000007\n",
      "Train Epoch: 941 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000052 drop: 0.000009 both: 0.000032\n",
      "Train Epoch: 941 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001090 drop: 0.000013 both: 0.000020\n",
      "Train Epoch: 941 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000012 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.3193\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0727\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.2331\tAccuracy: 4362.0/5000 (87%)\n",
      "both: Loss: 1.0610\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 942 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.001579 both: 0.000400\n",
      "Train Epoch: 942 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000378 drop: 0.000030 both: 0.000253\n",
      "Train Epoch: 942 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000029 both: 0.000028\n",
      "Train Epoch: 942 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000055 drop: 0.000176 both: 0.000138\n",
      "Test set:\n",
      "default: Loss: 1.3186\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0864\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.2576\tAccuracy: 4356.0/5000 (87%)\n",
      "both: Loss: 1.0730\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 943 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000076 drop: 0.000050 both: 0.000020\n",
      "Train Epoch: 943 [10000/25000 (40%)]\tLosses default: 0.194221 bn: 0.000015 drop: 0.000149 both: 0.000025\n",
      "Train Epoch: 943 [20000/25000 (80%)]\tLosses default: 0.000484 bn: 0.000408 drop: 0.000044 both: 0.000019\n",
      "Train Epoch: 943 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000019 drop: 0.008127 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.1592\tAccuracy: 4404.0/5000 (88%)\n",
      "bn: Loss: 1.0990\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2503\tAccuracy: 4360.0/5000 (87%)\n",
      "both: Loss: 1.0905\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 944 [0/25000 (0%)]\tLosses default: 0.002105 bn: 0.020339 drop: 0.002177 both: 0.002208\n",
      "Train Epoch: 944 [10000/25000 (40%)]\tLosses default: 0.000552 bn: 0.000003 drop: 0.000160 both: 0.000633\n",
      "Train Epoch: 944 [20000/25000 (80%)]\tLosses default: 0.000281 bn: 0.000191 drop: 0.000016 both: 0.000084\n",
      "Train Epoch: 944 [25000/25000 (100%)]\tLosses default: 0.000860 bn: 0.000005 drop: 0.000008 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.1099\tAccuracy: 4394.0/5000 (88%)\n",
      "bn: Loss: 1.0766\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.2098\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0783\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 945 [0/25000 (0%)]\tLosses default: 0.007731 bn: 0.000018 drop: 0.000003 both: 0.000016\n",
      "Train Epoch: 945 [10000/25000 (40%)]\tLosses default: 0.002867 bn: 0.000008 drop: 0.000007 both: 0.000036\n",
      "Train Epoch: 945 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000002 drop: 0.000004 both: 0.000011\n",
      "Train Epoch: 945 [25000/25000 (100%)]\tLosses default: 0.000063 bn: 0.000033 drop: 0.000006 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.0976\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0862\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.2148\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0874\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 946 [0/25000 (0%)]\tLosses default: 0.000052 bn: 0.000006 drop: 0.000016 both: 0.000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 946 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000128 drop: 0.000052 both: 0.000624\n",
      "Train Epoch: 946 [20000/25000 (80%)]\tLosses default: 0.000010 bn: 0.000107 drop: 0.000008 both: 0.000057\n",
      "Train Epoch: 946 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000033 drop: 0.000033 both: 0.000183\n",
      "Test set:\n",
      "default: Loss: 1.1080\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1125\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.2058\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0700\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 947 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.001430 drop: 0.000006 both: 0.003173\n",
      "Train Epoch: 947 [10000/25000 (40%)]\tLosses default: 0.000029 bn: 0.000016 drop: 0.020908 both: 0.001426\n",
      "Train Epoch: 947 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000007 drop: 0.000016 both: 0.000069\n",
      "Train Epoch: 947 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000062 drop: 0.000008 both: 0.003981\n",
      "Test set:\n",
      "default: Loss: 1.1091\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0720\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.2233\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0616\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 948 [0/25000 (0%)]\tLosses default: 0.000055 bn: 0.000058 drop: 0.000001 both: 0.000057\n",
      "Train Epoch: 948 [10000/25000 (40%)]\tLosses default: 0.000030 bn: 0.000005 drop: 0.000007 both: 0.000003\n",
      "Train Epoch: 948 [20000/25000 (80%)]\tLosses default: 0.000019 bn: 0.000003 drop: 0.000009 both: 0.000011\n",
      "Train Epoch: 948 [25000/25000 (100%)]\tLosses default: 0.000041 bn: 0.000023 drop: 0.000062 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.1140\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0909\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.2564\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.1031\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 949 [0/25000 (0%)]\tLosses default: 0.000012 bn: 0.000015 drop: 0.000008 both: 0.000038\n",
      "Train Epoch: 949 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000012 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 949 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000003 both: 0.000107\n",
      "Train Epoch: 949 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000018 drop: 0.000019 both: 0.000040\n",
      "Test set:\n",
      "default: Loss: 1.1193\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0992\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2484\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0705\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 950 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000085 both: 0.000003\n",
      "Train Epoch: 950 [10000/25000 (40%)]\tLosses default: 0.000054 bn: 0.000012 drop: 0.000123 both: 0.001413\n",
      "Train Epoch: 950 [20000/25000 (80%)]\tLosses default: 0.000009 bn: 0.000003 drop: 0.000002 both: 0.000166\n",
      "Train Epoch: 950 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.006315 drop: 0.000007 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.1246\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0900\tAccuracy: 4450.0/5000 (89%)\n",
      "drop: Loss: 1.2292\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0580\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 951 [0/25000 (0%)]\tLosses default: 0.000051 bn: 0.000690 drop: 0.000004 both: 0.000637\n",
      "Train Epoch: 951 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000397 drop: 0.000013 both: 0.007116\n",
      "Train Epoch: 951 [20000/25000 (80%)]\tLosses default: 0.000018 bn: 0.000065 drop: 0.000014 both: 0.000871\n",
      "Train Epoch: 951 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000005 drop: 0.000004 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.1296\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0593\tAccuracy: 4456.0/5000 (89%)\n",
      "drop: Loss: 1.2582\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0709\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 952 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000007 drop: 0.000012 both: 0.020728\n",
      "Train Epoch: 952 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000001 drop: 0.000003 both: 0.000009\n",
      "Train Epoch: 952 [20000/25000 (80%)]\tLosses default: 0.000031 bn: 0.000009 drop: 0.000018 both: 0.000043\n",
      "Train Epoch: 952 [25000/25000 (100%)]\tLosses default: 0.000031 bn: 0.000008 drop: 0.003991 both: 0.000033\n",
      "Test set:\n",
      "default: Loss: 1.1355\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0637\tAccuracy: 4449.0/5000 (89%)\n",
      "drop: Loss: 1.2231\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0550\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 953 [0/25000 (0%)]\tLosses default: 0.000014 bn: 0.000041 drop: 0.000157 both: 0.000081\n",
      "Train Epoch: 953 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000007 drop: 0.000036 both: 0.000009\n",
      "Train Epoch: 953 [20000/25000 (80%)]\tLosses default: 0.000013 bn: 0.000004 drop: 0.000030 both: 0.000022\n",
      "Train Epoch: 953 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000028 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.1410\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0877\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1739\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0777\tAccuracy: 4366.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 954 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000008 drop: 0.000018 both: 0.000005\n",
      "Train Epoch: 954 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000014 drop: 0.000188 both: 0.000198\n",
      "Train Epoch: 954 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000002 both: 0.001773\n",
      "Train Epoch: 954 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000006 drop: 0.000023 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.1470\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0543\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.1879\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0779\tAccuracy: 4366.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 955 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000002 drop: 0.000009 both: 0.000024\n",
      "Train Epoch: 955 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000006 both: 0.010774\n",
      "Train Epoch: 955 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000005 both: 0.000003\n",
      "Train Epoch: 955 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000001 drop: 0.034629 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.1528\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0968\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.2723\tAccuracy: 4315.0/5000 (86%)\n",
      "both: Loss: 1.0673\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 956 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000003 drop: 0.000016 both: 0.000004\n",
      "Train Epoch: 956 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.002014 both: 0.000011\n",
      "Train Epoch: 956 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000064 drop: 0.000018 both: 0.000024\n",
      "Train Epoch: 956 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000069 drop: 0.000528 both: 0.001390\n",
      "Test set:\n",
      "default: Loss: 1.1596\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1123\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.2049\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.1036\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 957 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000065 drop: 0.000020 both: 0.000065\n",
      "Train Epoch: 957 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000004 drop: 0.000053 both: 0.000075\n",
      "Train Epoch: 957 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000002 drop: 0.005597 both: 0.000961\n",
      "Train Epoch: 957 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000968 both: 0.105074\n",
      "Test set:\n",
      "default: Loss: 1.1661\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1132\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2038\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.1038\tAccuracy: 4363.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 958 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.004374 drop: 0.000266 both: 0.000434\n",
      "Train Epoch: 958 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000063 both: 0.005466\n",
      "Train Epoch: 958 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.003640 both: 0.000396\n",
      "Train Epoch: 958 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000033 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1730\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1093\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.2093\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.1260\tAccuracy: 4356.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 959 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000093 drop: 0.012862 both: 0.000054\n",
      "Train Epoch: 959 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000047 drop: 0.000017 both: 0.000006\n",
      "Train Epoch: 959 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000003 both: 0.000011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 959 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000012 drop: 0.000034 both: 0.000113\n",
      "Test set:\n",
      "default: Loss: 1.1806\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0850\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.2416\tAccuracy: 4367.0/5000 (87%)\n",
      "both: Loss: 1.0576\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 960 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000340 drop: 0.166040 both: 0.000050\n",
      "Train Epoch: 960 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000002 drop: 0.001872 both: 0.000073\n",
      "Train Epoch: 960 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000005 drop: 0.007516 both: 0.000035\n",
      "Train Epoch: 960 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000005 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.1871\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0862\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.2093\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0596\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 961 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000169 drop: 0.000011 both: 0.000074\n",
      "Train Epoch: 961 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000122 drop: 0.000007 both: 0.000029\n",
      "Train Epoch: 961 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000018 drop: 0.003268 both: 0.000010\n",
      "Train Epoch: 961 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000020 drop: 0.000008 both: 0.000025\n",
      "Test set:\n",
      "default: Loss: 1.1949\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0817\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.2259\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0341\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 962 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000004 both: 0.000008\n",
      "Train Epoch: 962 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000032 drop: 0.000002 both: 0.000250\n",
      "Train Epoch: 962 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000516 drop: 0.000004 both: 0.000011\n",
      "Train Epoch: 962 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000060 drop: 0.000346 both: 0.001047\n",
      "Test set:\n",
      "default: Loss: 1.2015\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0897\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1960\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0589\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 963 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000178 drop: 0.000047 both: 0.000127\n",
      "Train Epoch: 963 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000085 both: 0.000007\n",
      "Train Epoch: 963 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000003 both: 0.004870\n",
      "Train Epoch: 963 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000019 both: 0.000340\n",
      "Test set:\n",
      "default: Loss: 1.2090\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0999\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.2215\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0391\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 964 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000067 drop: 0.000003 both: 0.000776\n",
      "Train Epoch: 964 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000039 drop: 0.000003 both: 0.000419\n",
      "Train Epoch: 964 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000548 drop: 0.000011 both: 0.000866\n",
      "Train Epoch: 964 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001475 drop: 0.000007 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.2165\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0863\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.2156\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0531\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 965 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000053 drop: 0.000004 both: 0.000005\n",
      "Train Epoch: 965 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000004 both: 0.000002\n",
      "Train Epoch: 965 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000004 both: 0.000004\n",
      "Train Epoch: 965 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000008 drop: 0.000006 both: 0.000083\n",
      "Test set:\n",
      "default: Loss: 1.2239\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0605\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.2032\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0957\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 966 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000009 drop: 0.000002 both: 0.000031\n",
      "Train Epoch: 966 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000005 both: 0.000071\n",
      "Train Epoch: 966 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000015 both: 0.000186\n",
      "Train Epoch: 966 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000055 drop: 0.000005 both: 0.000101\n",
      "Test set:\n",
      "default: Loss: 1.2318\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1319\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.1938\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0958\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 967 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000216 drop: 0.000001 both: 0.000036\n",
      "Train Epoch: 967 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.004046 drop: 0.000003 both: 0.000009\n",
      "Train Epoch: 967 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000008 both: 0.096801\n",
      "Train Epoch: 967 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.000032 both: 0.000410\n",
      "Test set:\n",
      "default: Loss: 1.2398\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0956\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.2150\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0972\tAccuracy: 4367.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 968 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000026 both: 0.010634\n",
      "Train Epoch: 968 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000019 both: 0.000018\n",
      "Train Epoch: 968 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000102 drop: 0.000031 both: 0.000059\n",
      "Train Epoch: 968 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000006 both: 0.000174\n",
      "Test set:\n",
      "default: Loss: 1.2459\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0756\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.2264\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0837\tAccuracy: 4374.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 969 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000012 both: 0.010699\n",
      "Train Epoch: 969 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000063 drop: 0.000002 both: 0.000451\n",
      "Train Epoch: 969 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000001 both: 0.000009\n",
      "Train Epoch: 969 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000068 drop: 0.000003 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.2542\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0959\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.2101\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0589\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 970 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000001 both: 0.000010\n",
      "Train Epoch: 970 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000112 both: 0.000041\n",
      "Train Epoch: 970 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000000 both: 0.000006\n",
      "Train Epoch: 970 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000088 drop: 0.000002 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.2600\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1030\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.2166\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0813\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 971 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000370 drop: 0.000001 both: 0.000005\n",
      "Train Epoch: 971 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000193 drop: 0.000002 both: 0.000016\n",
      "Train Epoch: 971 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001864 drop: 0.000001 both: 0.000154\n",
      "Train Epoch: 971 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000010 both: 0.000600\n",
      "Test set:\n",
      "default: Loss: 1.2675\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.1016\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.2103\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1216\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 972 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000004 both: 0.000002\n",
      "Train Epoch: 972 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000005 both: 0.000019\n",
      "Train Epoch: 972 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000008 both: 0.001000\n",
      "Train Epoch: 972 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000109 drop: 0.000359 both: 0.000155\n",
      "Test set:\n",
      "default: Loss: 1.2747\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0893\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.2229\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0491\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 973 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000001 both: 0.000008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 973 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000039 drop: 0.000008 both: 0.000011\n",
      "Train Epoch: 973 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000056 drop: 0.000005 both: 0.000008\n",
      "Train Epoch: 973 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000295 drop: 0.000002 both: 0.000049\n",
      "Test set:\n",
      "default: Loss: 1.2804\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0730\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2255\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0911\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 974 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000006 both: 0.000005\n",
      "Train Epoch: 974 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000072 drop: 0.000003 both: 0.035306\n",
      "Train Epoch: 974 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.005944 drop: 0.000015 both: 0.016467\n",
      "Train Epoch: 974 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000003 both: 0.000046\n",
      "Test set:\n",
      "default: Loss: 1.2888\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0886\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.2325\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0832\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 975 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000726 drop: 0.000003 both: 0.000040\n",
      "Train Epoch: 975 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.007689 drop: 0.000003 both: 0.000104\n",
      "Train Epoch: 975 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000005 both: 0.000003\n",
      "Train Epoch: 975 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000035 drop: 0.000000 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.2955\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0618\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.2476\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0913\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 976 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000163 drop: 0.000000 both: 0.000046\n",
      "Train Epoch: 976 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000000 both: 0.000406\n",
      "Train Epoch: 976 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000129 drop: 0.000001 both: 0.000171\n",
      "Train Epoch: 976 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000001 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.3000\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0897\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.2554\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.1389\tAccuracy: 4362.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 977 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.000050\n",
      "Train Epoch: 977 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000004 both: 0.003587\n",
      "Train Epoch: 977 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000599 drop: 0.000018 both: 0.000011\n",
      "Train Epoch: 977 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000001 both: 0.000065\n",
      "Test set:\n",
      "default: Loss: 1.3058\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1140\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2477\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.1020\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 978 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000059 drop: 0.000002 both: 0.000026\n",
      "Train Epoch: 978 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000139 drop: 0.000000 both: 0.000013\n",
      "Train Epoch: 978 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000001 both: 0.000007\n",
      "Train Epoch: 978 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000001 both: 0.001305\n",
      "Test set:\n",
      "default: Loss: 1.3126\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1079\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.2517\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.1201\tAccuracy: 4366.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 979 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000092 drop: 0.000002 both: 0.000050\n",
      "Train Epoch: 979 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000001 both: 0.000099\n",
      "Train Epoch: 979 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000239 drop: 0.000004 both: 0.000687\n",
      "Train Epoch: 979 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000097 drop: 0.000004 both: 0.000049\n",
      "Test set:\n",
      "default: Loss: 1.3167\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1232\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.2692\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.1212\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 980 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.009136\n",
      "Train Epoch: 980 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000615 drop: 0.000001 both: 0.000010\n",
      "Train Epoch: 980 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.001144 both: 0.000022\n",
      "Train Epoch: 980 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000039\n",
      "Test set:\n",
      "default: Loss: 1.3196\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1182\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.2086\tAccuracy: 4358.0/5000 (87%)\n",
      "both: Loss: 1.1152\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 981 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.001205 both: 0.000016\n",
      "Train Epoch: 981 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000012\n",
      "Train Epoch: 981 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000000 both: 0.000009\n",
      "Train Epoch: 981 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001080 drop: 0.000015 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3267\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1042\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.2388\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.1269\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 982 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000003 both: 0.000002\n",
      "Train Epoch: 982 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000072 drop: 0.000004 both: 0.000111\n",
      "Train Epoch: 982 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000085 both: 0.000596\n",
      "Train Epoch: 982 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000011 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3277\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.1308\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.1971\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0637\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 983 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.002958 drop: 0.000001 both: 0.000027\n",
      "Train Epoch: 983 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000130 drop: 0.000045 both: 0.000193\n",
      "Train Epoch: 983 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000220 drop: 0.000001 both: 0.000118\n",
      "Train Epoch: 983 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000125 both: 0.000088\n",
      "Test set:\n",
      "default: Loss: 1.3306\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.1155\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.1928\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0631\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 984 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000002 both: 0.000003\n",
      "Train Epoch: 984 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000078 both: 0.000022\n",
      "Train Epoch: 984 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000098 both: 0.000346\n",
      "Train Epoch: 984 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000037 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3321\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0980\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.2389\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0667\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 985 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000020 both: 0.000253\n",
      "Train Epoch: 985 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000005 both: 0.000033\n",
      "Train Epoch: 985 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000008\n",
      "Train Epoch: 985 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000081 both: 0.000536\n",
      "Test set:\n",
      "default: Loss: 1.3328\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1090\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.2188\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0902\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 986 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000022 both: 0.000002\n",
      "Train Epoch: 986 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000004 both: 0.000018\n",
      "Train Epoch: 986 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000058 both: 0.000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 986 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000016 both: 0.000036\n",
      "Test set:\n",
      "default: Loss: 1.3327\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0973\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.2208\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0538\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 987 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000006 both: 0.000042\n",
      "Train Epoch: 987 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000125 both: 0.000040\n",
      "Train Epoch: 987 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000264 drop: 0.000010 both: 0.000113\n",
      "Train Epoch: 987 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000412 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.3364\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1143\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.2221\tAccuracy: 4356.0/5000 (87%)\n",
      "both: Loss: 1.1045\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 988 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000098 both: 0.000028\n",
      "Train Epoch: 988 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000360 drop: 0.000007 both: 0.000339\n",
      "Train Epoch: 988 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000063 drop: 0.000025 both: 0.000033\n",
      "Train Epoch: 988 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000060 drop: 0.000299 both: 0.000039\n",
      "Test set:\n",
      "default: Loss: 1.3342\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.1093\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.3044\tAccuracy: 4367.0/5000 (87%)\n",
      "both: Loss: 1.1016\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 989 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000282 both: 0.000105\n",
      "Train Epoch: 989 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000215 both: 0.077831\n",
      "Train Epoch: 989 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000115 both: 0.000008\n",
      "Train Epoch: 989 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000146 drop: 0.000035 both: 0.000218\n",
      "Test set:\n",
      "default: Loss: 1.3303\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1271\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2184\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0835\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 990 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000185 drop: 0.000364 both: 0.000010\n",
      "Train Epoch: 990 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000204 drop: 0.000457 both: 0.000019\n",
      "Train Epoch: 990 [20000/25000 (80%)]\tLosses default: 0.039807 bn: 0.000016 drop: 0.006918 both: 0.000016\n",
      "Train Epoch: 990 [25000/25000 (100%)]\tLosses default: 0.016820 bn: 0.000015 drop: 0.000390 both: 0.002027\n",
      "Test set:\n",
      "default: Loss: 0.9775\tAccuracy: 4402.0/5000 (88%)\n",
      "bn: Loss: 1.1180\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.2110\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0727\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 991 [0/25000 (0%)]\tLosses default: 0.000784 bn: 0.000007 drop: 0.000001 both: 0.000015\n",
      "Train Epoch: 991 [10000/25000 (40%)]\tLosses default: 0.002916 bn: 0.000012 drop: 0.000007 both: 0.000295\n",
      "Train Epoch: 991 [20000/25000 (80%)]\tLosses default: 0.000033 bn: 0.000053 drop: 0.000001 both: 0.018518\n",
      "Train Epoch: 991 [25000/25000 (100%)]\tLosses default: 0.001600 bn: 0.000001 drop: 0.000110 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.0424\tAccuracy: 4413.0/5000 (88%)\n",
      "bn: Loss: 1.1567\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.2252\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.1129\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 992 [0/25000 (0%)]\tLosses default: 0.005258 bn: 0.000007 drop: 0.000758 both: 0.000176\n",
      "Train Epoch: 992 [10000/25000 (40%)]\tLosses default: 0.000033 bn: 0.000000 drop: 0.000000 both: 0.000009\n",
      "Train Epoch: 992 [20000/25000 (80%)]\tLosses default: 0.000046 bn: 0.001150 drop: 0.000004 both: 0.000048\n",
      "Train Epoch: 992 [25000/25000 (100%)]\tLosses default: 0.000029 bn: 0.000004 drop: 0.000032 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.0936\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.1708\tAccuracy: 4392.0/5000 (88%)\n",
      "drop: Loss: 1.2041\tAccuracy: 4366.0/5000 (87%)\n",
      "both: Loss: 1.0809\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 993 [0/25000 (0%)]\tLosses default: 0.000126 bn: 0.000209 drop: 0.000016 both: 0.000025\n",
      "Train Epoch: 993 [10000/25000 (40%)]\tLosses default: 0.000129 bn: 0.000367 drop: 0.000011 both: 0.000005\n",
      "Train Epoch: 993 [20000/25000 (80%)]\tLosses default: 0.000029 bn: 0.000022 drop: 0.000005 both: 0.000004\n",
      "Train Epoch: 993 [25000/25000 (100%)]\tLosses default: 0.000033 bn: 0.000595 drop: 0.000002 both: 0.000125\n",
      "Test set:\n",
      "default: Loss: 1.1087\tAccuracy: 4414.0/5000 (88%)\n",
      "bn: Loss: 1.1061\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2382\tAccuracy: 4353.0/5000 (87%)\n",
      "both: Loss: 1.0956\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 994 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000019 drop: 0.000124 both: 0.000001\n",
      "Train Epoch: 994 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.000002 drop: 0.000001 both: 0.000120\n",
      "Train Epoch: 994 [20000/25000 (80%)]\tLosses default: 0.000024 bn: 0.000030 drop: 0.000016 both: 0.000003\n",
      "Train Epoch: 994 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.001064 drop: 0.000002 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.1114\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1109\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.2389\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.1037\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 995 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000021 drop: 0.000037 both: 0.000142\n",
      "Train Epoch: 995 [10000/25000 (40%)]\tLosses default: 0.000026 bn: 0.000025 drop: 0.000011 both: 0.000010\n",
      "Train Epoch: 995 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000000 drop: 0.000003 both: 0.000044\n",
      "Train Epoch: 995 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000001 drop: 0.000027 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.1224\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1037\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.2185\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.0916\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 996 [0/25000 (0%)]\tLosses default: 0.000015 bn: 0.000006 drop: 0.000139 both: 0.000023\n",
      "Train Epoch: 996 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000091 drop: 0.003815 both: 0.000025\n",
      "Train Epoch: 996 [20000/25000 (80%)]\tLosses default: 0.000066 bn: 0.003147 drop: 0.000278 both: 0.006746\n",
      "Train Epoch: 996 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000005 drop: 0.000043 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.1319\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.1057\tAccuracy: 4400.0/5000 (88%)\n",
      "drop: Loss: 1.1925\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0752\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 997 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000056 drop: 0.013638 both: 0.000013\n",
      "Train Epoch: 997 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000023 drop: 0.000304 both: 0.000014\n",
      "Train Epoch: 997 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000013 drop: 0.000078 both: 0.000025\n",
      "Train Epoch: 997 [25000/25000 (100%)]\tLosses default: 0.000017 bn: 0.000011 drop: 0.000242 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.1433\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1457\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.2038\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0579\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 998 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000022 drop: 0.000004 both: 0.000019\n",
      "Train Epoch: 998 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000159 drop: 0.000047 both: 0.000030\n",
      "Train Epoch: 998 [20000/25000 (80%)]\tLosses default: 0.000049 bn: 0.000401 drop: 0.000002 both: 0.000004\n",
      "Train Epoch: 998 [25000/25000 (100%)]\tLosses default: 0.000029 bn: 0.000009 drop: 0.000063 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1547\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1387\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.1933\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0708\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 999 [0/25000 (0%)]\tLosses default: 0.000019 bn: 0.000007 drop: 0.000027 both: 0.000005\n",
      "Train Epoch: 999 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000071 drop: 0.000026 both: 0.000016\n",
      "Train Epoch: 999 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000115 drop: 0.000052 both: 0.000054\n",
      "Train Epoch: 999 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000010 both: 0.000760\n",
      "Test set:\n",
      "default: Loss: 1.1654\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.1195\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.2052\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.1019\tAccuracy: 4363.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1000 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000011 both: 0.032377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1000 [10000/25000 (40%)]\tLosses default: 0.000019 bn: 0.000335 drop: 0.000026 both: 0.000010\n",
      "Train Epoch: 1000 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000011 drop: 0.000061 both: 0.000050\n",
      "Train Epoch: 1000 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000331 drop: 0.000002 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1765\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1355\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.1943\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0411\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1001 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000006 drop: 0.000001 both: 0.000083\n",
      "Train Epoch: 1001 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000021 drop: 0.000045 both: 0.000245\n",
      "Train Epoch: 1001 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000076 drop: 0.000025 both: 0.000012\n",
      "Train Epoch: 1001 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000005 drop: 0.000004 both: 0.000036\n",
      "Test set:\n",
      "default: Loss: 1.1865\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1441\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1943\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0520\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1002 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000039 drop: 0.000003 both: 0.000138\n",
      "Train Epoch: 1002 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000010 both: 0.000005\n",
      "Train Epoch: 1002 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000004 both: 0.000011\n",
      "Train Epoch: 1002 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000010 both: 0.000744\n",
      "Test set:\n",
      "default: Loss: 1.1966\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.1219\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1902\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0703\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1003 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000081 drop: 0.000009 both: 0.000026\n",
      "Train Epoch: 1003 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000006 both: 0.000039\n",
      "Train Epoch: 1003 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000003 drop: 0.000003 both: 0.000032\n",
      "Train Epoch: 1003 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000323 drop: 0.000006 both: 0.000083\n",
      "Test set:\n",
      "default: Loss: 1.2077\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.1005\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1938\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0997\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1004 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000009 both: 0.000009\n",
      "Train Epoch: 1004 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000006 both: 0.000018\n",
      "Train Epoch: 1004 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000005 both: 0.000089\n",
      "Train Epoch: 1004 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000072 drop: 0.000002 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.2179\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1226\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.2006\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1095\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1005 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000010 drop: 0.000006 both: 0.000043\n",
      "Train Epoch: 1005 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000088 drop: 0.000042 both: 0.000291\n",
      "Train Epoch: 1005 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000528 drop: 0.000003 both: 0.000108\n",
      "Train Epoch: 1005 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000008 both: 0.000031\n",
      "Test set:\n",
      "default: Loss: 1.2295\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1378\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1955\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.1104\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1006 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000015 both: 0.000004\n",
      "Train Epoch: 1006 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000010 both: 0.000004\n",
      "Train Epoch: 1006 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.137158 both: 0.000014\n",
      "Train Epoch: 1006 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000016 drop: 0.197994 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2383\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1268\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2395\tAccuracy: 4337.0/5000 (87%)\n",
      "both: Loss: 1.0968\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1007 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.178829 both: 0.000007\n",
      "Train Epoch: 1007 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000011 both: 0.000006\n",
      "Train Epoch: 1007 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000002 drop: 0.000091 both: 0.000002\n",
      "Train Epoch: 1007 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.032992 drop: 0.000082 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.2474\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1403\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.1863\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.1001\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1008 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.001761 both: 0.000486\n",
      "Train Epoch: 1008 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000052 both: 0.000058\n",
      "Train Epoch: 1008 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000041 both: 0.000004\n",
      "Train Epoch: 1008 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.079647 drop: 0.000270 both: 0.001215\n",
      "Test set:\n",
      "default: Loss: 1.2572\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1315\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.1833\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0943\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1009 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000011 both: 0.000019\n",
      "Train Epoch: 1009 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000009 drop: 0.000069 both: 0.000042\n",
      "Train Epoch: 1009 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000016 both: 0.069189\n",
      "Train Epoch: 1009 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.011323 drop: 0.000005 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.2660\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1053\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.1619\tAccuracy: 4365.0/5000 (87%)\n",
      "both: Loss: 1.1007\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1010 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000040 drop: 0.000094 both: 0.000452\n",
      "Train Epoch: 1010 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000024 drop: 0.000011 both: 0.000117\n",
      "Train Epoch: 1010 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000163 both: 0.000024\n",
      "Train Epoch: 1010 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000005 both: 0.000031\n",
      "Test set:\n",
      "default: Loss: 1.2752\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.1132\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1629\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0751\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1011 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000008 both: 0.000102\n",
      "Train Epoch: 1011 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000005 both: 0.000007\n",
      "Train Epoch: 1011 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000003 both: 0.000033\n",
      "Train Epoch: 1011 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000021 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.2821\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1240\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1556\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0771\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1012 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000020 drop: 0.000014 both: 0.000010\n",
      "Train Epoch: 1012 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000003\n",
      "Train Epoch: 1012 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001469 drop: 0.000422 both: 0.001473\n",
      "Train Epoch: 1012 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000461 drop: 0.000011 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.2905\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0744\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1668\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0639\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1013 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000002 both: 0.000007\n",
      "Train Epoch: 1013 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000013 both: 0.000425\n",
      "Train Epoch: 1013 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000031 both: 0.000139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1013 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000014 drop: 0.051944 both: 0.000185\n",
      "Test set:\n",
      "default: Loss: 1.2978\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0801\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.2208\tAccuracy: 4361.0/5000 (87%)\n",
      "both: Loss: 1.0822\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1014 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000058 drop: 0.029359 both: 0.000045\n",
      "Train Epoch: 1014 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.001459 both: 0.000042\n",
      "Train Epoch: 1014 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000057 drop: 0.000045 both: 0.000005\n",
      "Train Epoch: 1014 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000189 drop: 0.000069 both: 0.000114\n",
      "Test set:\n",
      "default: Loss: 1.3044\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0998\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1758\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.0875\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1015 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000098 drop: 0.000026 both: 0.000041\n",
      "Train Epoch: 1015 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000113 drop: 0.000088 both: 0.000010\n",
      "Train Epoch: 1015 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000637 both: 0.000003\n",
      "Train Epoch: 1015 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.002904 both: 0.000058\n",
      "Test set:\n",
      "default: Loss: 1.3123\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.1026\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1477\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0958\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1016 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000072 drop: 0.000011 both: 0.000212\n",
      "Train Epoch: 1016 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000005 both: 0.000019\n",
      "Train Epoch: 1016 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.003507 both: 0.000510\n",
      "Train Epoch: 1016 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000177 drop: 0.000030 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.3186\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1226\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1432\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0792\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1017 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000017 both: 0.000007\n",
      "Train Epoch: 1017 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000004 both: 0.000002\n",
      "Train Epoch: 1017 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000665 both: 0.000058\n",
      "Train Epoch: 1017 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000003 both: 0.000107\n",
      "Test set:\n",
      "default: Loss: 1.3231\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1304\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1524\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0847\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1018 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000332\n",
      "Train Epoch: 1018 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000001 both: 0.000068\n",
      "Train Epoch: 1018 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000003 both: 0.000008\n",
      "Train Epoch: 1018 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000077 drop: 0.000008 both: 0.000345\n",
      "Test set:\n",
      "default: Loss: 1.3289\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1271\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.1740\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0597\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1019 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000034 drop: 0.000064 both: 0.000015\n",
      "Train Epoch: 1019 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000002 both: 0.003127\n",
      "Train Epoch: 1019 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000002 both: 0.000015\n",
      "Train Epoch: 1019 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000408 drop: 0.000014 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.3338\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1155\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1794\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0916\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1020 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000008 both: 0.000002\n",
      "Train Epoch: 1020 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000005 both: 0.000011\n",
      "Train Epoch: 1020 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000015 both: 0.000004\n",
      "Train Epoch: 1020 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000774 drop: 0.000006 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.3401\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1037\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1683\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0810\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1021 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000325 drop: 0.000054 both: 0.000015\n",
      "Train Epoch: 1021 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000006 both: 0.021560\n",
      "Train Epoch: 1021 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000020 both: 0.000013\n",
      "Train Epoch: 1021 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000009 both: 0.006600\n",
      "Test set:\n",
      "default: Loss: 1.3465\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1489\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1831\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0649\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1022 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000233 drop: 0.000016 both: 0.000007\n",
      "Train Epoch: 1022 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000009 both: 0.000015\n",
      "Train Epoch: 1022 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000022 both: 0.000008\n",
      "Train Epoch: 1022 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000000 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.3500\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1200\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1836\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0769\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1023 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000003 both: 0.000241\n",
      "Train Epoch: 1023 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000006 both: 0.000432\n",
      "Train Epoch: 1023 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000373\n",
      "Train Epoch: 1023 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000112 drop: 0.000002 both: 0.001414\n",
      "Test set:\n",
      "default: Loss: 1.3554\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1018\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.1977\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0800\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1024 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000008 both: 0.000038\n",
      "Train Epoch: 1024 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000752 drop: 0.000019 both: 0.000057\n",
      "Train Epoch: 1024 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000154 drop: 0.000016 both: 0.000073\n",
      "Train Epoch: 1024 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000736 drop: 0.004945 both: 0.001351\n",
      "Test set:\n",
      "default: Loss: 1.3585\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.1503\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.2516\tAccuracy: 4320.0/5000 (86%)\n",
      "both: Loss: 1.0879\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1025 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.015260 both: 0.000048\n",
      "Train Epoch: 1025 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000007 both: 0.000157\n",
      "Train Epoch: 1025 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000312 both: 0.000022\n",
      "Train Epoch: 1025 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000411 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.3626\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1024\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 1.1378\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0807\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1026 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000395 both: 0.000054\n",
      "Train Epoch: 1026 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000080 both: 0.000013\n",
      "Train Epoch: 1026 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000055 both: 0.000043\n",
      "Train Epoch: 1026 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000551 drop: 0.000010 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3656\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.1134\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.1229\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0523\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1027 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000267 both: 0.000166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1027 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000084 both: 0.000013\n",
      "Train Epoch: 1027 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000165 both: 0.007788\n",
      "Train Epoch: 1027 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.016384 drop: 0.000159 both: 0.032015\n",
      "Test set:\n",
      "default: Loss: 1.3673\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1041\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.1412\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0610\tAccuracy: 4368.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1028 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000077 drop: 0.000046 both: 0.000038\n",
      "Train Epoch: 1028 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000016 both: 0.000013\n",
      "Train Epoch: 1028 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000047 drop: 0.000002 both: 0.000015\n",
      "Train Epoch: 1028 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000001 both: 0.000036\n",
      "Test set:\n",
      "default: Loss: 1.3707\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.1155\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1439\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0842\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1029 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000296 drop: 0.000005 both: 0.000070\n",
      "Train Epoch: 1029 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000086 drop: 0.000025 both: 0.000121\n",
      "Train Epoch: 1029 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000057 both: 0.000011\n",
      "Train Epoch: 1029 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000099 both: 0.000087\n",
      "Test set:\n",
      "default: Loss: 1.3733\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1158\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1374\tAccuracy: 4412.0/5000 (88%)\n",
      "both: Loss: 1.0719\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1030 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000006 both: 0.000079\n",
      "Train Epoch: 1030 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000011 both: 0.000012\n",
      "Train Epoch: 1030 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000005 both: 0.000005\n",
      "Train Epoch: 1030 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001189 drop: 0.000026 both: 0.000058\n",
      "Test set:\n",
      "default: Loss: 1.3765\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1706\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1406\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0508\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1031 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000007 both: 0.000011\n",
      "Train Epoch: 1031 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 1031 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000104 drop: 0.000012 both: 0.001307\n",
      "Train Epoch: 1031 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000005 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.3759\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0711\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.1269\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0812\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1032 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000000 both: 0.000001\n",
      "Train Epoch: 1032 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000125 both: 0.000096\n",
      "Train Epoch: 1032 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000057 both: 0.000104\n",
      "Train Epoch: 1032 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000003 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.3754\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1117\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1303\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0811\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1033 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.006563 drop: 0.000027 both: 0.000265\n",
      "Train Epoch: 1033 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000070 drop: 0.000001 both: 0.000171\n",
      "Train Epoch: 1033 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000101\n",
      "Train Epoch: 1033 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001542 drop: 0.000006 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.3755\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1248\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 1.1657\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0340\tAccuracy: 4414.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1034 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000232 both: 0.001629\n",
      "Train Epoch: 1034 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000003 both: 0.000019\n",
      "Train Epoch: 1034 [20000/25000 (80%)]\tLosses default: 0.002819 bn: 0.000007 drop: 0.000001 both: 0.000281\n",
      "Train Epoch: 1034 [25000/25000 (100%)]\tLosses default: 0.000640 bn: 0.000001 drop: 0.000009 both: 0.000200\n",
      "Test set:\n",
      "default: Loss: 1.0276\tAccuracy: 4397.0/5000 (88%)\n",
      "bn: Loss: 1.1761\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.1591\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0559\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1035 [0/25000 (0%)]\tLosses default: 0.000526 bn: 0.148270 drop: 0.000033 both: 0.000040\n",
      "Train Epoch: 1035 [10000/25000 (40%)]\tLosses default: 0.000038 bn: 0.000001 drop: 0.000002 both: 0.000004\n",
      "Train Epoch: 1035 [20000/25000 (80%)]\tLosses default: 0.000010 bn: 0.000013 drop: 0.000011 both: 0.000016\n",
      "Train Epoch: 1035 [25000/25000 (100%)]\tLosses default: 0.003387 bn: 0.000007 drop: 0.000006 both: 0.000266\n",
      "Test set:\n",
      "default: Loss: 1.0992\tAccuracy: 4402.0/5000 (88%)\n",
      "bn: Loss: 1.0838\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1767\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0553\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1036 [0/25000 (0%)]\tLosses default: 0.003220 bn: 0.000001 drop: 0.000084 both: 0.005966\n",
      "Train Epoch: 1036 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.001367 drop: 0.009391 both: 0.000103\n",
      "Train Epoch: 1036 [20000/25000 (80%)]\tLosses default: 0.000184 bn: 0.000004 drop: 0.000975 both: 0.000004\n",
      "Train Epoch: 1036 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000000 drop: 0.000060 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.0724\tAccuracy: 4410.0/5000 (88%)\n",
      "bn: Loss: 1.0815\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.1247\tAccuracy: 4361.0/5000 (87%)\n",
      "both: Loss: 1.0610\tAccuracy: 4414.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1037 [0/25000 (0%)]\tLosses default: 0.000023 bn: 0.000003 drop: 0.000101 both: 0.000034\n",
      "Train Epoch: 1037 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000001 drop: 0.000449 both: 0.000002\n",
      "Train Epoch: 1037 [20000/25000 (80%)]\tLosses default: 0.000011 bn: 0.000306 drop: 0.000012 both: 0.000037\n",
      "Train Epoch: 1037 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000002 drop: 0.000024 both: 0.000100\n",
      "Test set:\n",
      "default: Loss: 1.0644\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0575\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1342\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.1228\tAccuracy: 4362.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1038 [0/25000 (0%)]\tLosses default: 0.000013 bn: 0.000024 drop: 0.000064 both: 0.000040\n",
      "Train Epoch: 1038 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000016 both: 0.000189\n",
      "Train Epoch: 1038 [20000/25000 (80%)]\tLosses default: 0.000031 bn: 0.000020 drop: 0.000091 both: 0.000005\n",
      "Train Epoch: 1038 [25000/25000 (100%)]\tLosses default: 0.000081 bn: 0.000016 drop: 0.000065 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.0800\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0834\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1551\tAccuracy: 4372.0/5000 (87%)\n",
      "both: Loss: 1.0870\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1039 [0/25000 (0%)]\tLosses default: 0.000016 bn: 0.000015 drop: 0.000001 both: 0.002856\n",
      "Train Epoch: 1039 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.010266 drop: 0.000023 both: 0.000193\n",
      "Train Epoch: 1039 [20000/25000 (80%)]\tLosses default: 0.000048 bn: 0.000001 drop: 0.000061 both: 0.000005\n",
      "Train Epoch: 1039 [25000/25000 (100%)]\tLosses default: 0.000076 bn: 0.000030 drop: 0.000030 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.0941\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0792\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1107\tAccuracy: 4408.0/5000 (88%)\n",
      "both: Loss: 1.0916\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1040 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000004 both: 0.000005\n",
      "Train Epoch: 1040 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000040 drop: 0.000208 both: 0.000033\n",
      "Train Epoch: 1040 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000003 both: 0.000946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1040 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000010 drop: 0.000003 both: 0.000157\n",
      "Test set:\n",
      "default: Loss: 1.1052\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0807\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.1478\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.1046\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1041 [0/25000 (0%)]\tLosses default: 0.000031 bn: 0.000065 drop: 0.000004 both: 0.000337\n",
      "Train Epoch: 1041 [10000/25000 (40%)]\tLosses default: 0.000028 bn: 0.000060 drop: 0.000000 both: 0.000012\n",
      "Train Epoch: 1041 [20000/25000 (80%)]\tLosses default: 0.000048 bn: 0.000000 drop: 0.000016 both: 0.000012\n",
      "Train Epoch: 1041 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000151 drop: 0.000003 both: 0.000133\n",
      "Test set:\n",
      "default: Loss: 1.1172\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0703\tAccuracy: 4452.0/5000 (89%)\n",
      "drop: Loss: 1.1354\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0886\tAccuracy: 4367.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1042 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000003 both: 0.000007\n",
      "Train Epoch: 1042 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.000004 drop: 0.000022 both: 0.000038\n",
      "Train Epoch: 1042 [20000/25000 (80%)]\tLosses default: 0.000011 bn: 0.000074 drop: 0.000014 both: 0.000085\n",
      "Train Epoch: 1042 [25000/25000 (100%)]\tLosses default: 0.000019 bn: 0.000298 drop: 0.000055 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.1300\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0760\tAccuracy: 4453.0/5000 (89%)\n",
      "drop: Loss: 1.1376\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0695\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1043 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000030 drop: 0.000021 both: 0.000030\n",
      "Train Epoch: 1043 [10000/25000 (40%)]\tLosses default: 0.000025 bn: 0.000010 drop: 0.000016 both: 0.001500\n",
      "Train Epoch: 1043 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000018 drop: 0.000002 both: 0.000020\n",
      "Train Epoch: 1043 [25000/25000 (100%)]\tLosses default: 0.000013 bn: 0.000001 drop: 0.000001 both: 0.004196\n",
      "Test set:\n",
      "default: Loss: 1.1425\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0985\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.1610\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0596\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1044 [0/25000 (0%)]\tLosses default: 0.000026 bn: 0.000005 drop: 0.000005 both: 0.000006\n",
      "Train Epoch: 1044 [10000/25000 (40%)]\tLosses default: 0.000017 bn: 0.000003 drop: 0.000030 both: 0.000108\n",
      "Train Epoch: 1044 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000093 drop: 0.000002 both: 0.000044\n",
      "Train Epoch: 1044 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000001 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.1508\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1161\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1375\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0654\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1045 [0/25000 (0%)]\tLosses default: 0.000017 bn: 0.000007 drop: 0.000022 both: 0.000019\n",
      "Train Epoch: 1045 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000234 drop: 0.000001 both: 0.000007\n",
      "Train Epoch: 1045 [20000/25000 (80%)]\tLosses default: 0.000016 bn: 0.298218 drop: 0.000009 both: 0.000009\n",
      "Train Epoch: 1045 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000040 drop: 0.000007 both: 0.000686\n",
      "Test set:\n",
      "default: Loss: 1.1631\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.1245\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.1527\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0676\tAccuracy: 4365.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1046 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.001744 drop: 0.000004 both: 0.000155\n",
      "Train Epoch: 1046 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000003 drop: 0.000027 both: 0.002221\n",
      "Train Epoch: 1046 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000010 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 1046 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000035 drop: 0.000002 both: 0.000074\n",
      "Test set:\n",
      "default: Loss: 1.1748\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.1436\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.1574\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0804\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1047 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000009 drop: 0.000002 both: 0.000426\n",
      "Train Epoch: 1047 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000016 both: 0.000059\n",
      "Train Epoch: 1047 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000183 drop: 0.000029 both: 0.000012\n",
      "Train Epoch: 1047 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000021 drop: 0.000001 both: 0.000025\n",
      "Test set:\n",
      "default: Loss: 1.1858\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1425\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1601\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.1102\tAccuracy: 4367.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1048 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.000011 both: 0.000181\n",
      "Train Epoch: 1048 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000009 both: 0.000548\n",
      "Train Epoch: 1048 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.196910 both: 0.002264\n",
      "Train Epoch: 1048 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.009472 drop: 0.000272 both: 0.001734\n",
      "Test set:\n",
      "default: Loss: 1.1952\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.1263\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.1697\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0797\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1049 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000046 drop: 0.000152 both: 0.000105\n",
      "Train Epoch: 1049 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.001666 both: 0.000011\n",
      "Train Epoch: 1049 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000383 drop: 0.000045 both: 0.000033\n",
      "Train Epoch: 1049 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000042 drop: 0.000057 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.2057\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.1263\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.2042\tAccuracy: 4357.0/5000 (87%)\n",
      "both: Loss: 1.0848\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1050 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000004 drop: 0.000059 both: 0.000009\n",
      "Train Epoch: 1050 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000075 drop: 0.000005 both: 0.000014\n",
      "Train Epoch: 1050 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000043 both: 0.000086\n",
      "Train Epoch: 1050 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000015 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.2157\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.1044\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.2091\tAccuracy: 4347.0/5000 (87%)\n",
      "both: Loss: 1.0844\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1051 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000123 both: 0.000026\n",
      "Train Epoch: 1051 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000164 both: 0.000008\n",
      "Train Epoch: 1051 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000002 drop: 0.000007 both: 0.000003\n",
      "Train Epoch: 1051 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000083 drop: 0.000042 both: 0.000036\n",
      "Test set:\n",
      "default: Loss: 1.2255\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.1450\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.1823\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0878\tAccuracy: 4367.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1052 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000003 both: 0.000189\n",
      "Train Epoch: 1052 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000035 drop: 0.000006 both: 0.000006\n",
      "Train Epoch: 1052 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000003 both: 0.000005\n",
      "Train Epoch: 1052 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000002 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.2360\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.1042\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1806\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.0382\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1053 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000010 both: 0.000004\n",
      "Train Epoch: 1053 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000001 drop: 0.000016 both: 0.000033\n",
      "Train Epoch: 1053 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.000015 both: 0.000012\n",
      "Train Epoch: 1053 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000136 drop: 0.000003 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2437\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1477\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.1538\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0807\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1054 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000005 both: 0.009665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1054 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000439 drop: 0.000131 both: 0.000180\n",
      "Train Epoch: 1054 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000028 drop: 0.000006 both: 0.001224\n",
      "Train Epoch: 1054 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001622 drop: 0.000009 both: 0.000112\n",
      "Test set:\n",
      "default: Loss: 1.2534\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.0838\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.1696\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0739\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1055 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000083 drop: 0.000076 both: 0.000691\n",
      "Train Epoch: 1055 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000013 both: 0.000064\n",
      "Train Epoch: 1055 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000552 drop: 0.000010 both: 0.000011\n",
      "Train Epoch: 1055 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.149247 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2615\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0884\tAccuracy: 4442.0/5000 (89%)\n",
      "drop: Loss: 1.2005\tAccuracy: 4362.0/5000 (87%)\n",
      "both: Loss: 1.1153\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1056 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000020 both: 0.000776\n",
      "Train Epoch: 1056 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000045 both: 0.000400\n",
      "Train Epoch: 1056 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000169 drop: 0.000308 both: 0.000407\n",
      "Train Epoch: 1056 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000140 drop: 0.000014 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.2707\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0735\tAccuracy: 4442.0/5000 (89%)\n",
      "drop: Loss: 1.1872\tAccuracy: 4355.0/5000 (87%)\n",
      "both: Loss: 1.0994\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1057 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000032 both: 0.000593\n",
      "Train Epoch: 1057 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000101 both: 0.000291\n",
      "Train Epoch: 1057 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.002603 drop: 0.000175 both: 0.000107\n",
      "Train Epoch: 1057 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000320 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.2777\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0581\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.2565\tAccuracy: 4344.0/5000 (87%)\n",
      "both: Loss: 1.0697\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1058 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000037 drop: 0.000607 both: 0.000016\n",
      "Train Epoch: 1058 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000011 both: 0.000012\n",
      "Train Epoch: 1058 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000003 both: 0.000173\n",
      "Train Epoch: 1058 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000004 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.2853\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0847\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1935\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0932\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1059 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000162 drop: 0.000020 both: 0.000061\n",
      "Train Epoch: 1059 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000009 both: 0.000008\n",
      "Train Epoch: 1059 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000001 both: 0.000060\n",
      "Train Epoch: 1059 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000041\n",
      "Test set:\n",
      "default: Loss: 1.2920\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0752\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.1851\tAccuracy: 4372.0/5000 (87%)\n",
      "both: Loss: 1.0966\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1060 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000114 drop: 0.000007 both: 0.000252\n",
      "Train Epoch: 1060 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000015 both: 0.000136\n",
      "Train Epoch: 1060 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000096 both: 0.000282\n",
      "Train Epoch: 1060 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000634 drop: 0.000043 both: 0.002695\n",
      "Test set:\n",
      "default: Loss: 1.2998\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1010\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.2221\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0961\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1061 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000014 both: 0.041014\n",
      "Train Epoch: 1061 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000125 both: 0.000686\n",
      "Train Epoch: 1061 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000004 both: 0.000017\n",
      "Train Epoch: 1061 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000007 both: 0.000218\n",
      "Test set:\n",
      "default: Loss: 1.3066\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0769\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1836\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0708\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1062 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000331 drop: 0.000016 both: 0.000011\n",
      "Train Epoch: 1062 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000088 drop: 0.000014 both: 0.007058\n",
      "Train Epoch: 1062 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000003 both: 0.000027\n",
      "Train Epoch: 1062 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000003 both: 0.000023\n",
      "Test set:\n",
      "default: Loss: 1.3113\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0597\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2029\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0636\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1063 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000072 drop: 0.000031 both: 0.000013\n",
      "Train Epoch: 1063 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000179 drop: 0.000017 both: 0.004727\n",
      "Train Epoch: 1063 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000004 both: 0.000008\n",
      "Train Epoch: 1063 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000008 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.3170\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0788\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.1795\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.0920\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1064 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000002 both: 0.000438\n",
      "Train Epoch: 1064 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000182 drop: 0.000049 both: 0.000063\n",
      "Train Epoch: 1064 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000008 both: 0.000026\n",
      "Train Epoch: 1064 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000000 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.3231\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0908\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.2143\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.0617\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1065 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000007 both: 0.000008\n",
      "Train Epoch: 1065 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 1065 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000007 both: 0.000037\n",
      "Train Epoch: 1065 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.010032 drop: 0.000010 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.3283\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1056\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2117\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0444\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1066 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.006915 drop: 0.000003 both: 0.155423\n",
      "Train Epoch: 1066 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000291 drop: 0.000004 both: 0.000040\n",
      "Train Epoch: 1066 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000001 both: 0.000437\n",
      "Train Epoch: 1066 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000008 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.3329\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0832\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.1932\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0773\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1067 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000002 both: 0.000215\n",
      "Train Epoch: 1067 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.001818 both: 0.000010\n",
      "Train Epoch: 1067 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.082087 both: 0.000020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1067 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000035 drop: 0.001063 both: 0.000039\n",
      "Test set:\n",
      "default: Loss: 1.3364\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0834\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.1110\tAccuracy: 4362.0/5000 (87%)\n",
      "both: Loss: 1.0915\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1068 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000072 drop: 0.024032 both: 0.000096\n",
      "Train Epoch: 1068 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000222 both: 0.000014\n",
      "Train Epoch: 1068 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000003 both: 0.000004\n",
      "Train Epoch: 1068 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000296 drop: 0.000123 both: 0.000035\n",
      "Test set:\n",
      "default: Loss: 1.3399\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0844\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1238\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0928\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1069 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000775 both: 0.000016\n",
      "Train Epoch: 1069 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000110 both: 0.000004\n",
      "Train Epoch: 1069 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000098 drop: 0.000007 both: 0.000050\n",
      "Train Epoch: 1069 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000306 drop: 0.000027 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 1.3444\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1068\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.1261\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0788\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1070 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000265 drop: 0.000052 both: 0.000002\n",
      "Train Epoch: 1070 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000002 both: 0.000019\n",
      "Train Epoch: 1070 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000702 both: 0.000108\n",
      "Train Epoch: 1070 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000085 drop: 0.000183 both: 0.000042\n",
      "Test set:\n",
      "default: Loss: 1.3469\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.0603\tAccuracy: 4444.0/5000 (89%)\n",
      "drop: Loss: 1.1312\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0685\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1071 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000002 both: 0.022963\n",
      "Train Epoch: 1071 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000006 both: 0.000058\n",
      "Train Epoch: 1071 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000413 both: 0.000017\n",
      "Train Epoch: 1071 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000285 drop: 0.000208 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.3519\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.1042\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1586\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0917\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1072 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000380 drop: 0.000086 both: 0.000022\n",
      "Train Epoch: 1072 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000532 both: 0.000019\n",
      "Train Epoch: 1072 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000830 drop: 0.000033 both: 0.001263\n",
      "Train Epoch: 1072 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000191 both: 0.002251\n",
      "Test set:\n",
      "default: Loss: 1.3540\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.1216\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1510\tAccuracy: 4402.0/5000 (88%)\n",
      "both: Loss: 1.0971\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1073 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000008\n",
      "Train Epoch: 1073 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000123 drop: 0.000002 both: 0.000167\n",
      "Train Epoch: 1073 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000023 both: 0.000061\n",
      "Train Epoch: 1073 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.026967 drop: 0.000006 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.3590\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1044\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1431\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1002\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1074 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000206 drop: 0.000012 both: 0.000479\n",
      "Train Epoch: 1074 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000012 both: 0.000037\n",
      "Train Epoch: 1074 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000010 both: 0.000456\n",
      "Train Epoch: 1074 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000002 both: 0.000067\n",
      "Test set:\n",
      "default: Loss: 1.3589\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0922\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1466\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.1298\tAccuracy: 4366.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1075 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000070 drop: 0.000010 both: 0.000552\n",
      "Train Epoch: 1075 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000004 both: 0.000007\n",
      "Train Epoch: 1075 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000318 drop: 0.000001 both: 0.000330\n",
      "Train Epoch: 1075 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000014 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.3576\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1018\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1536\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1063\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1076 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000283 both: 0.000427\n",
      "Train Epoch: 1076 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000164 drop: 0.000002 both: 0.000008\n",
      "Train Epoch: 1076 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000083 drop: 0.000057 both: 0.000225\n",
      "Train Epoch: 1076 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000014 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.3569\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0963\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1606\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0923\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1077 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000070 drop: 0.000008 both: 0.000013\n",
      "Train Epoch: 1077 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000340 both: 0.010482\n",
      "Train Epoch: 1077 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000003 both: 0.000096\n",
      "Train Epoch: 1077 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000074 drop: 0.000002 both: 0.000210\n",
      "Test set:\n",
      "default: Loss: 1.3591\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1361\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.1555\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0876\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1078 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000006 both: 0.000127\n",
      "Train Epoch: 1078 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000042\n",
      "Train Epoch: 1078 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000003 both: 0.000010\n",
      "Train Epoch: 1078 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000007 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.3593\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0851\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1539\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0739\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1079 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000096 drop: 0.000021 both: 0.000010\n",
      "Train Epoch: 1079 [10000/25000 (40%)]\tLosses default: 0.001117 bn: 0.000001 drop: 0.000021 both: 0.000005\n",
      "Train Epoch: 1079 [20000/25000 (80%)]\tLosses default: 0.000158 bn: 0.000004 drop: 0.000002 both: 0.038369\n",
      "Train Epoch: 1079 [25000/25000 (100%)]\tLosses default: 0.058726 bn: 0.000004 drop: 0.000001 both: 0.000054\n",
      "Test set:\n",
      "default: Loss: 1.0643\tAccuracy: 4412.0/5000 (88%)\n",
      "bn: Loss: 1.0678\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1449\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.1034\tAccuracy: 4368.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1080 [0/25000 (0%)]\tLosses default: 0.000089 bn: 0.000045 drop: 0.000030 both: 0.000030\n",
      "Train Epoch: 1080 [10000/25000 (40%)]\tLosses default: 0.070212 bn: 0.000382 drop: 0.000003 both: 0.000018\n",
      "Train Epoch: 1080 [20000/25000 (80%)]\tLosses default: 0.001590 bn: 0.000008 drop: 0.000006 both: 0.000011\n",
      "Train Epoch: 1080 [25000/25000 (100%)]\tLosses default: 0.002129 bn: 0.000083 drop: 0.000002 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.0753\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1174\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.1649\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0739\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1081 [0/25000 (0%)]\tLosses default: 0.000135 bn: 0.000080 drop: 0.000001 both: 0.000113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1081 [10000/25000 (40%)]\tLosses default: 0.000177 bn: 0.000047 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 1081 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000042 drop: 0.000042 both: 0.000011\n",
      "Train Epoch: 1081 [25000/25000 (100%)]\tLosses default: 0.000448 bn: 0.000345 drop: 0.000006 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.1878\tAccuracy: 4401.0/5000 (88%)\n",
      "bn: Loss: 1.1436\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1800\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0822\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1082 [0/25000 (0%)]\tLosses default: 0.000206 bn: 0.000159 drop: 0.000001 both: 0.000838\n",
      "Train Epoch: 1082 [10000/25000 (40%)]\tLosses default: 0.001855 bn: 0.000146 drop: 0.000003 both: 0.002165\n",
      "Train Epoch: 1082 [20000/25000 (80%)]\tLosses default: 0.000057 bn: 0.000004 drop: 0.000002 both: 0.000007\n",
      "Train Epoch: 1082 [25000/25000 (100%)]\tLosses default: 0.000107 bn: 0.000026 drop: 0.000006 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.1414\tAccuracy: 4398.0/5000 (88%)\n",
      "bn: Loss: 1.1143\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.1828\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.1211\tAccuracy: 4370.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1083 [0/25000 (0%)]\tLosses default: 0.000018 bn: 0.000001 drop: 0.000000 both: 0.000004\n",
      "Train Epoch: 1083 [10000/25000 (40%)]\tLosses default: 0.000098 bn: 0.000162 drop: 0.000003 both: 0.000056\n",
      "Train Epoch: 1083 [20000/25000 (80%)]\tLosses default: 0.003057 bn: 0.000022 drop: 0.000001 both: 0.000047\n",
      "Train Epoch: 1083 [25000/25000 (100%)]\tLosses default: 0.000326 bn: 0.008507 drop: 0.000001 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.0518\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1406\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1909\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.1378\tAccuracy: 4366.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1084 [0/25000 (0%)]\tLosses default: 0.000013 bn: 0.000028 drop: 0.000002 both: 0.002770\n",
      "Train Epoch: 1084 [10000/25000 (40%)]\tLosses default: 0.000190 bn: 0.001529 drop: 0.000001 both: 0.000010\n",
      "Train Epoch: 1084 [20000/25000 (80%)]\tLosses default: 0.000029 bn: 0.000002 drop: 0.000057 both: 0.000014\n",
      "Train Epoch: 1084 [25000/25000 (100%)]\tLosses default: 0.000020 bn: 0.000001 drop: 0.000902 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.0818\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1003\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1921\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.1094\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1085 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000035 drop: 0.000196 both: 0.000026\n",
      "Train Epoch: 1085 [10000/25000 (40%)]\tLosses default: 0.000110 bn: 0.000004 drop: 0.000003 both: 0.000013\n",
      "Train Epoch: 1085 [20000/25000 (80%)]\tLosses default: 0.000098 bn: 0.000022 drop: 0.000001 both: 0.000014\n",
      "Train Epoch: 1085 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000053 drop: 0.001196 both: 0.000275\n",
      "Test set:\n",
      "default: Loss: 1.0910\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1056\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.1536\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0802\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1086 [0/25000 (0%)]\tLosses default: 0.000037 bn: 0.000040 drop: 0.000004 both: 0.000002\n",
      "Train Epoch: 1086 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000003 drop: 0.000012 both: 0.000003\n",
      "Train Epoch: 1086 [20000/25000 (80%)]\tLosses default: 0.000063 bn: 0.000008 drop: 0.000027 both: 0.004916\n",
      "Train Epoch: 1086 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000001 drop: 0.005469 both: 0.000050\n",
      "Test set:\n",
      "default: Loss: 1.1018\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0751\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.1340\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0814\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1087 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000017 drop: 0.000272 both: 0.000211\n",
      "Train Epoch: 1087 [10000/25000 (40%)]\tLosses default: 0.000027 bn: 0.000214 drop: 0.000013 both: 0.000139\n",
      "Train Epoch: 1087 [20000/25000 (80%)]\tLosses default: 0.000033 bn: 0.014558 drop: 0.000032 both: 0.000002\n",
      "Train Epoch: 1087 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000007 drop: 0.000006 both: 0.000161\n",
      "Test set:\n",
      "default: Loss: 1.1126\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1006\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.1621\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1005\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1088 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.000019 drop: 0.000008 both: 0.000007\n",
      "Train Epoch: 1088 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000009 both: 0.000016\n",
      "Train Epoch: 1088 [20000/25000 (80%)]\tLosses default: 0.000023 bn: 0.001722 drop: 0.000003 both: 0.000016\n",
      "Train Epoch: 1088 [25000/25000 (100%)]\tLosses default: 0.000054 bn: 0.000060 drop: 0.000007 both: 0.000487\n",
      "Test set:\n",
      "default: Loss: 1.1229\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1158\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.1634\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0804\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1089 [0/25000 (0%)]\tLosses default: 0.000017 bn: 0.084256 drop: 0.000013 both: 0.000301\n",
      "Train Epoch: 1089 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000004 drop: 0.000001 both: 0.000006\n",
      "Train Epoch: 1089 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000004 both: 0.000015\n",
      "Train Epoch: 1089 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000010 drop: 0.000016 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.1324\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1086\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1648\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0822\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1090 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000003 drop: 0.000340 both: 0.000008\n",
      "Train Epoch: 1090 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000400 drop: 0.000005 both: 0.000078\n",
      "Train Epoch: 1090 [20000/25000 (80%)]\tLosses default: 0.000021 bn: 0.000033 drop: 0.009832 both: 0.000011\n",
      "Train Epoch: 1090 [25000/25000 (100%)]\tLosses default: 0.000015 bn: 0.000226 drop: 0.000012 both: 0.002278\n",
      "Test set:\n",
      "default: Loss: 1.1422\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1205\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.1795\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.1196\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1091 [0/25000 (0%)]\tLosses default: 0.000008 bn: 0.000008 drop: 0.000001 both: 0.169665\n",
      "Train Epoch: 1091 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000065 both: 0.000058\n",
      "Train Epoch: 1091 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000000 drop: 0.000330 both: 0.000040\n",
      "Train Epoch: 1091 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.001555 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.1520\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1223\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1851\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0921\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1092 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.000036 drop: 0.067852 both: 0.000004\n",
      "Train Epoch: 1092 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000014 both: 0.000006\n",
      "Train Epoch: 1092 [20000/25000 (80%)]\tLosses default: 0.000012 bn: 0.000005 drop: 0.055205 both: 0.000013\n",
      "Train Epoch: 1092 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000002 drop: 0.000006 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.1628\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1655\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.1817\tAccuracy: 4357.0/5000 (87%)\n",
      "both: Loss: 1.1239\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1093 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000135 both: 0.000011\n",
      "Train Epoch: 1093 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.004120 drop: 0.000444 both: 0.000045\n",
      "Train Epoch: 1093 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000019 both: 0.000005\n",
      "Train Epoch: 1093 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000337 drop: 0.000007 both: 0.000163\n",
      "Test set:\n",
      "default: Loss: 1.1713\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1144\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1751\tAccuracy: 4357.0/5000 (87%)\n",
      "both: Loss: 1.1285\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1094 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000014 both: 0.000090\n",
      "Train Epoch: 1094 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000014 both: 0.000427\n",
      "Train Epoch: 1094 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000003 drop: 0.000044 both: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1094 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000049 drop: 0.000013 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.1814\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0908\tAccuracy: 4453.0/5000 (89%)\n",
      "drop: Loss: 1.1596\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1057\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1095 [0/25000 (0%)]\tLosses default: 0.000008 bn: 0.000051 drop: 0.000120 both: 0.000008\n",
      "Train Epoch: 1095 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000023 both: 0.000027\n",
      "Train Epoch: 1095 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000010 both: 0.000015\n",
      "Train Epoch: 1095 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000005 drop: 0.000050 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.1903\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.0907\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.1835\tAccuracy: 4353.0/5000 (87%)\n",
      "both: Loss: 1.1281\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1096 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000022 drop: 0.003244 both: 0.000041\n",
      "Train Epoch: 1096 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000001 drop: 0.000038 both: 0.000111\n",
      "Train Epoch: 1096 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000135 drop: 0.000020 both: 0.000017\n",
      "Train Epoch: 1096 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.000024 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.2001\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0859\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.1624\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.1019\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1097 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000005 both: 0.000065\n",
      "Train Epoch: 1097 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000009 drop: 0.000006 both: 0.000023\n",
      "Train Epoch: 1097 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000053 drop: 0.000321 both: 0.000061\n",
      "Train Epoch: 1097 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.002826 drop: 0.000019 both: 0.000024\n",
      "Test set:\n",
      "default: Loss: 1.2104\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1288\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1523\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0872\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1098 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000004 both: 0.000028\n",
      "Train Epoch: 1098 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000356 drop: 0.000089 both: 0.034130\n",
      "Train Epoch: 1098 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000026 drop: 0.000003 both: 0.000046\n",
      "Train Epoch: 1098 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.014539 drop: 0.000085 both: 0.000113\n",
      "Test set:\n",
      "default: Loss: 1.2186\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1787\tAccuracy: 4401.0/5000 (88%)\n",
      "drop: Loss: 1.1811\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.1021\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1099 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000004 drop: 0.000025 both: 0.000008\n",
      "Train Epoch: 1099 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000281 drop: 0.000032 both: 0.000013\n",
      "Train Epoch: 1099 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000009 both: 0.000180\n",
      "Train Epoch: 1099 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000012 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2272\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0859\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1762\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0695\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1100 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000624 drop: 0.000001 both: 0.000139\n",
      "Train Epoch: 1100 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000139 drop: 0.000004 both: 0.000040\n",
      "Train Epoch: 1100 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000010 both: 0.000009\n",
      "Train Epoch: 1100 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000303 drop: 0.000108 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.2357\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0925\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.1977\tAccuracy: 4367.0/5000 (87%)\n",
      "both: Loss: 1.0797\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1101 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000191 both: 0.000011\n",
      "Train Epoch: 1101 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.001187 drop: 0.000006 both: 0.003569\n",
      "Train Epoch: 1101 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.000002 both: 0.000004\n",
      "Train Epoch: 1101 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000111 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.2434\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0701\tAccuracy: 4442.0/5000 (89%)\n",
      "drop: Loss: 1.1799\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.1324\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1102 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000001 both: 0.000008\n",
      "Train Epoch: 1102 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000004 both: 0.001026\n",
      "Train Epoch: 1102 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.022268 both: 0.000041\n",
      "Train Epoch: 1102 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000008 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2517\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0879\tAccuracy: 4447.0/5000 (89%)\n",
      "drop: Loss: 1.1706\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.1092\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1103 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000153 both: 0.000017\n",
      "Train Epoch: 1103 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000021 both: 0.000007\n",
      "Train Epoch: 1103 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000072 drop: 0.000145 both: 0.000038\n",
      "Train Epoch: 1103 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000058 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.2588\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.1048\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.2041\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0908\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1104 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001060 drop: 0.000016 both: 0.000012\n",
      "Train Epoch: 1104 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000054 drop: 0.000037 both: 0.000003\n",
      "Train Epoch: 1104 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000031 both: 0.000007\n",
      "Train Epoch: 1104 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000006 both: 0.000077\n",
      "Test set:\n",
      "default: Loss: 1.2654\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1097\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.1824\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.1257\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1105 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000040 both: 0.000216\n",
      "Train Epoch: 1105 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000005 both: 0.000007\n",
      "Train Epoch: 1105 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000011 both: 0.000010\n",
      "Train Epoch: 1105 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000007 both: 0.000620\n",
      "Test set:\n",
      "default: Loss: 1.2715\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1102\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.1720\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0729\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1106 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000124 drop: 0.000009 both: 0.000017\n",
      "Train Epoch: 1106 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000008 both: 0.000056\n",
      "Train Epoch: 1106 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000014 both: 0.000648\n",
      "Train Epoch: 1106 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001228 drop: 0.000006 both: 0.044856\n",
      "Test set:\n",
      "default: Loss: 1.2778\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.1578\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.1587\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0888\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1107 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000011 both: 0.000062\n",
      "Train Epoch: 1107 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000069 drop: 0.000507 both: 0.000671\n",
      "Train Epoch: 1107 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000004 both: 0.000015\n",
      "Train Epoch: 1107 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000001 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.2855\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1206\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1960\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0966\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1108 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000013 both: 0.000013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1108 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000177 drop: 0.000040 both: 0.000016\n",
      "Train Epoch: 1108 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000002 both: 0.000011\n",
      "Train Epoch: 1108 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000060 both: 0.000210\n",
      "Test set:\n",
      "default: Loss: 1.2908\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1062\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1840\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.1111\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1109 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000846 drop: 0.000008 both: 0.000035\n",
      "Train Epoch: 1109 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000052 both: 0.000014\n",
      "Train Epoch: 1109 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000016 both: 0.041396\n",
      "Train Epoch: 1109 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000023 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.2951\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1221\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.1741\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0846\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1110 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000050 both: 0.000017\n",
      "Train Epoch: 1110 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000397 both: 0.000003\n",
      "Train Epoch: 1110 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000278 both: 0.006405\n",
      "Train Epoch: 1110 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000002 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.3008\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1043\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.2002\tAccuracy: 4362.0/5000 (87%)\n",
      "both: Loss: 1.1319\tAccuracy: 4364.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1111 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000007 both: 0.000092\n",
      "Train Epoch: 1111 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000107 drop: 0.000012 both: 0.000001\n",
      "Train Epoch: 1111 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000005 both: 0.000005\n",
      "Train Epoch: 1111 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000032 drop: 0.000005 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.3068\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1477\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1734\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.1256\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1112 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001155 drop: 0.074845 both: 0.000050\n",
      "Train Epoch: 1112 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000074 both: 0.000008\n",
      "Train Epoch: 1112 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000424 both: 0.000080\n",
      "Train Epoch: 1112 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000118 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.3111\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0729\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.1878\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0998\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1113 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000004 both: 0.000018\n",
      "Train Epoch: 1113 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000131 drop: 0.000035 both: 0.000007\n",
      "Train Epoch: 1113 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000070 drop: 0.000003 both: 0.000010\n",
      "Train Epoch: 1113 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000017 both: 0.000219\n",
      "Test set:\n",
      "default: Loss: 1.3163\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0840\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.1810\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0889\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1114 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000786 drop: 0.000055 both: 0.000155\n",
      "Train Epoch: 1114 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000001 both: 0.000071\n",
      "Train Epoch: 1114 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000675 drop: 0.000006 both: 0.000031\n",
      "Train Epoch: 1114 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000008 both: 0.000933\n",
      "Test set:\n",
      "default: Loss: 1.3193\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1128\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1625\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0932\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1115 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000008 both: 0.008206\n",
      "Train Epoch: 1115 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000004 both: 0.000002\n",
      "Train Epoch: 1115 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000029 both: 0.000007\n",
      "Train Epoch: 1115 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000000 both: 0.005490\n",
      "Test set:\n",
      "default: Loss: 1.3246\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0909\tAccuracy: 4444.0/5000 (89%)\n",
      "drop: Loss: 1.1759\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0826\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1116 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000069 drop: 0.000001 both: 0.000021\n",
      "Train Epoch: 1116 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000006 both: 0.000082\n",
      "Train Epoch: 1116 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000127 both: 0.000045\n",
      "Train Epoch: 1116 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000077 drop: 0.003946 both: 0.000859\n",
      "Test set:\n",
      "default: Loss: 1.3287\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.1071\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.2245\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0587\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1117 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.003336 drop: 0.142952 both: 0.000085\n",
      "Train Epoch: 1117 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000244 drop: 0.065530 both: 0.020721\n",
      "Train Epoch: 1117 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000015 both: 0.000251\n",
      "Train Epoch: 1117 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000007 both: 0.001406\n",
      "Test set:\n",
      "default: Loss: 1.3307\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1381\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1608\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0596\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1118 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000178 drop: 0.000009 both: 0.000155\n",
      "Train Epoch: 1118 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000855 drop: 0.000401 both: 0.000015\n",
      "Train Epoch: 1118 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.031250 drop: 0.000004 both: 0.000038\n",
      "Train Epoch: 1118 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000038 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.3313\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.1059\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 1.1624\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.0794\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1119 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000019 both: 0.000005\n",
      "Train Epoch: 1119 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000038 drop: 0.000022 both: 0.000003\n",
      "Train Epoch: 1119 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000365 both: 0.000028\n",
      "Train Epoch: 1119 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000030 both: 0.000050\n",
      "Test set:\n",
      "default: Loss: 1.3373\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.0789\tAccuracy: 4456.0/5000 (89%)\n",
      "drop: Loss: 1.1500\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0652\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1120 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000014 both: 0.000008\n",
      "Train Epoch: 1120 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001435 drop: 0.000021 both: 0.029854\n",
      "Train Epoch: 1120 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000408 drop: 0.000129 both: 0.000013\n",
      "Train Epoch: 1120 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000006 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.3379\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.1084\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1513\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.1035\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1121 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000005 both: 0.000924\n",
      "Train Epoch: 1121 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000009 both: 0.000113\n",
      "Train Epoch: 1121 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000005 both: 0.000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1121 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000007 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3368\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.1029\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1588\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0724\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1122 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000005 both: 0.000026\n",
      "Train Epoch: 1122 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 1122 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000015 both: 0.000029\n",
      "Train Epoch: 1122 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000372 drop: 0.000022 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.3379\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.1279\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1607\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.1214\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1123 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000002 both: 0.000026\n",
      "Train Epoch: 1123 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000056 drop: 0.000010 both: 0.000018\n",
      "Train Epoch: 1123 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 1123 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000111 drop: 0.000009 both: 0.000059\n",
      "Test set:\n",
      "default: Loss: 1.3353\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.1445\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1341\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.1236\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1124 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000038 both: 0.019101\n",
      "Train Epoch: 1124 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000022 both: 0.000037\n",
      "Train Epoch: 1124 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.024952 drop: 0.000515 both: 0.005089\n",
      "Train Epoch: 1124 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000313 drop: 0.061867 both: 0.000641\n",
      "Test set:\n",
      "default: Loss: 1.3418\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.1340\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2420\tAccuracy: 4325.0/5000 (86%)\n",
      "both: Loss: 1.0520\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1125 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.188471 both: 0.000023\n",
      "Train Epoch: 1125 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.011068 both: 0.000042\n",
      "Train Epoch: 1125 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000013 both: 0.000021\n",
      "Train Epoch: 1125 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000064 both: 0.000062\n",
      "Test set:\n",
      "default: Loss: 1.3420\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.1122\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 1.1485\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0556\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1126 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.001010 both: 0.000080\n",
      "Train Epoch: 1126 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000040 drop: 0.000004 both: 0.000036\n",
      "Train Epoch: 1126 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000003 both: 0.000010\n",
      "Train Epoch: 1126 [25000/25000 (100%)]\tLosses default: 0.166117 bn: 0.000166 drop: 0.000001 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.4824\tAccuracy: 4295.0/5000 (86%)\n",
      "bn: Loss: 1.1075\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1490\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0764\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1127 [0/25000 (0%)]\tLosses default: 0.425865 bn: 0.000041 drop: 0.000005 both: 0.000540\n",
      "Train Epoch: 1127 [10000/25000 (40%)]\tLosses default: 0.002717 bn: 0.000002 drop: 0.000330 both: 0.000902\n",
      "Train Epoch: 1127 [20000/25000 (80%)]\tLosses default: 0.000222 bn: 0.000005 drop: 0.000007 both: 0.000085\n",
      "Train Epoch: 1127 [25000/25000 (100%)]\tLosses default: 0.015124 bn: 0.000002 drop: 0.000670 both: 0.000068\n",
      "Test set:\n",
      "default: Loss: 0.9974\tAccuracy: 4410.0/5000 (88%)\n",
      "bn: Loss: 1.1083\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1655\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.1110\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1128 [0/25000 (0%)]\tLosses default: 0.000439 bn: 0.000005 drop: 0.000048 both: 0.000019\n",
      "Train Epoch: 1128 [10000/25000 (40%)]\tLosses default: 0.000159 bn: 0.000156 drop: 0.000175 both: 0.000177\n",
      "Train Epoch: 1128 [20000/25000 (80%)]\tLosses default: 0.000168 bn: 0.000021 drop: 0.000018 both: 0.000006\n",
      "Train Epoch: 1128 [25000/25000 (100%)]\tLosses default: 0.000388 bn: 0.000180 drop: 0.000005 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.0241\tAccuracy: 4408.0/5000 (88%)\n",
      "bn: Loss: 1.1056\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.1637\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.1258\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1129 [0/25000 (0%)]\tLosses default: 0.000034 bn: 0.000020 drop: 0.000007 both: 0.000086\n",
      "Train Epoch: 1129 [10000/25000 (40%)]\tLosses default: 0.000238 bn: 0.000001 drop: 0.000008 both: 0.000006\n",
      "Train Epoch: 1129 [20000/25000 (80%)]\tLosses default: 0.000242 bn: 0.000037 drop: 0.000053 both: 0.000164\n",
      "Train Epoch: 1129 [25000/25000 (100%)]\tLosses default: 0.000018 bn: 0.000002 drop: 0.000022 both: 0.000081\n",
      "Test set:\n",
      "default: Loss: 1.0446\tAccuracy: 4409.0/5000 (88%)\n",
      "bn: Loss: 1.1267\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 1.1606\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.1306\tAccuracy: 4369.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1130 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000007 drop: 0.000004 both: 0.000103\n",
      "Train Epoch: 1130 [10000/25000 (40%)]\tLosses default: 0.000104 bn: 0.000053 drop: 0.000004 both: 0.000182\n",
      "Train Epoch: 1130 [20000/25000 (80%)]\tLosses default: 0.000016 bn: 0.000005 drop: 0.000070 both: 0.000016\n",
      "Train Epoch: 1130 [25000/25000 (100%)]\tLosses default: 0.000022 bn: 0.000016 drop: 0.000006 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.0613\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.1308\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.1596\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0845\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1131 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000001 drop: 0.000012 both: 0.002242\n",
      "Train Epoch: 1131 [10000/25000 (40%)]\tLosses default: 0.000056 bn: 0.000042 drop: 0.000036 both: 0.015635\n",
      "Train Epoch: 1131 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000196 drop: 0.000023 both: 0.000015\n",
      "Train Epoch: 1131 [25000/25000 (100%)]\tLosses default: 0.000045 bn: 0.000157 drop: 0.000002 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.0725\tAccuracy: 4413.0/5000 (88%)\n",
      "bn: Loss: 1.1083\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1838\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.1097\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1132 [0/25000 (0%)]\tLosses default: 0.000060 bn: 0.000224 drop: 0.000044 both: 0.000206\n",
      "Train Epoch: 1132 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000010 drop: 0.000003 both: 0.000017\n",
      "Train Epoch: 1132 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000007 drop: 0.000029 both: 0.000155\n",
      "Train Epoch: 1132 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000109 drop: 0.000028 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.0866\tAccuracy: 4414.0/5000 (88%)\n",
      "bn: Loss: 1.1053\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1755\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.1117\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1133 [0/25000 (0%)]\tLosses default: 0.000060 bn: 0.000267 drop: 0.000032 both: 0.000794\n",
      "Train Epoch: 1133 [10000/25000 (40%)]\tLosses default: 0.000035 bn: 0.000009 drop: 0.000031 both: 0.000007\n",
      "Train Epoch: 1133 [20000/25000 (80%)]\tLosses default: 0.000106 bn: 0.000008 drop: 0.000009 both: 0.000037\n",
      "Train Epoch: 1133 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000037 drop: 0.000007 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.0973\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.1026\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.1527\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.1072\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1134 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.019772 drop: 0.000036 both: 0.000008\n",
      "Train Epoch: 1134 [10000/25000 (40%)]\tLosses default: 0.000026 bn: 0.000335 drop: 0.000002 both: 0.000020\n",
      "Train Epoch: 1134 [20000/25000 (80%)]\tLosses default: 0.000069 bn: 0.000001 drop: 0.000007 both: 0.003788\n",
      "Train Epoch: 1134 [25000/25000 (100%)]\tLosses default: 0.000028 bn: 0.000003 drop: 0.000007 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.1100\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0823\tAccuracy: 4453.0/5000 (89%)\n",
      "drop: Loss: 1.1421\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.1205\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1135 [0/25000 (0%)]\tLosses default: 0.000015 bn: 0.000001 drop: 0.000026 both: 0.000008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1135 [10000/25000 (40%)]\tLosses default: 0.000013 bn: 0.000005 drop: 0.000002 both: 0.000398\n",
      "Train Epoch: 1135 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000001 drop: 0.001073 both: 0.000091\n",
      "Train Epoch: 1135 [25000/25000 (100%)]\tLosses default: 0.000055 bn: 0.000004 drop: 0.014158 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.1227\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.1171\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.2248\tAccuracy: 4348.0/5000 (87%)\n",
      "both: Loss: 1.0826\tAccuracy: 4411.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1136 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000118 drop: 0.000101 both: 0.000034\n",
      "Train Epoch: 1136 [10000/25000 (40%)]\tLosses default: 0.000017 bn: 0.000633 drop: 0.000277 both: 0.000100\n",
      "Train Epoch: 1136 [20000/25000 (80%)]\tLosses default: 0.000014 bn: 0.000998 drop: 0.000213 both: 0.000039\n",
      "Train Epoch: 1136 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000002 drop: 0.000009 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.1332\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.1129\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1192\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.1041\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1137 [0/25000 (0%)]\tLosses default: 0.000012 bn: 0.000021 drop: 0.001586 both: 0.001189\n",
      "Train Epoch: 1137 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.000008 drop: 0.000257 both: 0.000050\n",
      "Train Epoch: 1137 [20000/25000 (80%)]\tLosses default: 0.000036 bn: 0.000015 drop: 0.000089 both: 0.000103\n",
      "Train Epoch: 1137 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000070 drop: 0.000100 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.1440\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.1223\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.1191\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0921\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1138 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000015 drop: 0.000026 both: 0.000009\n",
      "Train Epoch: 1138 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000007 drop: 0.000003 both: 0.000007\n",
      "Train Epoch: 1138 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000206 both: 0.000006\n",
      "Train Epoch: 1138 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000043 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.1567\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.1310\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.1714\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.1026\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1139 [0/25000 (0%)]\tLosses default: 0.000013 bn: 0.000003 drop: 0.000016 both: 0.000002\n",
      "Train Epoch: 1139 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000026 both: 0.000014\n",
      "Train Epoch: 1139 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000184 drop: 0.000178 both: 0.000062\n",
      "Train Epoch: 1139 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000018 drop: 0.003468 both: 0.000073\n",
      "Test set:\n",
      "default: Loss: 1.1676\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.1073\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1713\tAccuracy: 4355.0/5000 (87%)\n",
      "both: Loss: 1.0923\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1140 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000009 drop: 0.001242 both: 0.000008\n",
      "Train Epoch: 1140 [10000/25000 (40%)]\tLosses default: 0.000012 bn: 0.000000 drop: 0.000037 both: 0.000064\n",
      "Train Epoch: 1140 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000023 both: 0.000033\n",
      "Train Epoch: 1140 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000147 drop: 0.004037 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.1781\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1166\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.1691\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0907\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1141 [0/25000 (0%)]\tLosses default: 0.000012 bn: 0.000008 drop: 0.000054 both: 0.000035\n",
      "Train Epoch: 1141 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000610 drop: 0.000069 both: 0.000046\n",
      "Train Epoch: 1141 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000046 drop: 0.000046 both: 0.000025\n",
      "Train Epoch: 1141 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000001 drop: 0.000055 both: 0.000046\n",
      "Test set:\n",
      "default: Loss: 1.1879\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0893\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1852\tAccuracy: 4353.0/5000 (87%)\n",
      "both: Loss: 1.0705\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1142 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000023 drop: 0.002640 both: 0.000005\n",
      "Train Epoch: 1142 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000706 drop: 0.000012 both: 0.000019\n",
      "Train Epoch: 1142 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000276 drop: 0.000039 both: 0.000905\n",
      "Train Epoch: 1142 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000009 drop: 0.000066 both: 0.000025\n",
      "Test set:\n",
      "default: Loss: 1.1986\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.0860\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1616\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.1221\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1143 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000586 both: 0.000003\n",
      "Train Epoch: 1143 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000014 both: 0.000012\n",
      "Train Epoch: 1143 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000022 drop: 0.000026 both: 0.000125\n",
      "Train Epoch: 1143 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000176 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.2082\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.1165\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.1659\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0875\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1144 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000007 both: 0.000043\n",
      "Train Epoch: 1144 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.002369 drop: 0.000095 both: 0.000014\n",
      "Train Epoch: 1144 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000591 drop: 0.000003 both: 0.000182\n",
      "Train Epoch: 1144 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000061 drop: 0.002303 both: 0.000050\n",
      "Test set:\n",
      "default: Loss: 1.2198\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.1464\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1064\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0729\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1145 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.004671 both: 0.000316\n",
      "Train Epoch: 1145 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000025 both: 0.000018\n",
      "Train Epoch: 1145 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000095 both: 0.000172\n",
      "Train Epoch: 1145 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000209 drop: 0.000753 both: 0.000121\n",
      "Test set:\n",
      "default: Loss: 1.2301\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.0921\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.0954\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0745\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1146 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000631 drop: 0.000010 both: 0.000023\n",
      "Train Epoch: 1146 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000052 both: 0.002923\n",
      "Train Epoch: 1146 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000012 both: 0.005395\n",
      "Train Epoch: 1146 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.006101 drop: 0.000002 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.2379\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.1172\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1225\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0522\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1147 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000040 both: 0.000051\n",
      "Train Epoch: 1147 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000004 both: 0.000040\n",
      "Train Epoch: 1147 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000048 drop: 0.000021 both: 0.000044\n",
      "Train Epoch: 1147 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000003 both: 0.000414\n",
      "Test set:\n",
      "default: Loss: 1.2453\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1103\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1341\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0728\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1148 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000006 both: 0.000046\n",
      "Train Epoch: 1148 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000028 drop: 0.000017 both: 0.000006\n",
      "Train Epoch: 1148 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000019 both: 0.000045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1148 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000014 both: 0.000038\n",
      "Test set:\n",
      "default: Loss: 1.2539\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.1236\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.1463\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0844\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1149 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000024 both: 0.000005\n",
      "Train Epoch: 1149 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000009 both: 0.000016\n",
      "Train Epoch: 1149 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000022 both: 0.000008\n",
      "Train Epoch: 1149 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000048 drop: 0.000002 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.2634\tAccuracy: 4414.0/5000 (88%)\n",
      "bn: Loss: 1.1455\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1458\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0789\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1150 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000008 both: 0.000364\n",
      "Train Epoch: 1150 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000433 drop: 0.000014 both: 0.000032\n",
      "Train Epoch: 1150 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000992 drop: 0.000011 both: 0.000010\n",
      "Train Epoch: 1150 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000376 drop: 0.000045 both: 0.000464\n",
      "Test set:\n",
      "default: Loss: 1.2702\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.1029\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.1319\tAccuracy: 4410.0/5000 (88%)\n",
      "both: Loss: 1.0812\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1151 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000088 drop: 0.000017 both: 0.000112\n",
      "Train Epoch: 1151 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000022 both: 0.000671\n",
      "Train Epoch: 1151 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000005 both: 0.000020\n",
      "Train Epoch: 1151 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001683 drop: 0.000010 both: 0.000033\n",
      "Test set:\n",
      "default: Loss: 1.2801\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.1641\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.1434\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0595\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1152 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001203 drop: 0.000006 both: 0.000005\n",
      "Train Epoch: 1152 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000004 both: 0.000035\n",
      "Train Epoch: 1152 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000873 drop: 0.000008 both: 0.000013\n",
      "Train Epoch: 1152 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000031\n",
      "Test set:\n",
      "default: Loss: 1.2839\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.1475\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.1489\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0803\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1153 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000018 both: 0.000019\n",
      "Train Epoch: 1153 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000025 both: 0.000607\n",
      "Train Epoch: 1153 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000015\n",
      "Train Epoch: 1153 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000005 both: 0.000100\n",
      "Test set:\n",
      "default: Loss: 1.2910\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.1109\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 1.1535\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0773\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1154 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000016 both: 0.000310\n",
      "Train Epoch: 1154 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000002 both: 0.000077\n",
      "Train Epoch: 1154 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000385\n",
      "Train Epoch: 1154 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000002 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.2974\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0984\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1745\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0674\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1155 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000010 both: 0.000006\n",
      "Train Epoch: 1155 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001155 drop: 0.000011 both: 0.000014\n",
      "Train Epoch: 1155 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000006 both: 0.000006\n",
      "Train Epoch: 1155 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.005116 drop: 0.000003 both: 0.000103\n",
      "Test set:\n",
      "default: Loss: 1.3032\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.1244\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1712\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0912\tAccuracy: 4368.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1156 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000038\n",
      "Train Epoch: 1156 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000309 drop: 0.000001 both: 0.000088\n",
      "Train Epoch: 1156 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000005\n",
      "Train Epoch: 1156 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000003 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.3057\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1032\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.1715\tAccuracy: 4408.0/5000 (88%)\n",
      "both: Loss: 1.0877\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1157 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000020 both: 0.000129\n",
      "Train Epoch: 1157 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000007\n",
      "Train Epoch: 1157 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000004 both: 0.001172\n",
      "Train Epoch: 1157 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000413\n",
      "Test set:\n",
      "default: Loss: 1.3146\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0847\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1959\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0705\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1158 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000002 both: 0.002795\n",
      "Train Epoch: 1158 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000004 both: 0.000095\n",
      "Train Epoch: 1158 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000087 drop: 0.000000 both: 0.000002\n",
      "Train Epoch: 1158 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000272 drop: 0.000004 both: 0.000204\n",
      "Test set:\n",
      "default: Loss: 1.3223\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1324\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.1877\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0659\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1159 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.012726\n",
      "Train Epoch: 1159 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000003 both: 0.000034\n",
      "Train Epoch: 1159 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000094 drop: 0.000005 both: 0.000602\n",
      "Train Epoch: 1159 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000214 drop: 0.000005 both: 0.000048\n",
      "Test set:\n",
      "default: Loss: 1.3239\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1660\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.1842\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0941\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1160 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000007 both: 0.000007\n",
      "Train Epoch: 1160 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000055 drop: 0.000332 both: 0.000073\n",
      "Train Epoch: 1160 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000111 drop: 0.007582 both: 0.000026\n",
      "Train Epoch: 1160 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.074390 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.3287\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.1389\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.1657\tAccuracy: 4361.0/5000 (87%)\n",
      "both: Loss: 1.0904\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1161 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000088 both: 0.044555\n",
      "Train Epoch: 1161 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000051 both: 0.000005\n",
      "Train Epoch: 1161 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000518 both: 0.000088\n",
      "Train Epoch: 1161 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000065 drop: 0.000058 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3318\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1190\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1325\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0944\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1162 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000144 both: 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1162 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000044 drop: 0.000020 both: 0.000023\n",
      "Train Epoch: 1162 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000067 both: 0.000024\n",
      "Train Epoch: 1162 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.003704 drop: 0.000014 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.3366\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.1186\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1408\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.1002\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1163 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000012 both: 0.000046\n",
      "Train Epoch: 1163 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000002 both: 0.000014\n",
      "Train Epoch: 1163 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000109 drop: 0.000008 both: 0.031783\n",
      "Train Epoch: 1163 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000003 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.3363\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1479\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1383\tAccuracy: 4366.0/5000 (87%)\n",
      "both: Loss: 1.1014\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1164 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000009 both: 0.000017\n",
      "Train Epoch: 1164 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000004 both: 0.000003\n",
      "Train Epoch: 1164 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000005 both: 0.000054\n",
      "Train Epoch: 1164 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000390 drop: 0.000007 both: 0.000247\n",
      "Test set:\n",
      "default: Loss: 1.3403\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1500\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1326\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0859\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1165 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000021 both: 0.000036\n",
      "Train Epoch: 1165 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000016 both: 0.004383\n",
      "Train Epoch: 1165 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000002 both: 0.000013\n",
      "Train Epoch: 1165 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000011 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3441\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1637\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.1244\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0561\tAccuracy: 4417.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1166 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000003 both: 0.000320\n",
      "Train Epoch: 1166 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000145 drop: 0.000026 both: 0.000045\n",
      "Train Epoch: 1166 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000350 drop: 0.000013 both: 0.000167\n",
      "Train Epoch: 1166 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000071 drop: 0.000010 both: 0.000048\n",
      "Test set:\n",
      "default: Loss: 1.3440\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.1387\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.1466\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0838\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1167 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000319\n",
      "Train Epoch: 1167 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000009 both: 0.000018\n",
      "Train Epoch: 1167 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000003 both: 0.000009\n",
      "Train Epoch: 1167 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000015 both: 0.000030\n",
      "Test set:\n",
      "default: Loss: 1.3506\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1303\tAccuracy: 4448.0/5000 (89%)\n",
      "drop: Loss: 1.1472\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0723\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1168 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000050 both: 0.000149\n",
      "Train Epoch: 1168 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000005 both: 0.000012\n",
      "Train Epoch: 1168 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000004 both: 0.000772\n",
      "Train Epoch: 1168 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000256 drop: 0.000006 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.3465\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1441\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1741\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0730\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1169 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000026 both: 0.001033\n",
      "Train Epoch: 1169 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001832 drop: 0.000037 both: 0.000023\n",
      "Train Epoch: 1169 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000003 both: 0.000011\n",
      "Train Epoch: 1169 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000055 both: 0.000329\n",
      "Test set:\n",
      "default: Loss: 1.3528\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.1443\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1620\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0900\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1170 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000064 drop: 0.000003 both: 0.000015\n",
      "Train Epoch: 1170 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000004 both: 0.000044\n",
      "Train Epoch: 1170 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000008 both: 0.000010\n",
      "Train Epoch: 1170 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000006 both: 0.000097\n",
      "Test set:\n",
      "default: Loss: 1.3491\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.1298\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.1513\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0910\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1171 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000084 both: 0.000029\n",
      "Train Epoch: 1171 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000003 both: 0.000005\n",
      "Train Epoch: 1171 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000005 both: 0.000120\n",
      "Train Epoch: 1171 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000554 drop: 0.000018 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3458\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1510\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.1557\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0778\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1172 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000083 drop: 0.000002 both: 0.000009\n",
      "Train Epoch: 1172 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000117 both: 0.000039\n",
      "Train Epoch: 1172 [20000/25000 (80%)]\tLosses default: 0.157642 bn: 0.008033 drop: 0.118856 both: 0.000008\n",
      "Train Epoch: 1172 [25000/25000 (100%)]\tLosses default: 0.011131 bn: 0.000013 drop: 0.000047 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.1483\tAccuracy: 4400.0/5000 (88%)\n",
      "bn: Loss: 1.1305\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1318\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0668\tAccuracy: 4414.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1173 [0/25000 (0%)]\tLosses default: 0.000162 bn: 0.000008 drop: 0.000117 both: 0.000028\n",
      "Train Epoch: 1173 [10000/25000 (40%)]\tLosses default: 0.000021 bn: 0.000164 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 1173 [20000/25000 (80%)]\tLosses default: 0.000447 bn: 0.000001 drop: 0.000079 both: 0.000018\n",
      "Train Epoch: 1173 [25000/25000 (100%)]\tLosses default: 0.000089 bn: 0.000114 drop: 0.000025 both: 0.000387\n",
      "Test set:\n",
      "default: Loss: 1.0992\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1459\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.1334\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0998\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1174 [0/25000 (0%)]\tLosses default: 0.000105 bn: 0.000004 drop: 0.000144 both: 0.000612\n",
      "Train Epoch: 1174 [10000/25000 (40%)]\tLosses default: 0.000031 bn: 0.000009 drop: 0.000006 both: 0.000071\n",
      "Train Epoch: 1174 [20000/25000 (80%)]\tLosses default: 0.000210 bn: 0.000003 drop: 0.000003 both: 0.000004\n",
      "Train Epoch: 1174 [25000/25000 (100%)]\tLosses default: 0.000139 bn: 0.000006 drop: 0.000005 both: 0.000057\n",
      "Test set:\n",
      "default: Loss: 1.0845\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1298\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1029\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.1167\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1175 [0/25000 (0%)]\tLosses default: 0.000051 bn: 0.000010 drop: 0.000016 both: 0.000004\n",
      "Train Epoch: 1175 [10000/25000 (40%)]\tLosses default: 0.000032 bn: 0.000018 drop: 0.000053 both: 0.000247\n",
      "Train Epoch: 1175 [20000/25000 (80%)]\tLosses default: 0.000013 bn: 0.000009 drop: 0.000027 both: 0.000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1175 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000029 drop: 0.000057 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.1058\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1149\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.1311\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0626\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1176 [0/25000 (0%)]\tLosses default: 0.000099 bn: 0.000010 drop: 0.000012 both: 0.000005\n",
      "Train Epoch: 1176 [10000/25000 (40%)]\tLosses default: 0.000085 bn: 0.000002 drop: 0.000049 both: 0.000012\n",
      "Train Epoch: 1176 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000004 drop: 0.000009 both: 0.000040\n",
      "Train Epoch: 1176 [25000/25000 (100%)]\tLosses default: 0.000015 bn: 0.000000 drop: 0.000012 both: 0.000612\n",
      "Test set:\n",
      "default: Loss: 1.1099\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.1076\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1330\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0936\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1177 [0/25000 (0%)]\tLosses default: 0.000010 bn: 0.000002 drop: 0.000006 both: 0.000009\n",
      "Train Epoch: 1177 [10000/25000 (40%)]\tLosses default: 0.000032 bn: 0.000002 drop: 0.000110 both: 0.000025\n",
      "Train Epoch: 1177 [20000/25000 (80%)]\tLosses default: 0.000086 bn: 0.000004 drop: 0.000044 both: 0.000016\n",
      "Train Epoch: 1177 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000011 drop: 0.000002 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.1126\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1225\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1139\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0746\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1178 [0/25000 (0%)]\tLosses default: 0.000048 bn: 0.000076 drop: 0.000007 both: 0.000067\n",
      "Train Epoch: 1178 [10000/25000 (40%)]\tLosses default: 0.000032 bn: 0.000105 drop: 0.000014 both: 0.000005\n",
      "Train Epoch: 1178 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000047 both: 0.000003\n",
      "Train Epoch: 1178 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000002 drop: 0.000036 both: 0.000043\n",
      "Test set:\n",
      "default: Loss: 1.1172\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1372\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.1299\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0958\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1179 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000003 both: 0.000430\n",
      "Train Epoch: 1179 [10000/25000 (40%)]\tLosses default: 0.000021 bn: 0.000010 drop: 0.000012 both: 0.000208\n",
      "Train Epoch: 1179 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000044 drop: 0.000035 both: 0.000031\n",
      "Train Epoch: 1179 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000006 drop: 0.000005 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.1218\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1362\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.1278\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0880\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1180 [0/25000 (0%)]\tLosses default: 0.000036 bn: 0.000004 drop: 0.000006 both: 0.000005\n",
      "Train Epoch: 1180 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000002 drop: 0.000310 both: 0.000092\n",
      "Train Epoch: 1180 [20000/25000 (80%)]\tLosses default: 0.000016 bn: 0.000005 drop: 0.000040 both: 0.000531\n",
      "Train Epoch: 1180 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000085 drop: 0.000013 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.1283\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1426\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.1425\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0775\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1181 [0/25000 (0%)]\tLosses default: 0.000022 bn: 0.000008 drop: 0.000009 both: 0.000002\n",
      "Train Epoch: 1181 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000010 both: 0.000477\n",
      "Train Epoch: 1181 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000013 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 1181 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000004 drop: 0.000003 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.1322\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1334\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.1603\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0807\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1182 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.000001 drop: 0.000018 both: 0.000007\n",
      "Train Epoch: 1182 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000118 drop: 0.000019 both: 0.000003\n",
      "Train Epoch: 1182 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000558 drop: 0.000009 both: 0.000319\n",
      "Train Epoch: 1182 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000010 both: 0.000322\n",
      "Test set:\n",
      "default: Loss: 1.1380\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0943\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1550\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0837\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1183 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000012 drop: 0.000005 both: 0.000032\n",
      "Train Epoch: 1183 [10000/25000 (40%)]\tLosses default: 0.000012 bn: 0.000098 drop: 0.000017 both: 0.000071\n",
      "Train Epoch: 1183 [20000/25000 (80%)]\tLosses default: 0.000035 bn: 0.000092 drop: 0.000110 both: 0.000159\n",
      "Train Epoch: 1183 [25000/25000 (100%)]\tLosses default: 0.000048 bn: 0.000049 drop: 0.000013 both: 0.000041\n",
      "Test set:\n",
      "default: Loss: 1.1428\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1268\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1614\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.1193\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1184 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000002 drop: 0.000019 both: 0.000101\n",
      "Train Epoch: 1184 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000049 drop: 0.002465 both: 0.000011\n",
      "Train Epoch: 1184 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000017 drop: 0.000023 both: 0.000009\n",
      "Train Epoch: 1184 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000002 drop: 0.000187 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.1479\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.1262\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1462\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0827\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1185 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000268 drop: 0.000285 both: 0.000011\n",
      "Train Epoch: 1185 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000138 drop: 0.000005 both: 0.001177\n",
      "Train Epoch: 1185 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000011 drop: 0.000251 both: 0.000010\n",
      "Train Epoch: 1185 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000014 drop: 0.000032 both: 0.023561\n",
      "Test set:\n",
      "default: Loss: 1.1539\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.0851\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.1148\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0444\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1186 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000653 both: 0.001500\n",
      "Train Epoch: 1186 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000037 drop: 0.000002 both: 0.000398\n",
      "Train Epoch: 1186 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000009 drop: 0.000005 both: 0.000013\n",
      "Train Epoch: 1186 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000015 both: 0.000200\n",
      "Test set:\n",
      "default: Loss: 1.1604\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0830\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.0850\tAccuracy: 4410.0/5000 (88%)\n",
      "both: Loss: 1.0670\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1187 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000020 drop: 0.000150 both: 0.000273\n",
      "Train Epoch: 1187 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000124 drop: 0.000004 both: 0.000053\n",
      "Train Epoch: 1187 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000019 drop: 0.000029 both: 0.000062\n",
      "Train Epoch: 1187 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000022 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.1656\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0857\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1051\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0591\tAccuracy: 4419.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1188 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000155 drop: 0.000034 both: 0.000015\n",
      "Train Epoch: 1188 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000478 drop: 0.000043 both: 0.000023\n",
      "Train Epoch: 1188 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001155 drop: 0.000002 both: 0.000009\n",
      "Train Epoch: 1188 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000038 drop: 0.000002 both: 0.000030\n",
      "Test set:\n",
      "default: Loss: 1.1714\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1018\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.1126\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0614\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1189 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000054 drop: 0.000027 both: 0.000008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1189 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.000005 both: 0.001073\n",
      "Train Epoch: 1189 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000081 drop: 0.000011 both: 0.000195\n",
      "Train Epoch: 1189 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.000007 drop: 0.000002 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.1791\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0953\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1405\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0257\tAccuracy: 4410.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1190 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000009 drop: 0.000168 both: 0.000007\n",
      "Train Epoch: 1190 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000187 drop: 0.000002 both: 0.000210\n",
      "Train Epoch: 1190 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000005 both: 0.000077\n",
      "Train Epoch: 1190 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000040 drop: 0.000006 both: 0.000378\n",
      "Test set:\n",
      "default: Loss: 1.1849\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1204\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1230\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0391\tAccuracy: 4417.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1191 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000004 both: 0.000024\n",
      "Train Epoch: 1191 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000017 both: 0.000050\n",
      "Train Epoch: 1191 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000047 drop: 0.000000 both: 0.000009\n",
      "Train Epoch: 1191 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000021 both: 0.001092\n",
      "Test set:\n",
      "default: Loss: 1.1931\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1633\tAccuracy: 4387.0/5000 (88%)\n",
      "drop: Loss: 1.1254\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0439\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1192 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.001018 drop: 0.000010 both: 0.000046\n",
      "Train Epoch: 1192 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000008 drop: 0.000024 both: 0.000035\n",
      "Train Epoch: 1192 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.033512 drop: 0.000005 both: 0.000032\n",
      "Train Epoch: 1192 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.003093 drop: 0.000051 both: 0.000318\n",
      "Test set:\n",
      "default: Loss: 1.1989\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1080\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.1259\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0681\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1193 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.013167 drop: 0.000015 both: 0.000021\n",
      "Train Epoch: 1193 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000008 both: 0.000012\n",
      "Train Epoch: 1193 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000126 drop: 0.000040 both: 0.000874\n",
      "Train Epoch: 1193 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000067 drop: 0.000004 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.2078\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1100\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1261\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0809\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1194 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000006 both: 0.000002\n",
      "Train Epoch: 1194 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000184 drop: 0.000007 both: 0.000004\n",
      "Train Epoch: 1194 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000018 both: 0.000683\n",
      "Train Epoch: 1194 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000010 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.2134\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1054\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1384\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.1030\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1195 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000009 both: 0.000015\n",
      "Train Epoch: 1195 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000001 both: 0.000031\n",
      "Train Epoch: 1195 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000067\n",
      "Train Epoch: 1195 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000004 drop: 0.000007 both: 0.000042\n",
      "Test set:\n",
      "default: Loss: 1.2216\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0943\tAccuracy: 4441.0/5000 (89%)\n",
      "drop: Loss: 1.1333\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0818\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1196 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000012 both: 0.000022\n",
      "Train Epoch: 1196 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000043 drop: 0.000019 both: 0.000060\n",
      "Train Epoch: 1196 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000004 both: 0.000009\n",
      "Train Epoch: 1196 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000000 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.2285\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1301\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.1384\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0928\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1197 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000012 both: 0.000012\n",
      "Train Epoch: 1197 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000003 both: 0.000011\n",
      "Train Epoch: 1197 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000015\n",
      "Train Epoch: 1197 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000013 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2359\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.1061\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.1421\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.1110\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1198 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000004 both: 0.000022\n",
      "Train Epoch: 1198 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000006 both: 0.143020\n",
      "Train Epoch: 1198 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000044 drop: 0.000014 both: 0.000043\n",
      "Train Epoch: 1198 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000050 drop: 0.000007 both: 0.000028\n",
      "Test set:\n",
      "default: Loss: 1.2447\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1082\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.1579\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0708\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1199 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.054527 drop: 0.000014 both: 0.000994\n",
      "Train Epoch: 1199 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000666 drop: 0.000034 both: 0.000008\n",
      "Train Epoch: 1199 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000030 both: 0.000005\n",
      "Train Epoch: 1199 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000001 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2510\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1046\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.1681\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0761\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1200 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000007 both: 0.000015\n",
      "Train Epoch: 1200 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000000 both: 0.000095\n",
      "Train Epoch: 1200 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000039 drop: 0.000002 both: 0.000020\n",
      "Train Epoch: 1200 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000039 drop: 0.000001 both: 0.000036\n",
      "Test set:\n",
      "default: Loss: 1.2592\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1217\tAccuracy: 4401.0/5000 (88%)\n",
      "drop: Loss: 1.1756\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0835\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1201 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000005 both: 0.000015\n",
      "Train Epoch: 1201 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000071 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 1201 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1201 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000578 drop: 0.000003 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2662\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1075\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.1922\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0823\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1202 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000005 both: 0.000032\n",
      "Train Epoch: 1202 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000009 both: 0.000024\n",
      "Train Epoch: 1202 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.012796 drop: 0.000016 both: 0.001234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1202 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000002 both: 0.000046\n",
      "Test set:\n",
      "default: Loss: 1.2746\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1349\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 1.1903\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0718\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1203 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000397 drop: 0.000003 both: 0.000681\n",
      "Train Epoch: 1203 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000038 drop: 0.000010 both: 0.000026\n",
      "Train Epoch: 1203 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000004 both: 0.000021\n",
      "Train Epoch: 1203 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.014057 both: 0.000136\n",
      "Test set:\n",
      "default: Loss: 1.2821\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1069\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.2442\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0449\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1204 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.123221 both: 0.000517\n",
      "Train Epoch: 1204 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000021 both: 0.000035\n",
      "Train Epoch: 1204 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000510 both: 0.000003\n",
      "Train Epoch: 1204 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000054 drop: 0.014879 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.2879\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0731\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.2356\tAccuracy: 4350.0/5000 (87%)\n",
      "both: Loss: 1.0529\tAccuracy: 4417.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1205 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000079 drop: 0.003931 both: 0.000070\n",
      "Train Epoch: 1205 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000008 both: 0.000215\n",
      "Train Epoch: 1205 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000090 drop: 0.000073 both: 0.000010\n",
      "Train Epoch: 1205 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000004 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.2940\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0943\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.2110\tAccuracy: 4366.0/5000 (87%)\n",
      "both: Loss: 1.0467\tAccuracy: 4414.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1206 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000011 both: 0.000008\n",
      "Train Epoch: 1206 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000204 drop: 0.000020 both: 0.002054\n",
      "Train Epoch: 1206 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000164 drop: 0.000001 both: 0.000020\n",
      "Train Epoch: 1206 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000026 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.3022\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1013\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1927\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0426\tAccuracy: 4416.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1207 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000008 both: 0.000107\n",
      "Train Epoch: 1207 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000024 both: 0.000057\n",
      "Train Epoch: 1207 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000087 drop: 0.000014 both: 0.000031\n",
      "Train Epoch: 1207 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000011 both: 0.000112\n",
      "Test set:\n",
      "default: Loss: 1.3082\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1523\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.1913\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.1015\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1208 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000139 both: 0.000013\n",
      "Train Epoch: 1208 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000010 both: 0.000114\n",
      "Train Epoch: 1208 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000001 both: 0.000143\n",
      "Train Epoch: 1208 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000012 both: 0.000067\n",
      "Test set:\n",
      "default: Loss: 1.3142\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.1706\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1815\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0580\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1209 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000016 both: 0.000027\n",
      "Train Epoch: 1209 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000806 drop: 0.000003 both: 0.000021\n",
      "Train Epoch: 1209 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 1209 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000006 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.3187\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1480\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.1819\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0632\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1210 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000913\n",
      "Train Epoch: 1210 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 1210 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000004 both: 0.000002\n",
      "Train Epoch: 1210 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000004 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3241\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.1180\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.2025\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0505\tAccuracy: 4417.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1211 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000004 both: 0.022151\n",
      "Train Epoch: 1211 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000011 both: 0.000007\n",
      "Train Epoch: 1211 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000047 drop: 0.000010 both: 0.000073\n",
      "Train Epoch: 1211 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001976 drop: 0.000020 both: 0.007720\n",
      "Test set:\n",
      "default: Loss: 1.3276\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0971\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.1994\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.1113\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1212 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000001 both: 0.000053\n",
      "Train Epoch: 1212 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000007 both: 0.000045\n",
      "Train Epoch: 1212 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000423 drop: 0.000012 both: 0.000014\n",
      "Train Epoch: 1212 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000030 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.3298\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.0779\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1929\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0879\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1213 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000014 both: 0.000065\n",
      "Train Epoch: 1213 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000070 drop: 0.000086 both: 0.000004\n",
      "Train Epoch: 1213 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000678 drop: 0.000005 both: 0.000002\n",
      "Train Epoch: 1213 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000017 both: 0.000096\n",
      "Test set:\n",
      "default: Loss: 1.3308\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0964\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.1940\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.0863\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1214 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1214 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000000 both: 0.000013\n",
      "Train Epoch: 1214 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.000090\n",
      "Train Epoch: 1214 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000001 both: 0.000738\n",
      "Test set:\n",
      "default: Loss: 1.3349\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0947\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.2001\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0752\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1215 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000001 both: 0.000041\n",
      "Train Epoch: 1215 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000004 both: 0.000285\n",
      "Train Epoch: 1215 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000010\n",
      "Train Epoch: 1215 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001865 drop: 0.000001 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.3378\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1462\tAccuracy: 4376.0/5000 (88%)\n",
      "drop: Loss: 1.2010\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0757\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1216 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.008832 drop: 0.000014 both: 0.000902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1216 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000006 both: 0.000015\n",
      "Train Epoch: 1216 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000068 drop: 0.001172 both: 0.000050\n",
      "Train Epoch: 1216 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 1.3379\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1542\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.2434\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.0475\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1217 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000000 both: 0.000031\n",
      "Train Epoch: 1217 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000014 both: 0.000062\n",
      "Train Epoch: 1217 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000050 both: 0.000014\n",
      "Train Epoch: 1217 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000053 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.3367\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1038\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1431\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0869\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1218 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000733 both: 0.000011\n",
      "Train Epoch: 1218 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000390 drop: 0.000624 both: 0.060219\n",
      "Train Epoch: 1218 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000014 both: 0.001033\n",
      "Train Epoch: 1218 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000198 drop: 0.000012 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.3410\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0854\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1217\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0917\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1219 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000417 drop: 0.006507 both: 0.000442\n",
      "Train Epoch: 1219 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000053 both: 0.000096\n",
      "Train Epoch: 1219 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.002327 drop: 0.000014 both: 0.000790\n",
      "Train Epoch: 1219 [25000/25000 (100%)]\tLosses default: 0.086797 bn: 0.000028 drop: 0.000235 both: 0.000024\n",
      "Test set:\n",
      "default: Loss: 1.5017\tAccuracy: 4331.0/5000 (87%)\n",
      "bn: Loss: 1.1188\tAccuracy: 4404.0/5000 (88%)\n",
      "drop: Loss: 1.1283\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0571\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1220 [0/25000 (0%)]\tLosses default: 0.319949 bn: 0.000002 drop: 0.000006 both: 0.000012\n",
      "Train Epoch: 1220 [10000/25000 (40%)]\tLosses default: 0.009052 bn: 0.000064 drop: 0.000045 both: 0.000125\n",
      "Train Epoch: 1220 [20000/25000 (80%)]\tLosses default: 0.000851 bn: 0.000005 drop: 0.000010 both: 0.000211\n",
      "Train Epoch: 1220 [25000/25000 (100%)]\tLosses default: 0.000872 bn: 0.003565 drop: 0.000003 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.1202\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.1054\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1183\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.1309\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1221 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000009 both: 0.000095\n",
      "Train Epoch: 1221 [10000/25000 (40%)]\tLosses default: 0.000072 bn: 0.000005 drop: 0.000002 both: 0.000007\n",
      "Train Epoch: 1221 [20000/25000 (80%)]\tLosses default: 0.000020 bn: 0.000001 drop: 0.000123 both: 0.000025\n",
      "Train Epoch: 1221 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000001 drop: 0.000013 both: 0.000269\n",
      "Test set:\n",
      "default: Loss: 1.1074\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1304\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1526\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0798\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1222 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001433 drop: 0.000010 both: 0.000017\n",
      "Train Epoch: 1222 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000000 drop: 0.000004 both: 0.000095\n",
      "Train Epoch: 1222 [20000/25000 (80%)]\tLosses default: 0.000022 bn: 0.000006 drop: 0.000011 both: 0.000024\n",
      "Train Epoch: 1222 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000010 both: 0.000030\n",
      "Test set:\n",
      "default: Loss: 1.1226\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1134\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.1277\tAccuracy: 4406.0/5000 (88%)\n",
      "both: Loss: 1.0757\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1223 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000224 drop: 0.000061 both: 0.000008\n",
      "Train Epoch: 1223 [10000/25000 (40%)]\tLosses default: 0.000076 bn: 0.000001 drop: 0.000013 both: 0.000097\n",
      "Train Epoch: 1223 [20000/25000 (80%)]\tLosses default: 0.000067 bn: 0.000190 drop: 0.000061 both: 0.000011\n",
      "Train Epoch: 1223 [25000/25000 (100%)]\tLosses default: 0.000368 bn: 0.000035 drop: 0.000010 both: 0.000172\n",
      "Test set:\n",
      "default: Loss: 1.1224\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1022\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1481\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.1142\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1224 [0/25000 (0%)]\tLosses default: 0.000016 bn: 0.000003 drop: 0.000011 both: 0.000018\n",
      "Train Epoch: 1224 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000014 drop: 0.000026 both: 0.000357\n",
      "Train Epoch: 1224 [20000/25000 (80%)]\tLosses default: 0.000015 bn: 0.000028 drop: 0.000000 both: 0.000001\n",
      "Train Epoch: 1224 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000072 drop: 0.000004 both: 0.000161\n",
      "Test set:\n",
      "default: Loss: 1.1251\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1039\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1563\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.1099\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1225 [0/25000 (0%)]\tLosses default: 0.000015 bn: 0.000008 drop: 0.000015 both: 0.000019\n",
      "Train Epoch: 1225 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000022 drop: 0.000008 both: 0.000010\n",
      "Train Epoch: 1225 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001223 drop: 0.000002 both: 0.000007\n",
      "Train Epoch: 1225 [25000/25000 (100%)]\tLosses default: 0.000041 bn: 0.000845 drop: 0.000023 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.1270\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.1290\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.1425\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.1015\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1226 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000003 both: 0.000004\n",
      "Train Epoch: 1226 [10000/25000 (40%)]\tLosses default: 0.000020 bn: 0.000004 drop: 0.000005 both: 0.000006\n",
      "Train Epoch: 1226 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000015 drop: 0.000010 both: 0.002430\n",
      "Train Epoch: 1226 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000016 drop: 0.000016 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.1294\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1454\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.1702\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.1054\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1227 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.076741 drop: 0.000003 both: 0.000006\n",
      "Train Epoch: 1227 [10000/25000 (40%)]\tLosses default: 0.000097 bn: 0.000008 drop: 0.000004 both: 0.000018\n",
      "Train Epoch: 1227 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000005 both: 0.000011\n",
      "Train Epoch: 1227 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000157 both: 0.000322\n",
      "Test set:\n",
      "default: Loss: 1.1337\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0986\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.1548\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.1057\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1228 [0/25000 (0%)]\tLosses default: 0.000024 bn: 0.000001 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1228 [10000/25000 (40%)]\tLosses default: 0.000026 bn: 0.000369 drop: 0.000008 both: 0.000103\n",
      "Train Epoch: 1228 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000006 drop: 0.000006 both: 0.000003\n",
      "Train Epoch: 1228 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000015 both: 0.000136\n",
      "Test set:\n",
      "default: Loss: 1.1366\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.1044\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.1681\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0866\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1229 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000001 drop: 0.000010 both: 0.000011\n",
      "Train Epoch: 1229 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000003 both: 0.000018\n",
      "Train Epoch: 1229 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000001 both: 0.000249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1229 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000206 drop: 0.000013 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.1399\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1123\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.1770\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0800\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1230 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000005 both: 0.000018\n",
      "Train Epoch: 1230 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000069 drop: 0.000001 both: 0.000013\n",
      "Train Epoch: 1230 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.030452 drop: 0.000025 both: 0.000160\n",
      "Train Epoch: 1230 [25000/25000 (100%)]\tLosses default: 0.000011 bn: 0.000006 drop: 0.000003 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1441\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0929\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1667\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0806\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1231 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000007 both: 0.005714\n",
      "Train Epoch: 1231 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000005 both: 0.000121\n",
      "Train Epoch: 1231 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000003 drop: 0.000012 both: 0.000244\n",
      "Train Epoch: 1231 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000915 drop: 0.000004 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.1491\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1133\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.1865\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0873\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1232 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000009 both: 0.000030\n",
      "Train Epoch: 1232 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000120 drop: 0.000002 both: 0.000004\n",
      "Train Epoch: 1232 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000034 drop: 0.000008 both: 0.000014\n",
      "Train Epoch: 1232 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000001 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.1536\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0931\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1845\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0592\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1233 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.001046 drop: 0.000002 both: 0.000011\n",
      "Train Epoch: 1233 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000001 both: 0.000038\n",
      "Train Epoch: 1233 [20000/25000 (80%)]\tLosses default: 0.000012 bn: 0.001657 drop: 0.000002 both: 0.000453\n",
      "Train Epoch: 1233 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000188 drop: 0.000001 both: 0.000028\n",
      "Test set:\n",
      "default: Loss: 1.1581\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1177\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2185\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0867\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1234 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.003463 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1234 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000002 drop: 0.000006 both: 0.000070\n",
      "Train Epoch: 1234 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000178 drop: 0.000015 both: 0.000008\n",
      "Train Epoch: 1234 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000106 drop: 0.000003 both: 0.000305\n",
      "Test set:\n",
      "default: Loss: 1.1635\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0848\tAccuracy: 4445.0/5000 (89%)\n",
      "drop: Loss: 1.2170\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0629\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1235 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000003 both: 0.000287\n",
      "Train Epoch: 1235 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000036 drop: 0.000007 both: 0.000016\n",
      "Train Epoch: 1235 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1235 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.001882 drop: 0.000013 both: 0.050686\n",
      "Test set:\n",
      "default: Loss: 1.1686\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0867\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.2277\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0700\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1236 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000012 drop: 0.000000 both: 0.000017\n",
      "Train Epoch: 1236 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000007 both: 0.000112\n",
      "Train Epoch: 1236 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000037 drop: 0.000001 both: 0.000017\n",
      "Train Epoch: 1236 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000008 drop: 0.000001 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.1751\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1154\tAccuracy: 4391.0/5000 (88%)\n",
      "drop: Loss: 1.2413\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0610\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1237 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000005 both: 0.000178\n",
      "Train Epoch: 1237 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.007727 drop: 0.000000 both: 0.000002\n",
      "Train Epoch: 1237 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000001 both: 0.000678\n",
      "Train Epoch: 1237 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000061 drop: 0.000000 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.1814\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.1042\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.2360\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0521\tAccuracy: 4415.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1238 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000001 both: 0.000007\n",
      "Train Epoch: 1238 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000134 drop: 0.000007 both: 0.000071\n",
      "Train Epoch: 1238 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000066 drop: 0.000000 both: 0.000021\n",
      "Train Epoch: 1238 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000004 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.1872\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1078\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.2500\tAccuracy: 4404.0/5000 (88%)\n",
      "both: Loss: 1.0580\tAccuracy: 4417.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1239 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000029 drop: 0.000001 both: 0.026974\n",
      "Train Epoch: 1239 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000001 both: 0.000019\n",
      "Train Epoch: 1239 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000003 both: 0.000009\n",
      "Train Epoch: 1239 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000001 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.1937\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.1040\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.2706\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.0351\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1240 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000002 both: 0.000008\n",
      "Train Epoch: 1240 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1240 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000066 drop: 0.007397 both: 0.000014\n",
      "Train Epoch: 1240 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000187 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.2001\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.1459\tAccuracy: 4400.0/5000 (88%)\n",
      "drop: Loss: 1.2841\tAccuracy: 4356.0/5000 (87%)\n",
      "both: Loss: 1.0868\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1241 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000472 both: 0.000008\n",
      "Train Epoch: 1241 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000045 both: 0.000023\n",
      "Train Epoch: 1241 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000014 both: 0.000004\n",
      "Train Epoch: 1241 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000008 both: 0.001035\n",
      "Test set:\n",
      "default: Loss: 1.2074\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0851\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.2686\tAccuracy: 4358.0/5000 (87%)\n",
      "both: Loss: 1.0797\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1242 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000009 drop: 0.001581 both: 0.000004\n",
      "Train Epoch: 1242 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000127 drop: 0.000006 both: 0.000101\n",
      "Train Epoch: 1242 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000028\n",
      "Train Epoch: 1242 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000804 drop: 0.000044 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.2151\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1080\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2516\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1068\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1243 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000014 both: 0.000085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1243 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000008 both: 0.000310\n",
      "Train Epoch: 1243 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000002 both: 0.000046\n",
      "Train Epoch: 1243 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000309 drop: 0.000157 both: 0.000024\n",
      "Test set:\n",
      "default: Loss: 1.2224\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1156\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.2450\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0891\tAccuracy: 4414.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1244 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000006 both: 0.000337\n",
      "Train Epoch: 1244 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000012 both: 0.000004\n",
      "Train Epoch: 1244 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000004\n",
      "Train Epoch: 1244 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000016 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.2282\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.1342\tAccuracy: 4444.0/5000 (89%)\n",
      "drop: Loss: 1.2330\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0964\tAccuracy: 4418.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1245 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000008 both: 0.000005\n",
      "Train Epoch: 1245 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000008 both: 0.000006\n",
      "Train Epoch: 1245 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000041 drop: 0.000033 both: 0.000364\n",
      "Train Epoch: 1245 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.2358\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.1352\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.2492\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.1026\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1246 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000014 both: 0.000008\n",
      "Train Epoch: 1246 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000003 both: 0.000012\n",
      "Train Epoch: 1246 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000021 both: 0.000007\n",
      "Train Epoch: 1246 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000006 both: 0.054643\n",
      "Test set:\n",
      "default: Loss: 1.2436\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1544\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.2512\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.1246\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1247 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000002 both: 0.000611\n",
      "Train Epoch: 1247 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000005 both: 0.000568\n",
      "Train Epoch: 1247 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000267 drop: 0.000001 both: 0.000007\n",
      "Train Epoch: 1247 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000002 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.2495\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1482\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.2467\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0933\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1248 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001109 drop: 0.000013 both: 0.000016\n",
      "Train Epoch: 1248 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000534 drop: 0.000011 both: 0.001833\n",
      "Train Epoch: 1248 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000007 both: 0.000045\n",
      "Train Epoch: 1248 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000001 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.2568\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1218\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.2546\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1334\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1249 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.055699 drop: 0.000001 both: 0.000465\n",
      "Train Epoch: 1249 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.018752 drop: 0.000001 both: 0.000007\n",
      "Train Epoch: 1249 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000043 both: 0.000003\n",
      "Train Epoch: 1249 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000001 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2643\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.1167\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.2450\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0674\tAccuracy: 4415.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1250 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000000 both: 0.024902\n",
      "Train Epoch: 1250 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000221 drop: 0.000010 both: 0.000007\n",
      "Train Epoch: 1250 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1250 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000008 both: 0.000068\n",
      "Test set:\n",
      "default: Loss: 1.2695\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1072\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.2587\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0977\tAccuracy: 4410.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1251 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000239 drop: 0.000033 both: 0.000002\n",
      "Train Epoch: 1251 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.001185 both: 0.000016\n",
      "Train Epoch: 1251 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000012 both: 0.000007\n",
      "Train Epoch: 1251 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000015 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.2775\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0940\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.2622\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0996\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1252 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000012 both: 0.001753\n",
      "Train Epoch: 1252 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000000 both: 0.000595\n",
      "Train Epoch: 1252 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000428 drop: 0.000000 both: 0.000060\n",
      "Train Epoch: 1252 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000145 drop: 0.000006 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.2851\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0983\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.2699\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0834\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1253 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.000008\n",
      "Train Epoch: 1253 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000006 both: 0.001322\n",
      "Train Epoch: 1253 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000001 both: 0.000865\n",
      "Train Epoch: 1253 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000001 both: 0.000037\n",
      "Test set:\n",
      "default: Loss: 1.2909\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.0830\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.2889\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0588\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1254 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000000 both: 0.000433\n",
      "Train Epoch: 1254 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000008\n",
      "Train Epoch: 1254 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000004 both: 0.000004\n",
      "Train Epoch: 1254 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000003 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2973\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1208\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2789\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.1206\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1255 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000007\n",
      "Train Epoch: 1255 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.013369 both: 0.000018\n",
      "Train Epoch: 1255 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.003092 both: 0.000005\n",
      "Train Epoch: 1255 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000025 both: 0.000100\n",
      "Test set:\n",
      "default: Loss: 1.3028\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1148\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.1816\tAccuracy: 4367.0/5000 (87%)\n",
      "both: Loss: 1.0759\tAccuracy: 4414.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1256 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000050 drop: 0.000004 both: 0.000005\n",
      "Train Epoch: 1256 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000001 both: 0.000063\n",
      "Train Epoch: 1256 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000010 both: 0.000278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1256 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000046 drop: 0.000021 both: 0.000438\n",
      "Test set:\n",
      "default: Loss: 1.3086\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0984\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.1887\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.1032\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1257 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000049 both: 0.004854\n",
      "Train Epoch: 1257 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000040 drop: 0.000023 both: 0.000119\n",
      "Train Epoch: 1257 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000003 both: 0.000015\n",
      "Train Epoch: 1257 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000016 both: 0.001777\n",
      "Test set:\n",
      "default: Loss: 1.3157\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1123\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.1750\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0853\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1258 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000144 both: 0.000006\n",
      "Train Epoch: 1258 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000007 both: 0.000008\n",
      "Train Epoch: 1258 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000009 both: 0.000025\n",
      "Train Epoch: 1258 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000651 drop: 0.000004 both: 0.001247\n",
      "Test set:\n",
      "default: Loss: 1.3186\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.1123\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1678\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0504\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1259 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000030 both: 0.000016\n",
      "Train Epoch: 1259 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000009 both: 0.000025\n",
      "Train Epoch: 1259 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000343 both: 0.000004\n",
      "Train Epoch: 1259 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000082 drop: 0.000002 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3215\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.1174\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.2023\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0592\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1260 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000658 both: 0.000002\n",
      "Train Epoch: 1260 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000015 both: 0.000076\n",
      "Train Epoch: 1260 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000095 drop: 0.001112 both: 0.000005\n",
      "Train Epoch: 1260 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000018 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.3270\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.1253\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.1970\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0880\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1261 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000018 both: 0.000001\n",
      "Train Epoch: 1261 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000065 drop: 0.000004 both: 0.000031\n",
      "Train Epoch: 1261 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000001 both: 0.000003\n",
      "Train Epoch: 1261 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000010 both: 0.000040\n",
      "Test set:\n",
      "default: Loss: 1.3285\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.1090\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1943\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.0804\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1262 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000020 both: 0.000215\n",
      "Train Epoch: 1262 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000049 drop: 0.000065 both: 0.000003\n",
      "Train Epoch: 1262 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000001 both: 0.000029\n",
      "Train Epoch: 1262 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000107 drop: 0.000004 both: 0.000776\n",
      "Test set:\n",
      "default: Loss: 1.3290\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.1540\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.2136\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0730\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1263 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000014 both: 0.000005\n",
      "Train Epoch: 1263 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000006 both: 0.038075\n",
      "Train Epoch: 1263 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000004 both: 0.086171\n",
      "Train Epoch: 1263 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000088 drop: 0.000006 both: 0.000311\n",
      "Test set:\n",
      "default: Loss: 1.3312\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.1022\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.2091\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0971\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1264 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000071\n",
      "Train Epoch: 1264 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000156 drop: 0.000006 both: 0.000002\n",
      "Train Epoch: 1264 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000403 drop: 0.000001 both: 0.000012\n",
      "Train Epoch: 1264 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000025 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.3312\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.1049\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.2139\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0596\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1265 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000016 both: 0.000158\n",
      "Train Epoch: 1265 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000005 both: 0.000006\n",
      "Train Epoch: 1265 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000004 both: 0.000017\n",
      "Train Epoch: 1265 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001617 drop: 0.000001 both: 0.000360\n",
      "Test set:\n",
      "default: Loss: 1.3334\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0875\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.2280\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0473\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1266 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000007 both: 0.000006\n",
      "Train Epoch: 1266 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000002 both: 0.000011\n",
      "Train Epoch: 1266 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.005673 drop: 0.000005 both: 0.000029\n",
      "Train Epoch: 1266 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000170 drop: 0.000001 both: 0.002796\n",
      "Test set:\n",
      "default: Loss: 1.3355\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.1238\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.2180\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.0612\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1267 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000154 both: 0.000011\n",
      "Train Epoch: 1267 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000151 drop: 0.000001 both: 0.000008\n",
      "Train Epoch: 1267 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000620 drop: 0.000003 both: 0.043913\n",
      "Train Epoch: 1267 [25000/25000 (100%)]\tLosses default: 0.631473 bn: 0.011838 drop: 0.000000 both: 0.004805\n",
      "Test set:\n",
      "default: Loss: 1.1832\tAccuracy: 4346.0/5000 (87%)\n",
      "bn: Loss: 1.1525\tAccuracy: 4391.0/5000 (88%)\n",
      "drop: Loss: 1.2219\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0608\tAccuracy: 4415.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1268 [0/25000 (0%)]\tLosses default: 0.060052 bn: 0.000013 drop: 0.000002 both: 0.000013\n",
      "Train Epoch: 1268 [10000/25000 (40%)]\tLosses default: 0.001248 bn: 0.000006 drop: 0.000000 both: 0.000061\n",
      "Train Epoch: 1268 [20000/25000 (80%)]\tLosses default: 0.000440 bn: 0.010556 drop: 0.000014 both: 0.000013\n",
      "Train Epoch: 1268 [25000/25000 (100%)]\tLosses default: 0.000225 bn: 0.000056 drop: 0.000001 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.1564\tAccuracy: 4404.0/5000 (88%)\n",
      "bn: Loss: 1.1366\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 1.2518\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0681\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1269 [0/25000 (0%)]\tLosses default: 0.000080 bn: 0.000372 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 1269 [10000/25000 (40%)]\tLosses default: 0.000027 bn: 0.000062 drop: 0.000001 both: 0.000014\n",
      "Train Epoch: 1269 [20000/25000 (80%)]\tLosses default: 0.000529 bn: 0.000020 drop: 0.000015 both: 0.000631\n",
      "Train Epoch: 1269 [25000/25000 (100%)]\tLosses default: 0.014822 bn: 0.000002 drop: 0.000001 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.1752\tAccuracy: 4403.0/5000 (88%)\n",
      "bn: Loss: 1.1384\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2452\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0651\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1270 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000089 drop: 0.000004 both: 0.000086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1270 [10000/25000 (40%)]\tLosses default: 0.000008 bn: 0.000008 drop: 0.000000 both: 0.000045\n",
      "Train Epoch: 1270 [20000/25000 (80%)]\tLosses default: 0.000123 bn: 0.000001 drop: 0.000004 both: 0.000102\n",
      "Train Epoch: 1270 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000034 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.1634\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1174\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.2475\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0586\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1271 [0/25000 (0%)]\tLosses default: 0.000017 bn: 0.000000 drop: 0.000001 both: 0.000060\n",
      "Train Epoch: 1271 [10000/25000 (40%)]\tLosses default: 0.000058 bn: 0.000003 drop: 0.000001 both: 0.000030\n",
      "Train Epoch: 1271 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000002 both: 0.000015\n",
      "Train Epoch: 1271 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000013 drop: 0.000000 both: 0.000070\n",
      "Test set:\n",
      "default: Loss: 1.1582\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1496\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.2408\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0398\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1272 [0/25000 (0%)]\tLosses default: 0.000042 bn: 0.000022 drop: 0.000000 both: 0.000045\n",
      "Train Epoch: 1272 [10000/25000 (40%)]\tLosses default: 0.000012 bn: 0.004570 drop: 0.000001 both: 0.000138\n",
      "Train Epoch: 1272 [20000/25000 (80%)]\tLosses default: 0.000172 bn: 0.000006 drop: 0.000001 both: 0.000060\n",
      "Train Epoch: 1272 [25000/25000 (100%)]\tLosses default: 0.000011 bn: 0.000016 drop: 0.000000 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.1638\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.1299\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.2669\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0644\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1273 [0/25000 (0%)]\tLosses default: 0.000012 bn: 0.000002 drop: 0.000003 both: 0.000007\n",
      "Train Epoch: 1273 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000002 drop: 0.000001 both: 0.000247\n",
      "Train Epoch: 1273 [20000/25000 (80%)]\tLosses default: 0.000011 bn: 0.000009 drop: 0.000009 both: 0.000018\n",
      "Train Epoch: 1273 [25000/25000 (100%)]\tLosses default: 0.000010 bn: 0.000006 drop: 0.000001 both: 0.000913\n",
      "Test set:\n",
      "default: Loss: 1.1689\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1153\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.2825\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.0917\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1274 [0/25000 (0%)]\tLosses default: 0.000007 bn: 0.000001 drop: 0.000000 both: 0.000452\n",
      "Train Epoch: 1274 [10000/25000 (40%)]\tLosses default: 0.000046 bn: 0.000005 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1274 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000008 drop: 0.000001 both: 0.000082\n",
      "Train Epoch: 1274 [25000/25000 (100%)]\tLosses default: 0.000052 bn: 0.000007 drop: 0.000001 both: 0.001041\n",
      "Test set:\n",
      "default: Loss: 1.1751\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.0913\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2869\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.1156\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1275 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000010 drop: 0.000007 both: 0.000679\n",
      "Train Epoch: 1275 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000009 drop: 0.000001 both: 0.006992\n",
      "Train Epoch: 1275 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000016 drop: 0.000001 both: 0.000029\n",
      "Train Epoch: 1275 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000012 drop: 0.000038 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.1801\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.0961\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.2898\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.0575\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1276 [0/25000 (0%)]\tLosses default: 0.000008 bn: 0.000171 drop: 0.000001 both: 0.000077\n",
      "Train Epoch: 1276 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000000 drop: 0.000002 both: 0.000018\n",
      "Train Epoch: 1276 [20000/25000 (80%)]\tLosses default: 0.000012 bn: 0.000089 drop: 0.000001 both: 0.000006\n",
      "Train Epoch: 1276 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000019 drop: 0.000000 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.1862\tAccuracy: 4423.0/5000 (88%)\n",
      "bn: Loss: 1.1303\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.2816\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.1111\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1277 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000011 drop: 0.000005 both: 0.000163\n",
      "Train Epoch: 1277 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000001 both: 0.000022\n",
      "Train Epoch: 1277 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000000 drop: 0.000002 both: 0.000248\n",
      "Train Epoch: 1277 [25000/25000 (100%)]\tLosses default: 0.000035 bn: 0.000025 drop: 0.000002 both: 0.001104\n",
      "Test set:\n",
      "default: Loss: 1.1923\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1182\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.3070\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0770\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1278 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000025 drop: 0.000004 both: 0.000011\n",
      "Train Epoch: 1278 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000062 both: 0.000007\n",
      "Train Epoch: 1278 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000023 drop: 0.000104 both: 0.000002\n",
      "Train Epoch: 1278 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.017143 drop: 0.000021 both: 0.000025\n",
      "Test set:\n",
      "default: Loss: 1.1997\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1352\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.1306\tAccuracy: 4362.0/5000 (87%)\n",
      "both: Loss: 1.0835\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1279 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000109 drop: 0.000438 both: 0.000003\n",
      "Train Epoch: 1279 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000051 drop: 0.000082 both: 0.000004\n",
      "Train Epoch: 1279 [20000/25000 (80%)]\tLosses default: 0.000005 bn: 0.000002 drop: 0.000471 both: 0.000056\n",
      "Train Epoch: 1279 [25000/25000 (100%)]\tLosses default: 0.000013 bn: 0.000036 drop: 0.014257 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.2058\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1430\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.2131\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.0849\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1280 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000007 both: 0.000048\n",
      "Train Epoch: 1280 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000330 both: 0.000018\n",
      "Train Epoch: 1280 [20000/25000 (80%)]\tLosses default: 0.000011 bn: 0.000003 drop: 0.000004 both: 0.000015\n",
      "Train Epoch: 1280 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000001 both: 0.000176\n",
      "Test set:\n",
      "default: Loss: 1.2127\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0983\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.2133\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0814\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1281 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000024 drop: 0.000424 both: 0.000011\n",
      "Train Epoch: 1281 [10000/25000 (40%)]\tLosses default: 0.000007 bn: 0.000005 drop: 0.000396 both: 0.000125\n",
      "Train Epoch: 1281 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000011 both: 0.000004\n",
      "Train Epoch: 1281 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000008 both: 0.000105\n",
      "Test set:\n",
      "default: Loss: 1.2187\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1209\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.2147\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.0797\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1282 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000069 drop: 0.000002 both: 0.000066\n",
      "Train Epoch: 1282 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000012 drop: 0.000009 both: 0.000028\n",
      "Train Epoch: 1282 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000000 drop: 0.000139 both: 0.000007\n",
      "Train Epoch: 1282 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000006 both: 0.000060\n",
      "Test set:\n",
      "default: Loss: 1.2270\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1080\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.2439\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.0905\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1283 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000013 drop: 0.000006 both: 0.000027\n",
      "Train Epoch: 1283 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000047 drop: 0.000007 both: 0.000009\n",
      "Train Epoch: 1283 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000050 drop: 0.000015 both: 0.000042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1283 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000008 drop: 0.000029 both: 0.000057\n",
      "Test set:\n",
      "default: Loss: 1.2335\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1521\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.2100\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.1135\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1284 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000280 drop: 0.000004 both: 0.000209\n",
      "Train Epoch: 1284 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000012 both: 0.000027\n",
      "Train Epoch: 1284 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000451 drop: 0.000003 both: 0.000043\n",
      "Train Epoch: 1284 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000004 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.2402\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1248\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.2256\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1048\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1285 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000010 both: 0.000005\n",
      "Train Epoch: 1285 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000001 both: 0.000138\n",
      "Train Epoch: 1285 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.011579 drop: 0.000001 both: 0.000749\n",
      "Train Epoch: 1285 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000097 drop: 0.000002 both: 0.000042\n",
      "Test set:\n",
      "default: Loss: 1.2478\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.1003\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.2427\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.1086\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1286 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000013 drop: 0.000020 both: 0.000003\n",
      "Train Epoch: 1286 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 1286 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000038 both: 0.000006\n",
      "Train Epoch: 1286 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000037 drop: 0.000002 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.2533\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1413\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.2377\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.1028\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1287 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000002 both: 0.000020\n",
      "Train Epoch: 1287 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000066 drop: 0.000009 both: 0.000024\n",
      "Train Epoch: 1287 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.057101 drop: 0.000003 both: 0.000038\n",
      "Train Epoch: 1287 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000002 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.2602\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1340\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.2539\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.1276\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1288 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000004 both: 0.000009\n",
      "Train Epoch: 1288 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.004472 drop: 0.000031 both: 0.000559\n",
      "Train Epoch: 1288 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000014 both: 0.000769\n",
      "Train Epoch: 1288 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000039 drop: 0.000004 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2663\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1229\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.2466\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.1092\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1289 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000005 both: 0.000013\n",
      "Train Epoch: 1289 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000000 both: 0.000004\n",
      "Train Epoch: 1289 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000037 drop: 0.000005 both: 0.000003\n",
      "Train Epoch: 1289 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000023 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2734\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1072\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.2345\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0874\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1290 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000037 drop: 0.000002 both: 0.000024\n",
      "Train Epoch: 1290 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000133 both: 0.000027\n",
      "Train Epoch: 1290 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000023 drop: 0.000002 both: 0.000250\n",
      "Train Epoch: 1290 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000042 drop: 0.000004 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2810\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1148\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.2395\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1335\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1291 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.035887 drop: 0.000002 both: 0.000004\n",
      "Train Epoch: 1291 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000005 both: 0.000009\n",
      "Train Epoch: 1291 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000010 both: 0.000304\n",
      "Train Epoch: 1291 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000073 drop: 0.000019 both: 0.000049\n",
      "Test set:\n",
      "default: Loss: 1.2854\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1038\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.2481\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.1466\tAccuracy: 4370.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1292 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000001 both: 0.000023\n",
      "Train Epoch: 1292 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000010 both: 0.000014\n",
      "Train Epoch: 1292 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000004 both: 0.000013\n",
      "Train Epoch: 1292 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000032 drop: 0.000004 both: 0.000034\n",
      "Test set:\n",
      "default: Loss: 1.2934\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0816\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.2585\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.1031\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1293 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000019 drop: 0.000003 both: 0.000016\n",
      "Train Epoch: 1293 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001218 drop: 0.000003 both: 0.000004\n",
      "Train Epoch: 1293 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000000 both: 0.000004\n",
      "Train Epoch: 1293 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000084 drop: 0.000014 both: 0.000314\n",
      "Test set:\n",
      "default: Loss: 1.2975\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1192\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.2653\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.1055\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1294 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000001 both: 0.000298\n",
      "Train Epoch: 1294 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000004 both: 0.000819\n",
      "Train Epoch: 1294 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1294 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000049 both: 0.000023\n",
      "Test set:\n",
      "default: Loss: 1.3038\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0852\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.2772\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0919\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1295 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000092 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 1295 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000000 both: 0.000033\n",
      "Train Epoch: 1295 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000004 both: 0.000011\n",
      "Train Epoch: 1295 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000019 both: 0.000040\n",
      "Test set:\n",
      "default: Loss: 1.3090\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1013\tAccuracy: 4453.0/5000 (89%)\n",
      "drop: Loss: 1.2789\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0523\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1296 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000001 both: 0.000079\n",
      "Train Epoch: 1296 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000022\n",
      "Train Epoch: 1296 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000000 both: 0.000010\n",
      "Train Epoch: 1296 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000079 drop: 0.000001 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.3157\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1220\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2654\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0708\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1297 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.007860 drop: 0.000002 both: 0.000019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1297 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000001 both: 0.000006\n",
      "Train Epoch: 1297 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001178 drop: 0.000001 both: 0.000054\n",
      "Train Epoch: 1297 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000001 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 1.3222\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1444\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.3072\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0647\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1298 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001327 drop: 0.000000 both: 0.000005\n",
      "Train Epoch: 1298 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000306 drop: 0.127431 both: 0.000004\n",
      "Train Epoch: 1298 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.001584 both: 0.000012\n",
      "Train Epoch: 1298 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000038 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3259\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0799\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.2187\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.1394\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1299 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.002740 both: 0.000080\n",
      "Train Epoch: 1299 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.014511 both: 0.000006\n",
      "Train Epoch: 1299 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000358 both: 0.000020\n",
      "Train Epoch: 1299 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000002 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3316\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1196\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.2503\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.0707\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1300 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000009\n",
      "Train Epoch: 1300 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000072 both: 0.000009\n",
      "Train Epoch: 1300 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000069 drop: 0.000013 both: 0.000011\n",
      "Train Epoch: 1300 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000014 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3376\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1021\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.2292\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0854\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1301 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000012 both: 0.000009\n",
      "Train Epoch: 1301 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000089 both: 0.000001\n",
      "Train Epoch: 1301 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000031 both: 0.000027\n",
      "Train Epoch: 1301 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000012 both: 0.012147\n",
      "Test set:\n",
      "default: Loss: 1.3448\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0874\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.2427\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0931\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1302 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000007 both: 0.000001\n",
      "Train Epoch: 1302 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000015\n",
      "Train Epoch: 1302 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000015 both: 0.000033\n",
      "Train Epoch: 1302 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000125 drop: 0.000024 both: 0.000024\n",
      "Test set:\n",
      "default: Loss: 1.3472\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0927\tAccuracy: 4442.0/5000 (89%)\n",
      "drop: Loss: 1.2294\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0951\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1303 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000033\n",
      "Train Epoch: 1303 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.007295 drop: 0.174694 both: 0.000031\n",
      "Train Epoch: 1303 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000005 both: 0.000004\n",
      "Train Epoch: 1303 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001739 drop: 0.000147 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.3534\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1232\tAccuracy: 4393.0/5000 (88%)\n",
      "drop: Loss: 1.2261\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0819\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1304 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.005109 drop: 0.000003 both: 0.000016\n",
      "Train Epoch: 1304 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000784 drop: 0.000011 both: 0.000004\n",
      "Train Epoch: 1304 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.006027 drop: 0.000048 both: 0.001053\n",
      "Train Epoch: 1304 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000020 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3565\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.0929\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.2291\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.1374\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1305 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.000088\n",
      "Train Epoch: 1305 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 1305 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000012 both: 0.000002\n",
      "Train Epoch: 1305 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000010 both: 0.000069\n",
      "Test set:\n",
      "default: Loss: 1.3583\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.0771\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.2048\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.1184\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1306 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000031 drop: 0.000006 both: 0.000006\n",
      "Train Epoch: 1306 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000014 both: 0.001388\n",
      "Train Epoch: 1306 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000050 drop: 0.000056 both: 0.000039\n",
      "Train Epoch: 1306 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000063 drop: 0.000005 both: 0.009824\n",
      "Test set:\n",
      "default: Loss: 1.3650\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1090\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2091\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.1182\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1307 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000047 both: 0.000079\n",
      "Train Epoch: 1307 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000106 drop: 0.000002 both: 0.000011\n",
      "Train Epoch: 1307 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000192 drop: 0.000001 both: 0.000161\n",
      "Train Epoch: 1307 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.000000 both: 0.000473\n",
      "Test set:\n",
      "default: Loss: 1.3684\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1140\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.1927\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.1276\tAccuracy: 4361.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1308 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000007 both: 0.000018\n",
      "Train Epoch: 1308 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000001\n",
      "Train Epoch: 1308 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000330 drop: 0.000000 both: 0.000315\n",
      "Train Epoch: 1308 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000006 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.3661\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0897\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1813\tAccuracy: 4408.0/5000 (88%)\n",
      "both: Loss: 1.1040\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1309 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000031\n",
      "Train Epoch: 1309 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000123 drop: 0.000001 both: 0.000005\n",
      "Train Epoch: 1309 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000004 both: 0.000001\n",
      "Train Epoch: 1309 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000075\n",
      "Test set:\n",
      "default: Loss: 1.3708\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1049\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.2167\tAccuracy: 4405.0/5000 (88%)\n",
      "both: Loss: 1.1155\tAccuracy: 4397.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1310 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000040 drop: 0.000011 both: 0.000029\n",
      "Train Epoch: 1310 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000040 drop: 0.000002 both: 0.000005\n",
      "Train Epoch: 1310 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000002 both: 0.000081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1310 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000001 both: 0.000436\n",
      "Test set:\n",
      "default: Loss: 1.3693\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1601\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.1816\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.1093\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1311 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000003 both: 0.000006\n",
      "Train Epoch: 1311 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000121 both: 0.000693\n",
      "Train Epoch: 1311 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000009 both: 0.000046\n",
      "Train Epoch: 1311 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000248 both: 0.000946\n",
      "Test set:\n",
      "default: Loss: 1.3715\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1043\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1907\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.1480\tAccuracy: 4372.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1312 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000212 drop: 0.000001 both: 0.000099\n",
      "Train Epoch: 1312 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000001 both: 0.011127\n",
      "Train Epoch: 1312 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000001 both: 0.000014\n",
      "Train Epoch: 1312 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000001 both: 0.000039\n",
      "Test set:\n",
      "default: Loss: 1.3702\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.0892\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.2162\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.1509\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1313 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000005 both: 0.000004\n",
      "Train Epoch: 1313 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000002 both: 0.000085\n",
      "Train Epoch: 1313 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000011\n",
      "Train Epoch: 1313 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000001 both: 0.000039\n",
      "Test set:\n",
      "default: Loss: 1.3688\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0976\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.2192\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.1200\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1314 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 1314 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000001 both: 0.000009\n",
      "Train Epoch: 1314 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000000 both: 0.000042\n",
      "Train Epoch: 1314 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000006 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.3686\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1076\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.2184\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.1163\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1315 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000119 drop: 0.000001 both: 0.000044\n",
      "Train Epoch: 1315 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000000 both: 0.000001\n",
      "Train Epoch: 1315 [20000/25000 (80%)]\tLosses default: 0.309243 bn: 0.036109 drop: 0.000001 both: 0.004018\n",
      "Train Epoch: 1315 [25000/25000 (100%)]\tLosses default: 0.000573 bn: 0.000000 drop: 0.000001 both: 0.000103\n",
      "Test set:\n",
      "default: Loss: 1.1058\tAccuracy: 4382.0/5000 (88%)\n",
      "bn: Loss: 1.0978\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.2062\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.1294\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1316 [0/25000 (0%)]\tLosses default: 0.001749 bn: 0.000002 drop: 0.000000 both: 0.000002\n",
      "Train Epoch: 1316 [10000/25000 (40%)]\tLosses default: 0.000801 bn: 0.000031 drop: 0.000004 both: 0.000007\n",
      "Train Epoch: 1316 [20000/25000 (80%)]\tLosses default: 0.001335 bn: 0.000004 drop: 0.000309 both: 0.000332\n",
      "Train Epoch: 1316 [25000/25000 (100%)]\tLosses default: 0.003049 bn: 0.000004 drop: 0.005873 both: 0.000310\n",
      "Test set:\n",
      "default: Loss: 1.0931\tAccuracy: 4412.0/5000 (88%)\n",
      "bn: Loss: 1.1351\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.2134\tAccuracy: 4347.0/5000 (87%)\n",
      "both: Loss: 1.0913\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1317 [0/25000 (0%)]\tLosses default: 0.000111 bn: 0.000576 drop: 0.000004 both: 0.000003\n",
      "Train Epoch: 1317 [10000/25000 (40%)]\tLosses default: 0.000167 bn: 0.000008 drop: 0.000833 both: 0.000008\n",
      "Train Epoch: 1317 [20000/25000 (80%)]\tLosses default: 0.000038 bn: 0.000001 drop: 0.000010 both: 0.000014\n",
      "Train Epoch: 1317 [25000/25000 (100%)]\tLosses default: 0.000179 bn: 0.000939 drop: 0.000136 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.1080\tAccuracy: 4409.0/5000 (88%)\n",
      "bn: Loss: 1.0894\tAccuracy: 4443.0/5000 (89%)\n",
      "drop: Loss: 1.2291\tAccuracy: 4365.0/5000 (87%)\n",
      "both: Loss: 1.1077\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1318 [0/25000 (0%)]\tLosses default: 0.000243 bn: 0.000001 drop: 0.000012 both: 0.000028\n",
      "Train Epoch: 1318 [10000/25000 (40%)]\tLosses default: 0.000030 bn: 0.000002 drop: 0.018884 both: 0.000132\n",
      "Train Epoch: 1318 [20000/25000 (80%)]\tLosses default: 0.000262 bn: 0.000012 drop: 0.000553 both: 0.008124\n",
      "Train Epoch: 1318 [25000/25000 (100%)]\tLosses default: 0.000269 bn: 0.000028 drop: 0.000024 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.1157\tAccuracy: 4413.0/5000 (88%)\n",
      "bn: Loss: 1.1365\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.2085\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1047\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1319 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000059 drop: 0.000120 both: 0.000023\n",
      "Train Epoch: 1319 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000003 drop: 0.000010 both: 0.000007\n",
      "Train Epoch: 1319 [20000/25000 (80%)]\tLosses default: 0.000006 bn: 0.000061 drop: 0.000007 both: 0.000026\n",
      "Train Epoch: 1319 [25000/25000 (100%)]\tLosses default: 0.000034 bn: 0.000004 drop: 0.000021 both: 0.000239\n",
      "Test set:\n",
      "default: Loss: 1.1284\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.1032\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.2164\tAccuracy: 4367.0/5000 (87%)\n",
      "both: Loss: 1.1463\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1320 [0/25000 (0%)]\tLosses default: 0.000018 bn: 0.000053 drop: 0.000043 both: 0.000128\n",
      "Train Epoch: 1320 [10000/25000 (40%)]\tLosses default: 0.000037 bn: 0.000089 drop: 0.000028 both: 0.000069\n",
      "Train Epoch: 1320 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000001 drop: 0.000002 both: 0.077009\n",
      "Train Epoch: 1320 [25000/25000 (100%)]\tLosses default: 0.000165 bn: 0.000903 drop: 0.000004 both: 0.000031\n",
      "Test set:\n",
      "default: Loss: 1.1391\tAccuracy: 4411.0/5000 (88%)\n",
      "bn: Loss: 1.1380\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.2385\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.1110\tAccuracy: 4414.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1321 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000006 drop: 0.000017 both: 0.092455\n",
      "Train Epoch: 1321 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000001\n",
      "Train Epoch: 1321 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000000 both: 0.000086\n",
      "Train Epoch: 1321 [25000/25000 (100%)]\tLosses default: 0.000029 bn: 0.000045 drop: 0.000127 both: 0.000548\n",
      "Test set:\n",
      "default: Loss: 1.1489\tAccuracy: 4413.0/5000 (88%)\n",
      "bn: Loss: 1.1380\tAccuracy: 4406.0/5000 (88%)\n",
      "drop: Loss: 1.2191\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.1163\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1322 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000080 drop: 0.000010 both: 0.000015\n",
      "Train Epoch: 1322 [10000/25000 (40%)]\tLosses default: 0.000043 bn: 0.034510 drop: 0.000150 both: 0.000010\n",
      "Train Epoch: 1322 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000001 drop: 0.000007 both: 0.000106\n",
      "Train Epoch: 1322 [25000/25000 (100%)]\tLosses default: 0.000030 bn: 0.000010 drop: 0.000026 both: 0.000108\n",
      "Test set:\n",
      "default: Loss: 1.1584\tAccuracy: 4410.0/5000 (88%)\n",
      "bn: Loss: 1.1029\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.2253\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.1186\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1323 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.001839 drop: 0.000011 both: 0.000043\n",
      "Train Epoch: 1323 [10000/25000 (40%)]\tLosses default: 0.000023 bn: 0.000005 drop: 0.000033 both: 0.000006\n",
      "Train Epoch: 1323 [20000/25000 (80%)]\tLosses default: 0.000013 bn: 0.000000 drop: 0.000002 both: 0.000036\n",
      "Train Epoch: 1323 [25000/25000 (100%)]\tLosses default: 0.000013 bn: 0.000108 drop: 0.000002 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.1680\tAccuracy: 4410.0/5000 (88%)\n",
      "bn: Loss: 1.1043\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2198\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.1082\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1324 [0/25000 (0%)]\tLosses default: 0.000008 bn: 0.000002 drop: 0.000012 both: 0.000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1324 [10000/25000 (40%)]\tLosses default: 0.000012 bn: 0.000025 drop: 0.000004 both: 0.000004\n",
      "Train Epoch: 1324 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000006 both: 0.000102\n",
      "Train Epoch: 1324 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000011 drop: 0.000197 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1763\tAccuracy: 4408.0/5000 (88%)\n",
      "bn: Loss: 1.1163\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.2284\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.1143\tAccuracy: 4409.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1325 [0/25000 (0%)]\tLosses default: 0.000012 bn: 0.000003 drop: 0.000042 both: 0.000077\n",
      "Train Epoch: 1325 [10000/25000 (40%)]\tLosses default: 0.000021 bn: 0.000011 drop: 0.000007 both: 0.000014\n",
      "Train Epoch: 1325 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000055 drop: 0.000001 both: 0.000042\n",
      "Train Epoch: 1325 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000007 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.1859\tAccuracy: 4406.0/5000 (88%)\n",
      "bn: Loss: 1.1294\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.2192\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.1136\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1326 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000061 drop: 0.000000 both: 0.000030\n",
      "Train Epoch: 1326 [10000/25000 (40%)]\tLosses default: 0.000020 bn: 0.000337 drop: 0.000001 both: 0.000052\n",
      "Train Epoch: 1326 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000003 drop: 0.000009 both: 0.000074\n",
      "Train Epoch: 1326 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000094 drop: 0.000056 both: 0.000365\n",
      "Test set:\n",
      "default: Loss: 1.1941\tAccuracy: 4409.0/5000 (88%)\n",
      "bn: Loss: 1.1034\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.2200\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.1620\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1327 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000003 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1327 [10000/25000 (40%)]\tLosses default: 0.000015 bn: 0.000003 drop: 0.000001 both: 0.040827\n",
      "Train Epoch: 1327 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000021 both: 0.000009\n",
      "Train Epoch: 1327 [25000/25000 (100%)]\tLosses default: 0.000006 bn: 0.000003 drop: 0.000006 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2029\tAccuracy: 4412.0/5000 (88%)\n",
      "bn: Loss: 1.1122\tAccuracy: 4440.0/5000 (89%)\n",
      "drop: Loss: 1.2513\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.1417\tAccuracy: 4362.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1328 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.002519 both: 0.000012\n",
      "Train Epoch: 1328 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000003 drop: 0.000002 both: 0.000022\n",
      "Train Epoch: 1328 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000010 drop: 0.000014 both: 0.000018\n",
      "Train Epoch: 1328 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000002 both: 0.000278\n",
      "Test set:\n",
      "default: Loss: 1.2113\tAccuracy: 4413.0/5000 (88%)\n",
      "bn: Loss: 1.0908\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2472\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.1169\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1329 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000012 drop: 0.000001 both: 0.000011\n",
      "Train Epoch: 1329 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000001 drop: 0.000002 both: 0.000009\n",
      "Train Epoch: 1329 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.003424\n",
      "Train Epoch: 1329 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000002 both: 0.000828\n",
      "Test set:\n",
      "default: Loss: 1.2197\tAccuracy: 4412.0/5000 (88%)\n",
      "bn: Loss: 1.1133\tAccuracy: 4434.0/5000 (89%)\n",
      "drop: Loss: 1.2586\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.1194\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1330 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000022 drop: 0.000004 both: 0.000004\n",
      "Train Epoch: 1330 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000011 drop: 0.000656 both: 0.010943\n",
      "Train Epoch: 1330 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000036 drop: 0.000077 both: 0.000012\n",
      "Train Epoch: 1330 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000002 drop: 0.000102 both: 0.000033\n",
      "Test set:\n",
      "default: Loss: 1.2271\tAccuracy: 4407.0/5000 (88%)\n",
      "bn: Loss: 1.1257\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.2121\tAccuracy: 4367.0/5000 (87%)\n",
      "both: Loss: 1.1007\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1331 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.002593 drop: 0.000007 both: 0.000543\n",
      "Train Epoch: 1331 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000027 both: 0.002123\n",
      "Train Epoch: 1331 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.001965 drop: 0.003216 both: 0.000005\n",
      "Train Epoch: 1331 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000001 drop: 0.000003 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2345\tAccuracy: 4409.0/5000 (88%)\n",
      "bn: Loss: 1.1669\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.1657\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.1409\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1332 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000280 drop: 0.000005 both: 0.000002\n",
      "Train Epoch: 1332 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000011 drop: 0.000234 both: 0.000020\n",
      "Train Epoch: 1332 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000772 drop: 0.000013 both: 0.000029\n",
      "Train Epoch: 1332 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000019 drop: 0.000002 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2423\tAccuracy: 4408.0/5000 (88%)\n",
      "bn: Loss: 1.1574\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.1421\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.1093\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1333 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000912 drop: 0.000008 both: 0.000004\n",
      "Train Epoch: 1333 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000000 drop: 0.000011 both: 0.000026\n",
      "Train Epoch: 1333 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000001 drop: 0.000092 both: 0.000074\n",
      "Train Epoch: 1333 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000068 drop: 0.000003 both: 0.000808\n",
      "Test set:\n",
      "default: Loss: 1.2506\tAccuracy: 4409.0/5000 (88%)\n",
      "bn: Loss: 1.1520\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1698\tAccuracy: 4382.0/5000 (88%)\n",
      "both: Loss: 1.1279\tAccuracy: 4389.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1334 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000639 drop: 0.000027 both: 0.000047\n",
      "Train Epoch: 1334 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000009 both: 0.000011\n",
      "Train Epoch: 1334 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.000006 both: 0.000050\n",
      "Train Epoch: 1334 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000008 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2570\tAccuracy: 4408.0/5000 (88%)\n",
      "bn: Loss: 1.1329\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.1721\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.0896\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1335 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000066 both: 0.000598\n",
      "Train Epoch: 1335 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000006 both: 0.000094\n",
      "Train Epoch: 1335 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000015 drop: 0.000002 both: 0.000769\n",
      "Train Epoch: 1335 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000022 both: 0.000049\n",
      "Test set:\n",
      "default: Loss: 1.2646\tAccuracy: 4410.0/5000 (88%)\n",
      "bn: Loss: 1.1338\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.1699\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.1371\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1336 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000029 drop: 0.000002 both: 0.000014\n",
      "Train Epoch: 1336 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000190 both: 0.001134\n",
      "Train Epoch: 1336 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001127 drop: 0.000000 both: 0.000005\n",
      "Train Epoch: 1336 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000004 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.2705\tAccuracy: 4410.0/5000 (88%)\n",
      "bn: Loss: 1.1358\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.1817\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.1299\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1337 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.001323 drop: 0.000025 both: 0.000046\n",
      "Train Epoch: 1337 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000009\n",
      "Train Epoch: 1337 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000011 drop: 0.000198 both: 0.000215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1337 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000001 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.2769\tAccuracy: 4408.0/5000 (88%)\n",
      "bn: Loss: 1.1423\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.1756\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.1416\tAccuracy: 4368.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1338 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000011 both: 0.000608\n",
      "Train Epoch: 1338 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000000 both: 0.000139\n",
      "Train Epoch: 1338 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000126 drop: 0.000002 both: 0.000616\n",
      "Train Epoch: 1338 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.001125 drop: 0.000002 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2821\tAccuracy: 4411.0/5000 (88%)\n",
      "bn: Loss: 1.1173\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1766\tAccuracy: 4399.0/5000 (88%)\n",
      "both: Loss: 1.1355\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1339 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000039 drop: 0.000018 both: 0.000137\n",
      "Train Epoch: 1339 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000031 drop: 0.000025 both: 0.000097\n",
      "Train Epoch: 1339 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000390 both: 0.000673\n",
      "Train Epoch: 1339 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.177188 drop: 0.000004 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 1.2878\tAccuracy: 4409.0/5000 (88%)\n",
      "bn: Loss: 1.1722\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.1972\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.1431\tAccuracy: 4367.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1340 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000001 both: 0.000059\n",
      "Train Epoch: 1340 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001058 drop: 0.000002 both: 0.000006\n",
      "Train Epoch: 1340 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000001 both: 0.000011\n",
      "Train Epoch: 1340 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000005 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2938\tAccuracy: 4408.0/5000 (88%)\n",
      "bn: Loss: 1.1199\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.1870\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.1072\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1341 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000205 drop: 0.000006 both: 0.000839\n",
      "Train Epoch: 1341 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000688 drop: 0.000002 both: 0.000601\n",
      "Train Epoch: 1341 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000005 both: 0.000096\n",
      "Train Epoch: 1341 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000014 both: 0.000034\n",
      "Test set:\n",
      "default: Loss: 1.2998\tAccuracy: 4412.0/5000 (88%)\n",
      "bn: Loss: 1.1174\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.1725\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.1186\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1342 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000014 both: 0.000675\n",
      "Train Epoch: 1342 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000045 drop: 0.000017 both: 0.000091\n",
      "Train Epoch: 1342 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000012 drop: 0.000002 both: 0.000012\n",
      "Train Epoch: 1342 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000087\n",
      "Test set:\n",
      "default: Loss: 1.3047\tAccuracy: 4411.0/5000 (88%)\n",
      "bn: Loss: 1.1237\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.1946\tAccuracy: 4398.0/5000 (88%)\n",
      "both: Loss: 1.1017\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1343 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000008\n",
      "Train Epoch: 1343 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000976 drop: 0.000004 both: 0.000017\n",
      "Train Epoch: 1343 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000126 drop: 0.000002 both: 0.000003\n",
      "Train Epoch: 1343 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000002 both: 0.000093\n",
      "Test set:\n",
      "default: Loss: 1.3103\tAccuracy: 4412.0/5000 (88%)\n",
      "bn: Loss: 1.1205\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.2193\tAccuracy: 4401.0/5000 (88%)\n",
      "both: Loss: 1.1240\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1344 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000002 both: 0.000043\n",
      "Train Epoch: 1344 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000001 both: 0.000057\n",
      "Train Epoch: 1344 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000003 both: 0.000010\n",
      "Train Epoch: 1344 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000002 both: 0.000042\n",
      "Test set:\n",
      "default: Loss: 1.3152\tAccuracy: 4414.0/5000 (88%)\n",
      "bn: Loss: 1.1354\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.1945\tAccuracy: 4403.0/5000 (88%)\n",
      "both: Loss: 1.0767\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1345 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000050 both: 0.000008\n",
      "Train Epoch: 1345 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000013 both: 0.000046\n",
      "Train Epoch: 1345 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000037 drop: 0.000005 both: 0.000003\n",
      "Train Epoch: 1345 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000007 both: 0.000051\n",
      "Test set:\n",
      "default: Loss: 1.3217\tAccuracy: 4408.0/5000 (88%)\n",
      "bn: Loss: 1.1269\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.2240\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0795\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1346 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000155 drop: 0.000005 both: 0.000019\n",
      "Train Epoch: 1346 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000084 drop: 0.000007 both: 0.000057\n",
      "Train Epoch: 1346 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.014991 drop: 0.000002 both: 0.000058\n",
      "Train Epoch: 1346 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000007 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 1.3256\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.1197\tAccuracy: 4439.0/5000 (89%)\n",
      "drop: Loss: 1.2225\tAccuracy: 4400.0/5000 (88%)\n",
      "both: Loss: 1.1229\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1347 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000059\n",
      "Train Epoch: 1347 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001520 drop: 0.000000 both: 0.000017\n",
      "Train Epoch: 1347 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000005 both: 0.000008\n",
      "Train Epoch: 1347 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000061 drop: 0.000001 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.3316\tAccuracy: 4413.0/5000 (88%)\n",
      "bn: Loss: 1.1479\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.2310\tAccuracy: 4397.0/5000 (88%)\n",
      "both: Loss: 1.0785\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1348 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000001 both: 0.000015\n",
      "Train Epoch: 1348 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000261 both: 0.000052\n",
      "Train Epoch: 1348 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000038 both: 0.000020\n",
      "Train Epoch: 1348 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.3354\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.1142\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.2430\tAccuracy: 4361.0/5000 (87%)\n",
      "both: Loss: 1.1071\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1349 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000161 both: 0.000028\n",
      "Train Epoch: 1349 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000055 both: 0.000025\n",
      "Train Epoch: 1349 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000255 drop: 0.000009 both: 0.001103\n",
      "Train Epoch: 1349 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000004 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3415\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.1522\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.1921\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0650\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1350 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000003 both: 0.000522\n",
      "Train Epoch: 1350 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000017 both: 0.000023\n",
      "Train Epoch: 1350 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000062 drop: 0.000002 both: 0.000070\n",
      "Train Epoch: 1350 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000003 both: 0.000028\n",
      "Test set:\n",
      "default: Loss: 1.3429\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.1417\tAccuracy: 4444.0/5000 (89%)\n",
      "drop: Loss: 1.2233\tAccuracy: 4368.0/5000 (87%)\n",
      "both: Loss: 1.0900\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1351 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000016 both: 0.000023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1351 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000059 drop: 0.000002 both: 0.000014\n",
      "Train Epoch: 1351 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000068 both: 0.000018\n",
      "Train Epoch: 1351 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000006 both: 0.000075\n",
      "Test set:\n",
      "default: Loss: 1.3493\tAccuracy: 4421.0/5000 (88%)\n",
      "bn: Loss: 1.1354\tAccuracy: 4410.0/5000 (88%)\n",
      "drop: Loss: 1.2075\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.0767\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1352 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000038 both: 0.000453\n",
      "Train Epoch: 1352 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000005 both: 0.000004\n",
      "Train Epoch: 1352 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000081\n",
      "Train Epoch: 1352 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000020 drop: 0.000024 both: 0.000306\n",
      "Test set:\n",
      "default: Loss: 1.3528\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1165\tAccuracy: 4435.0/5000 (89%)\n",
      "drop: Loss: 1.2056\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.1258\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1353 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000002 both: 0.000002\n",
      "Train Epoch: 1353 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000009 both: 0.000005\n",
      "Train Epoch: 1353 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000402 drop: 0.000027 both: 0.000104\n",
      "Train Epoch: 1353 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000296 drop: 0.000001 both: 0.000035\n",
      "Test set:\n",
      "default: Loss: 1.3570\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1200\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2174\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.1282\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1354 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000017 both: 0.000008\n",
      "Train Epoch: 1354 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000025 both: 0.000019\n",
      "Train Epoch: 1354 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.032583 drop: 0.000037 both: 0.000090\n",
      "Train Epoch: 1354 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000417 drop: 0.004140 both: 0.000119\n",
      "Test set:\n",
      "default: Loss: 1.3605\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1617\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.2435\tAccuracy: 4359.0/5000 (87%)\n",
      "both: Loss: 1.0880\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1355 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000008 both: 0.000003\n",
      "Train Epoch: 1355 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.013805 both: 0.000676\n",
      "Train Epoch: 1355 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.019245 drop: 0.000011 both: 0.000089\n",
      "Train Epoch: 1355 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000084 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.3618\tAccuracy: 4428.0/5000 (89%)\n",
      "bn: Loss: 1.1673\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.2097\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.0919\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1356 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000153 drop: 0.000020 both: 0.000035\n",
      "Train Epoch: 1356 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000033 drop: 0.000036 both: 0.000005\n",
      "Train Epoch: 1356 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000010 both: 0.000013\n",
      "Train Epoch: 1356 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000004 both: 0.000051\n",
      "Test set:\n",
      "default: Loss: 1.3651\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1117\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.2051\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0835\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1357 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000116 both: 0.000079\n",
      "Train Epoch: 1357 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000006 both: 0.009137\n",
      "Train Epoch: 1357 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.004946 drop: 0.000013 both: 0.000015\n",
      "Train Epoch: 1357 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000060 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.3661\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0897\tAccuracy: 4437.0/5000 (89%)\n",
      "drop: Loss: 1.2071\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.1139\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1358 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000011 both: 0.000102\n",
      "Train Epoch: 1358 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000009 both: 0.000019\n",
      "Train Epoch: 1358 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000011 both: 0.000012\n",
      "Train Epoch: 1358 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.001915 drop: 0.000003 both: 0.000032\n",
      "Test set:\n",
      "default: Loss: 1.3658\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1144\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.1977\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0876\tAccuracy: 4410.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1359 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000019 both: 0.000126\n",
      "Train Epoch: 1359 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.039788 drop: 0.000000 both: 0.000183\n",
      "Train Epoch: 1359 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001153 drop: 0.000001 both: 0.000041\n",
      "Train Epoch: 1359 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000000 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3625\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0812\tAccuracy: 4436.0/5000 (89%)\n",
      "drop: Loss: 1.2006\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0741\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1360 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000007 both: 0.000016\n",
      "Train Epoch: 1360 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000100 both: 0.000077\n",
      "Train Epoch: 1360 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000030 drop: 0.000027 both: 0.000478\n",
      "Train Epoch: 1360 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000003 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.3634\tAccuracy: 4431.0/5000 (89%)\n",
      "bn: Loss: 1.0857\tAccuracy: 4448.0/5000 (89%)\n",
      "drop: Loss: 1.2046\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0765\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1361 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000024 both: 0.000046\n",
      "Train Epoch: 1361 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000002 both: 0.000007\n",
      "Train Epoch: 1361 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000074 both: 0.000002\n",
      "Train Epoch: 1361 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3600\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1181\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.1956\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0734\tAccuracy: 4418.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1362 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000066 both: 0.000011\n",
      "Train Epoch: 1362 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000001 both: 0.000124\n",
      "Train Epoch: 1362 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000002 both: 0.000044\n",
      "Train Epoch: 1362 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000004 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.3584\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1455\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2364\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.1003\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1363 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000293 drop: 0.000141 both: 0.000034\n",
      "Train Epoch: 1363 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.004721 drop: 0.000004 both: 0.000167\n",
      "Train Epoch: 1363 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000002 both: 0.000003\n",
      "Train Epoch: 1363 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.005274 drop: 0.000003 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.3618\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1289\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.2080\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.0842\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1364 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.005306 drop: 0.000000 both: 0.000031\n",
      "Train Epoch: 1364 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000001 both: 0.002750\n",
      "Train Epoch: 1364 [20000/25000 (80%)]\tLosses default: 0.026016 bn: 0.000118 drop: 0.000015 both: 0.000293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1364 [25000/25000 (100%)]\tLosses default: 0.000098 bn: 0.000003 drop: 0.000002 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 0.9972\tAccuracy: 4383.0/5000 (88%)\n",
      "bn: Loss: 1.1106\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.2077\tAccuracy: 4393.0/5000 (88%)\n",
      "both: Loss: 1.1595\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1365 [0/25000 (0%)]\tLosses default: 0.025187 bn: 0.000063 drop: 0.000007 both: 0.000162\n",
      "Train Epoch: 1365 [10000/25000 (40%)]\tLosses default: 0.000152 bn: 0.000004 drop: 0.000010 both: 0.000027\n",
      "Train Epoch: 1365 [20000/25000 (80%)]\tLosses default: 0.000035 bn: 0.000014 drop: 0.000001 both: 0.000042\n",
      "Train Epoch: 1365 [25000/25000 (100%)]\tLosses default: 0.001047 bn: 0.000005 drop: 0.000003 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 0.9454\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1177\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.2201\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0771\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1366 [0/25000 (0%)]\tLosses default: 0.000004 bn: 0.000253 drop: 0.000006 both: 0.000006\n",
      "Train Epoch: 1366 [10000/25000 (40%)]\tLosses default: 0.000103 bn: 0.000011 drop: 0.000000 both: 0.000036\n",
      "Train Epoch: 1366 [20000/25000 (80%)]\tLosses default: 0.000016 bn: 0.000037 drop: 0.000001 both: 0.000008\n",
      "Train Epoch: 1366 [25000/25000 (100%)]\tLosses default: 0.000071 bn: 0.000008 drop: 0.000009 both: 0.000017\n",
      "Test set:\n",
      "default: Loss: 0.9640\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.0953\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2147\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.0596\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1367 [0/25000 (0%)]\tLosses default: 0.000141 bn: 0.000007 drop: 0.000004 both: 0.000004\n",
      "Train Epoch: 1367 [10000/25000 (40%)]\tLosses default: 0.000128 bn: 0.000000 drop: 0.000001 both: 0.000049\n",
      "Train Epoch: 1367 [20000/25000 (80%)]\tLosses default: 0.000201 bn: 0.000009 drop: 0.000004 both: 0.000065\n",
      "Train Epoch: 1367 [25000/25000 (100%)]\tLosses default: 0.000056 bn: 0.000000 drop: 0.000000 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 0.9796\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1297\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.2255\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.0833\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1368 [0/25000 (0%)]\tLosses default: 0.000085 bn: 0.000186 drop: 0.000001 both: 0.000067\n",
      "Train Epoch: 1368 [10000/25000 (40%)]\tLosses default: 0.000013 bn: 0.000035 drop: 0.000001 both: 0.000028\n",
      "Train Epoch: 1368 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000708 drop: 0.000000 both: 0.000006\n",
      "Train Epoch: 1368 [25000/25000 (100%)]\tLosses default: 0.000160 bn: 0.000019 drop: 0.000001 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 0.9955\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1391\tAccuracy: 4403.0/5000 (88%)\n",
      "drop: Loss: 1.2441\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1183\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1369 [0/25000 (0%)]\tLosses default: 0.000021 bn: 0.000047 drop: 0.000000 both: 0.000043\n",
      "Train Epoch: 1369 [10000/25000 (40%)]\tLosses default: 0.000088 bn: 0.000001 drop: 0.000001 both: 0.000238\n",
      "Train Epoch: 1369 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000175 drop: 0.000001 both: 0.000003\n",
      "Train Epoch: 1369 [25000/25000 (100%)]\tLosses default: 0.000113 bn: 0.000024 drop: 0.000000 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.0112\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1418\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 1.2300\tAccuracy: 4395.0/5000 (88%)\n",
      "both: Loss: 1.0563\tAccuracy: 4395.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1370 [0/25000 (0%)]\tLosses default: 0.000056 bn: 0.000197 drop: 0.000001 both: 0.000012\n",
      "Train Epoch: 1370 [10000/25000 (40%)]\tLosses default: 0.000155 bn: 0.000005 drop: 0.000005 both: 0.000144\n",
      "Train Epoch: 1370 [20000/25000 (80%)]\tLosses default: 0.000064 bn: 0.000005 drop: 0.000004 both: 0.000008\n",
      "Train Epoch: 1370 [25000/25000 (100%)]\tLosses default: 0.000087 bn: 0.000011 drop: 0.000002 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.0266\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1174\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.2611\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0869\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1371 [0/25000 (0%)]\tLosses default: 0.000040 bn: 0.001272 drop: 0.000001 both: 0.000094\n",
      "Train Epoch: 1371 [10000/25000 (40%)]\tLosses default: 0.000011 bn: 0.000004 drop: 0.000001 both: 0.000051\n",
      "Train Epoch: 1371 [20000/25000 (80%)]\tLosses default: 0.000014 bn: 0.000157 drop: 0.000013 both: 0.000004\n",
      "Train Epoch: 1371 [25000/25000 (100%)]\tLosses default: 0.000054 bn: 0.000009 drop: 0.000002 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.0420\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1010\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.2451\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.1101\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1372 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000023 drop: 0.000000 both: 0.000002\n",
      "Train Epoch: 1372 [10000/25000 (40%)]\tLosses default: 0.000060 bn: 0.000004 drop: 0.000010 both: 0.000002\n",
      "Train Epoch: 1372 [20000/25000 (80%)]\tLosses default: 0.000022 bn: 0.000001 drop: 0.000000 both: 0.000013\n",
      "Train Epoch: 1372 [25000/25000 (100%)]\tLosses default: 0.000024 bn: 0.000000 drop: 0.078546 both: 0.000036\n",
      "Test set:\n",
      "default: Loss: 1.0564\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1335\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.3024\tAccuracy: 4370.0/5000 (87%)\n",
      "both: Loss: 1.1115\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1373 [0/25000 (0%)]\tLosses default: 0.000020 bn: 0.000014 drop: 0.000081 both: 0.000011\n",
      "Train Epoch: 1373 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000053 drop: 0.000016 both: 0.000005\n",
      "Train Epoch: 1373 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000019 drop: 0.001654 both: 0.000024\n",
      "Train Epoch: 1373 [25000/25000 (100%)]\tLosses default: 0.000005 bn: 0.001846 drop: 0.000025 both: 0.000042\n",
      "Test set:\n",
      "default: Loss: 1.0721\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1194\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.2635\tAccuracy: 4367.0/5000 (87%)\n",
      "both: Loss: 1.1026\tAccuracy: 4394.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1374 [0/25000 (0%)]\tLosses default: 0.000026 bn: 0.000023 drop: 0.000096 both: 0.000509\n",
      "Train Epoch: 1374 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000028 drop: 0.000001 both: 0.000040\n",
      "Train Epoch: 1374 [20000/25000 (80%)]\tLosses default: 0.000022 bn: 0.000053 drop: 0.000017 both: 0.000005\n",
      "Train Epoch: 1374 [25000/25000 (100%)]\tLosses default: 0.000012 bn: 0.000545 drop: 0.000093 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.0866\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1151\tAccuracy: 4398.0/5000 (88%)\n",
      "drop: Loss: 1.2363\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0716\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1375 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.047269 drop: 0.000039 both: 0.000165\n",
      "Train Epoch: 1375 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000000 drop: 0.000010 both: 0.016034\n",
      "Train Epoch: 1375 [20000/25000 (80%)]\tLosses default: 0.000004 bn: 0.000018 drop: 0.000003 both: 0.000167\n",
      "Train Epoch: 1375 [25000/25000 (100%)]\tLosses default: 0.000008 bn: 0.000002 drop: 0.000009 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.1007\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1118\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2357\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.1243\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1376 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.001214 drop: 0.000002 both: 0.000021\n",
      "Train Epoch: 1376 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000557 drop: 0.000007 both: 0.000191\n",
      "Train Epoch: 1376 [20000/25000 (80%)]\tLosses default: 0.000042 bn: 0.000375 drop: 0.000011 both: 0.000086\n",
      "Train Epoch: 1376 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.001847 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.1152\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1200\tAccuracy: 4407.0/5000 (88%)\n",
      "drop: Loss: 1.2222\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.0968\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1377 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000000 both: 0.000009\n",
      "Train Epoch: 1377 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.089865 drop: 0.000009 both: 0.000157\n",
      "Train Epoch: 1377 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000004 both: 0.000400\n",
      "Train Epoch: 1377 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000000 drop: 0.000004 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.1284\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1286\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.2404\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.1088\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1378 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000316 drop: 0.000002 both: 0.000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1378 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000001 drop: 0.000001 both: 0.000016\n",
      "Train Epoch: 1378 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000011 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 1378 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.003511 drop: 0.000022 both: 0.070582\n",
      "Test set:\n",
      "default: Loss: 1.1421\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1328\tAccuracy: 4404.0/5000 (88%)\n",
      "drop: Loss: 1.2360\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.1025\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1379 [0/25000 (0%)]\tLosses default: 0.000016 bn: 0.000004 drop: 0.000003 both: 0.000007\n",
      "Train Epoch: 1379 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000012 drop: 0.000000 both: 0.000311\n",
      "Train Epoch: 1379 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.000002 both: 0.000017\n",
      "Train Epoch: 1379 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000052 drop: 0.000033 both: 0.000146\n",
      "Test set:\n",
      "default: Loss: 1.1555\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0946\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.2957\tAccuracy: 4361.0/5000 (87%)\n",
      "both: Loss: 1.0877\tAccuracy: 4380.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1380 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.000072 both: 0.000333\n",
      "Train Epoch: 1380 [10000/25000 (40%)]\tLosses default: 0.000009 bn: 0.003871 drop: 0.015499 both: 0.000016\n",
      "Train Epoch: 1380 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000217 both: 0.000028\n",
      "Train Epoch: 1380 [25000/25000 (100%)]\tLosses default: 0.000003 bn: 0.000003 drop: 0.000012 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.1682\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1272\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2160\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.1227\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1381 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000146 both: 0.000002\n",
      "Train Epoch: 1381 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.005096 drop: 0.000001 both: 0.001317\n",
      "Train Epoch: 1381 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001032 drop: 0.000134 both: 0.000023\n",
      "Train Epoch: 1381 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000014 drop: 0.000118 both: 0.000095\n",
      "Test set:\n",
      "default: Loss: 1.1803\tAccuracy: 4434.0/5000 (89%)\n",
      "bn: Loss: 1.1214\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.1739\tAccuracy: 4372.0/5000 (87%)\n",
      "both: Loss: 1.1251\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1382 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000002 both: 0.000013\n",
      "Train Epoch: 1382 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000001 drop: 0.000021 both: 0.000106\n",
      "Train Epoch: 1382 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000064 drop: 0.000006 both: 0.000021\n",
      "Train Epoch: 1382 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000057 both: 0.000006\n",
      "Test set:\n",
      "default: Loss: 1.1924\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1240\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.1971\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1219\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1383 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000040 drop: 0.000005 both: 0.000031\n",
      "Train Epoch: 1383 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000010 drop: 0.000001 both: 0.005840\n",
      "Train Epoch: 1383 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000162 drop: 0.000056 both: 0.000617\n",
      "Train Epoch: 1383 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.142101 drop: 0.000034 both: 0.006587\n",
      "Test set:\n",
      "default: Loss: 1.2038\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1541\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.1867\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.1267\tAccuracy: 4390.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1384 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000073 drop: 0.000006 both: 0.000155\n",
      "Train Epoch: 1384 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000003 both: 0.014470\n",
      "Train Epoch: 1384 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000715 drop: 0.000010 both: 0.000010\n",
      "Train Epoch: 1384 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000141 drop: 0.000001 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.2147\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.1467\tAccuracy: 4405.0/5000 (88%)\n",
      "drop: Loss: 1.2064\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.1189\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1385 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000001 both: 0.000607\n",
      "Train Epoch: 1385 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000030 drop: 0.000005 both: 0.000122\n",
      "Train Epoch: 1385 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000008 both: 0.000270\n",
      "Train Epoch: 1385 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000045 drop: 0.000006 both: 0.000028\n",
      "Test set:\n",
      "default: Loss: 1.2257\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0832\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.1954\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.1175\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1386 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000078 both: 0.000010\n",
      "Train Epoch: 1386 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000045 both: 0.000026\n",
      "Train Epoch: 1386 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000009 both: 0.000007\n",
      "Train Epoch: 1386 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000002 drop: 0.000000 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 1.2360\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.0650\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.2015\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.1061\tAccuracy: 4376.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1387 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000024 drop: 0.000030 both: 0.000615\n",
      "Train Epoch: 1387 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000006 drop: 0.000003 both: 0.000156\n",
      "Train Epoch: 1387 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000076 drop: 0.000005 both: 0.000061\n",
      "Train Epoch: 1387 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000019 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2452\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1234\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.2120\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.0844\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1388 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000064 drop: 0.000004 both: 0.000013\n",
      "Train Epoch: 1388 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000088\n",
      "Train Epoch: 1388 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000009 both: 0.000017\n",
      "Train Epoch: 1388 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000250 drop: 0.000003 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2546\tAccuracy: 4432.0/5000 (89%)\n",
      "bn: Loss: 1.1242\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.2150\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0921\tAccuracy: 4401.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1389 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000344 drop: 0.000000 both: 0.000015\n",
      "Train Epoch: 1389 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000091 both: 0.000016\n",
      "Train Epoch: 1389 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000045 drop: 0.000000 both: 0.000017\n",
      "Train Epoch: 1389 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000036 drop: 0.000001 both: 0.105214\n",
      "Test set:\n",
      "default: Loss: 1.2639\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1082\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.2033\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.1137\tAccuracy: 4371.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1390 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000102 drop: 0.000008 both: 0.046718\n",
      "Train Epoch: 1390 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000003 both: 0.000332\n",
      "Train Epoch: 1390 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.011262 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 1390 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000250 both: 0.000019\n",
      "Test set:\n",
      "default: Loss: 1.2731\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1018\tAccuracy: 4432.0/5000 (89%)\n",
      "drop: Loss: 1.2141\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1077\tAccuracy: 4383.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1391 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000007\n",
      "Train Epoch: 1391 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000003 both: 0.000006\n",
      "Train Epoch: 1391 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000009 both: 0.000038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1391 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000003 both: 0.000086\n",
      "Test set:\n",
      "default: Loss: 1.2806\tAccuracy: 4435.0/5000 (89%)\n",
      "bn: Loss: 1.1207\tAccuracy: 4423.0/5000 (88%)\n",
      "drop: Loss: 1.2132\tAccuracy: 4374.0/5000 (87%)\n",
      "both: Loss: 1.1077\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1392 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000000 both: 0.000035\n",
      "Train Epoch: 1392 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000115 drop: 0.000003 both: 0.000027\n",
      "Train Epoch: 1392 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000148 drop: 0.000000 both: 0.000005\n",
      "Train Epoch: 1392 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000434 drop: 0.000000 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.2878\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1436\tAccuracy: 4397.0/5000 (88%)\n",
      "drop: Loss: 1.2223\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.0986\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1393 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000002 both: 0.000005\n",
      "Train Epoch: 1393 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000037 both: 0.000005\n",
      "Train Epoch: 1393 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000149 drop: 0.000002 both: 0.000804\n",
      "Train Epoch: 1393 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000049 both: 0.000147\n",
      "Test set:\n",
      "default: Loss: 1.2966\tAccuracy: 4437.0/5000 (89%)\n",
      "bn: Loss: 1.1079\tAccuracy: 4408.0/5000 (88%)\n",
      "drop: Loss: 1.2447\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.1002\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1394 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000006 both: 0.000003\n",
      "Train Epoch: 1394 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.002529 drop: 0.000008 both: 0.000308\n",
      "Train Epoch: 1394 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000026 drop: 0.000012 both: 0.000019\n",
      "Train Epoch: 1394 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000032 drop: 0.000001 both: 0.000010\n",
      "Test set:\n",
      "default: Loss: 1.3041\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.0934\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2304\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0884\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1395 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000022\n",
      "Train Epoch: 1395 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000040\n",
      "Train Epoch: 1395 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000001 both: 0.000007\n",
      "Train Epoch: 1395 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000050 both: 0.000015\n",
      "Test set:\n",
      "default: Loss: 1.3104\tAccuracy: 4436.0/5000 (89%)\n",
      "bn: Loss: 1.0999\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.2449\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1073\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1396 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 1396 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.000002 both: 0.000051\n",
      "Train Epoch: 1396 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.004720 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1396 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000082\n",
      "Test set:\n",
      "default: Loss: 1.3168\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1654\tAccuracy: 4393.0/5000 (88%)\n",
      "drop: Loss: 1.2354\tAccuracy: 4394.0/5000 (88%)\n",
      "both: Loss: 1.1013\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1397 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000498 drop: 0.000001 both: 0.000245\n",
      "Train Epoch: 1397 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000014\n",
      "Train Epoch: 1397 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000017\n",
      "Train Epoch: 1397 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000002 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.3227\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0952\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.2423\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1250\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1398 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000000 both: 0.000015\n",
      "Train Epoch: 1398 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000003 both: 0.000015\n",
      "Train Epoch: 1398 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000022 drop: 0.000001 both: 0.000012\n",
      "Train Epoch: 1398 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000001 both: 0.000027\n",
      "Test set:\n",
      "default: Loss: 1.3290\tAccuracy: 4439.0/5000 (89%)\n",
      "bn: Loss: 1.0856\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.2690\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.0821\tAccuracy: 4386.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1399 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000184 drop: 0.000000 both: 0.000013\n",
      "Train Epoch: 1399 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000177 drop: 0.000007 both: 0.000013\n",
      "Train Epoch: 1399 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000147 drop: 0.000002 both: 0.000179\n",
      "Train Epoch: 1399 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000061\n",
      "Test set:\n",
      "default: Loss: 1.3347\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.1004\tAccuracy: 4446.0/5000 (89%)\n",
      "drop: Loss: 1.2824\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1285\tAccuracy: 4382.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1400 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000000 both: 0.000004\n",
      "Train Epoch: 1400 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000019 drop: 0.000000 both: 0.000004\n",
      "Train Epoch: 1400 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000021 drop: 0.000000 both: 0.000014\n",
      "Train Epoch: 1400 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000001 both: 0.000188\n",
      "Test set:\n",
      "default: Loss: 1.3404\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.1441\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2766\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.1055\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1401 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000223 drop: 0.000007 both: 0.014773\n",
      "Train Epoch: 1401 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.001100 drop: 0.000000 both: 0.000145\n",
      "Train Epoch: 1401 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000009 both: 0.000002\n",
      "Train Epoch: 1401 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000135 drop: 0.000002 both: 0.000022\n",
      "Test set:\n",
      "default: Loss: 1.3440\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.1185\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.2888\tAccuracy: 4388.0/5000 (88%)\n",
      "both: Loss: 1.1472\tAccuracy: 4358.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1402 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 1402 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000180 drop: 0.000000 both: 0.000018\n",
      "Train Epoch: 1402 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000064 drop: 0.000001 both: 0.000013\n",
      "Train Epoch: 1402 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000040 drop: 0.000001 both: 0.000249\n",
      "Test set:\n",
      "default: Loss: 1.3485\tAccuracy: 4444.0/5000 (89%)\n",
      "bn: Loss: 1.1443\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2970\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1152\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1403 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000000 both: 0.000072\n",
      "Train Epoch: 1403 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000047 drop: 0.000001 both: 0.000038\n",
      "Train Epoch: 1403 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000003 both: 0.000002\n",
      "Train Epoch: 1403 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000000 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3525\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.1129\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.3097\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.0968\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1404 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000000 both: 0.000015\n",
      "Train Epoch: 1404 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000053\n",
      "Train Epoch: 1404 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000376 drop: 0.000012 both: 0.000014\n",
      "Train Epoch: 1404 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.015031 drop: 0.000008 both: 0.000044\n",
      "Test set:\n",
      "default: Loss: 1.3557\tAccuracy: 4438.0/5000 (89%)\n",
      "bn: Loss: 1.1431\tAccuracy: 4399.0/5000 (88%)\n",
      "drop: Loss: 1.3065\tAccuracy: 4364.0/5000 (87%)\n",
      "both: Loss: 1.1277\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1405 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.016210 both: 0.017676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1405 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000005\n",
      "Train Epoch: 1405 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.002246 drop: 0.000028 both: 0.000011\n",
      "Train Epoch: 1405 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000010 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3578\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.1539\tAccuracy: 4401.0/5000 (88%)\n",
      "drop: Loss: 1.2647\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.1038\tAccuracy: 4406.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1406 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.105766 drop: 0.000024 both: 0.000034\n",
      "Train Epoch: 1406 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000823 drop: 0.000710 both: 0.000331\n",
      "Train Epoch: 1406 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000002\n",
      "Train Epoch: 1406 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000010 drop: 0.000001 both: 0.000026\n",
      "Test set:\n",
      "default: Loss: 1.3591\tAccuracy: 4443.0/5000 (89%)\n",
      "bn: Loss: 1.1285\tAccuracy: 4416.0/5000 (88%)\n",
      "drop: Loss: 1.3276\tAccuracy: 4342.0/5000 (87%)\n",
      "both: Loss: 1.0909\tAccuracy: 4378.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1407 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000013 drop: 0.000175 both: 0.000023\n",
      "Train Epoch: 1407 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000004 both: 0.000002\n",
      "Train Epoch: 1407 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000093 drop: 0.000003 both: 0.000021\n",
      "Train Epoch: 1407 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000018 drop: 0.000001 both: 0.000024\n",
      "Test set:\n",
      "default: Loss: 1.3613\tAccuracy: 4440.0/5000 (89%)\n",
      "bn: Loss: 1.1054\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.2851\tAccuracy: 4358.0/5000 (87%)\n",
      "both: Loss: 1.1361\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1408 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000005 both: 0.000061\n",
      "Train Epoch: 1408 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000016 drop: 0.000079 both: 0.000026\n",
      "Train Epoch: 1408 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000008 both: 0.000039\n",
      "Train Epoch: 1408 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000006 both: 0.000190\n",
      "Test set:\n",
      "default: Loss: 1.3607\tAccuracy: 4441.0/5000 (89%)\n",
      "bn: Loss: 1.0997\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2775\tAccuracy: 4366.0/5000 (87%)\n",
      "both: Loss: 1.0915\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1409 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000363 drop: 0.000006 both: 0.000040\n",
      "Train Epoch: 1409 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000001 both: 0.000006\n",
      "Train Epoch: 1409 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000021 both: 0.000275\n",
      "Train Epoch: 1409 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000077 both: 0.000094\n",
      "Test set:\n",
      "default: Loss: 1.3598\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.1278\tAccuracy: 4402.0/5000 (88%)\n",
      "drop: Loss: 1.2935\tAccuracy: 4367.0/5000 (87%)\n",
      "both: Loss: 1.0881\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1410 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000274 both: 0.000012\n",
      "Train Epoch: 1410 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000056 drop: 0.000069 both: 0.000072\n",
      "Train Epoch: 1410 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000001 both: 0.000042\n",
      "Train Epoch: 1410 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000001 both: 0.000038\n",
      "Test set:\n",
      "default: Loss: 1.3585\tAccuracy: 4442.0/5000 (89%)\n",
      "bn: Loss: 1.1077\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.2939\tAccuracy: 4366.0/5000 (87%)\n",
      "both: Loss: 1.0694\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1411 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000003 both: 0.000005\n",
      "Train Epoch: 1411 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000002 both: 0.000004\n",
      "Train Epoch: 1411 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000001 both: 0.000025\n",
      "Train Epoch: 1411 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000013 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.3572\tAccuracy: 4445.0/5000 (89%)\n",
      "bn: Loss: 1.1108\tAccuracy: 4421.0/5000 (88%)\n",
      "drop: Loss: 1.2880\tAccuracy: 4379.0/5000 (88%)\n",
      "both: Loss: 1.0800\tAccuracy: 4407.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1412 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000004 both: 0.000003\n",
      "Train Epoch: 1412 [10000/25000 (40%)]\tLosses default: 0.003750 bn: 0.000006 drop: 0.000001 both: 0.000049\n",
      "Train Epoch: 1412 [20000/25000 (80%)]\tLosses default: 0.044962 bn: 0.000002 drop: 0.000009 both: 0.000009\n",
      "Train Epoch: 1412 [25000/25000 (100%)]\tLosses default: 0.000102 bn: 0.000294 drop: 0.000001 both: 0.000066\n",
      "Test set:\n",
      "default: Loss: 1.1492\tAccuracy: 4402.0/5000 (88%)\n",
      "bn: Loss: 1.1140\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.2653\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0904\tAccuracy: 4396.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1413 [0/25000 (0%)]\tLosses default: 0.000018 bn: 0.000042 drop: 0.000002 both: 0.000075\n",
      "Train Epoch: 1413 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000031 both: 0.001820\n",
      "Train Epoch: 1413 [20000/25000 (80%)]\tLosses default: 0.000078 bn: 0.000007 drop: 0.000002 both: 0.000048\n",
      "Train Epoch: 1413 [25000/25000 (100%)]\tLosses default: 0.001710 bn: 0.000001 drop: 0.000003 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.1477\tAccuracy: 4404.0/5000 (88%)\n",
      "bn: Loss: 1.1269\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.2879\tAccuracy: 4376.0/5000 (88%)\n",
      "both: Loss: 1.0809\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1414 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000092 drop: 0.000025 both: 0.000005\n",
      "Train Epoch: 1414 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000260 drop: 0.000003 both: 0.000008\n",
      "Train Epoch: 1414 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000178 drop: 0.000001 both: 0.000118\n",
      "Train Epoch: 1414 [25000/25000 (100%)]\tLosses default: 0.000380 bn: 0.000015 drop: 0.000029 both: 0.000021\n",
      "Test set:\n",
      "default: Loss: 1.1569\tAccuracy: 4408.0/5000 (88%)\n",
      "bn: Loss: 1.1229\tAccuracy: 4411.0/5000 (88%)\n",
      "drop: Loss: 1.2944\tAccuracy: 4372.0/5000 (87%)\n",
      "both: Loss: 1.1047\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1415 [0/25000 (0%)]\tLosses default: 0.000150 bn: 0.000021 drop: 0.000016 both: 0.000724\n",
      "Train Epoch: 1415 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000078 drop: 0.000001 both: 0.000007\n",
      "Train Epoch: 1415 [20000/25000 (80%)]\tLosses default: 0.000032 bn: 0.000003 drop: 0.000001 both: 0.000006\n",
      "Train Epoch: 1415 [25000/25000 (100%)]\tLosses default: 0.000018 bn: 0.000045 drop: 0.000003 both: 0.001219\n",
      "Test set:\n",
      "default: Loss: 1.1650\tAccuracy: 4409.0/5000 (88%)\n",
      "bn: Loss: 1.1298\tAccuracy: 4394.0/5000 (88%)\n",
      "drop: Loss: 1.2795\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.0583\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1416 [0/25000 (0%)]\tLosses default: 0.000110 bn: 0.000003 drop: 0.000008 both: 0.000002\n",
      "Train Epoch: 1416 [10000/25000 (40%)]\tLosses default: 0.000021 bn: 0.000003 drop: 0.000007 both: 0.000043\n",
      "Train Epoch: 1416 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.001042 drop: 0.000001 both: 0.000214\n",
      "Train Epoch: 1416 [25000/25000 (100%)]\tLosses default: 0.000004 bn: 0.000058 drop: 0.000001 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.1722\tAccuracy: 4413.0/5000 (88%)\n",
      "bn: Loss: 1.0906\tAccuracy: 4420.0/5000 (88%)\n",
      "drop: Loss: 1.3047\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.0831\tAccuracy: 4413.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1417 [0/25000 (0%)]\tLosses default: 0.000009 bn: 0.000023 drop: 0.000003 both: 0.000013\n",
      "Train Epoch: 1417 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000000 both: 0.000159\n",
      "Train Epoch: 1417 [20000/25000 (80%)]\tLosses default: 0.000016 bn: 0.000022 drop: 0.000001 both: 0.000017\n",
      "Train Epoch: 1417 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000031 drop: 0.000008 both: 0.000020\n",
      "Test set:\n",
      "default: Loss: 1.1786\tAccuracy: 4412.0/5000 (88%)\n",
      "bn: Loss: 1.1499\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.2932\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.0707\tAccuracy: 4408.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1418 [0/25000 (0%)]\tLosses default: 0.000056 bn: 0.004000 drop: 0.000009 both: 0.000023\n",
      "Train Epoch: 1418 [10000/25000 (40%)]\tLosses default: 0.000010 bn: 0.000106 drop: 0.000000 both: 0.000022\n",
      "Train Epoch: 1418 [20000/25000 (80%)]\tLosses default: 0.000010 bn: 0.000017 drop: 0.000001 both: 0.000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1418 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000000 both: 0.000074\n",
      "Test set:\n",
      "default: Loss: 1.1840\tAccuracy: 4414.0/5000 (88%)\n",
      "bn: Loss: 1.1211\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.2882\tAccuracy: 4378.0/5000 (88%)\n",
      "both: Loss: 1.0973\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1419 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000054 drop: 0.000003 both: 0.000003\n",
      "Train Epoch: 1419 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000018 both: 0.001090\n",
      "Train Epoch: 1419 [20000/25000 (80%)]\tLosses default: 0.000024 bn: 0.002012 drop: 0.000003 both: 0.000005\n",
      "Train Epoch: 1419 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000001 both: 0.000342\n",
      "Test set:\n",
      "default: Loss: 1.1904\tAccuracy: 4414.0/5000 (88%)\n",
      "bn: Loss: 1.0743\tAccuracy: 4447.0/5000 (89%)\n",
      "drop: Loss: 1.2951\tAccuracy: 4369.0/5000 (87%)\n",
      "both: Loss: 1.0964\tAccuracy: 4402.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1420 [0/25000 (0%)]\tLosses default: 0.000011 bn: 0.000399 drop: 0.000002 both: 0.000020\n",
      "Train Epoch: 1420 [10000/25000 (40%)]\tLosses default: 0.000028 bn: 0.000005 drop: 0.271733 both: 0.000004\n",
      "Train Epoch: 1420 [20000/25000 (80%)]\tLosses default: 0.000011 bn: 0.010403 drop: 0.000391 both: 0.000041\n",
      "Train Epoch: 1420 [25000/25000 (100%)]\tLosses default: 0.000024 bn: 0.000011 drop: 0.000013 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 1.1961\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.0658\tAccuracy: 4445.0/5000 (89%)\n",
      "drop: Loss: 1.2451\tAccuracy: 4371.0/5000 (87%)\n",
      "both: Loss: 1.0895\tAccuracy: 4384.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1421 [0/25000 (0%)]\tLosses default: 0.000006 bn: 0.000047 drop: 0.000003 both: 0.000085\n",
      "Train Epoch: 1421 [10000/25000 (40%)]\tLosses default: 0.000029 bn: 0.000012 drop: 0.000106 both: 0.000100\n",
      "Train Epoch: 1421 [20000/25000 (80%)]\tLosses default: 0.000003 bn: 0.000003 drop: 0.001804 both: 0.000469\n",
      "Train Epoch: 1421 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.000000 drop: 0.000005 both: 0.000131\n",
      "Test set:\n",
      "default: Loss: 1.2021\tAccuracy: 4413.0/5000 (88%)\n",
      "bn: Loss: 1.0868\tAccuracy: 4451.0/5000 (89%)\n",
      "drop: Loss: 1.2821\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.1543\tAccuracy: 4358.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1422 [0/25000 (0%)]\tLosses default: 0.000005 bn: 0.000002 drop: 0.000041 both: 0.000403\n",
      "Train Epoch: 1422 [10000/25000 (40%)]\tLosses default: 0.000006 bn: 0.000030 drop: 0.000034 both: 0.031847\n",
      "Train Epoch: 1422 [20000/25000 (80%)]\tLosses default: 0.000007 bn: 0.000000 drop: 0.019342 both: 0.000029\n",
      "Train Epoch: 1422 [25000/25000 (100%)]\tLosses default: 0.000007 bn: 0.074502 drop: 0.000004 both: 0.000043\n",
      "Test set:\n",
      "default: Loss: 1.2073\tAccuracy: 4415.0/5000 (88%)\n",
      "bn: Loss: 1.1720\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.2564\tAccuracy: 4386.0/5000 (88%)\n",
      "both: Loss: 1.1481\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1423 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000021 drop: 0.000003 both: 0.000012\n",
      "Train Epoch: 1423 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000011 both: 0.000007\n",
      "Train Epoch: 1423 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.001412 drop: 0.000041 both: 0.000107\n",
      "Train Epoch: 1423 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000008 both: 0.006394\n",
      "Test set:\n",
      "default: Loss: 1.2129\tAccuracy: 4414.0/5000 (88%)\n",
      "bn: Loss: 1.1193\tAccuracy: 4417.0/5000 (88%)\n",
      "drop: Loss: 1.2153\tAccuracy: 4407.0/5000 (88%)\n",
      "both: Loss: 1.1166\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1424 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000584 drop: 0.000002 both: 0.000028\n",
      "Train Epoch: 1424 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000006 drop: 0.000011 both: 0.000003\n",
      "Train Epoch: 1424 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000573 drop: 0.000007 both: 0.000024\n",
      "Train Epoch: 1424 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000068 drop: 0.000116 both: 0.000003\n",
      "Test set:\n",
      "default: Loss: 1.2189\tAccuracy: 4414.0/5000 (88%)\n",
      "bn: Loss: 1.1288\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.2496\tAccuracy: 4391.0/5000 (88%)\n",
      "both: Loss: 1.1263\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1425 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000008 both: 0.000007\n",
      "Train Epoch: 1425 [10000/25000 (40%)]\tLosses default: 0.000005 bn: 0.000001 drop: 0.000004 both: 0.000182\n",
      "Train Epoch: 1425 [20000/25000 (80%)]\tLosses default: 0.000008 bn: 0.000026 drop: 0.000027 both: 0.000276\n",
      "Train Epoch: 1425 [25000/25000 (100%)]\tLosses default: 0.000002 bn: 0.000045 drop: 0.000001 both: 0.000072\n",
      "Test set:\n",
      "default: Loss: 1.2248\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.0959\tAccuracy: 4413.0/5000 (88%)\n",
      "drop: Loss: 1.2614\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.1364\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1426 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.017795 drop: 0.000000 both: 0.000005\n",
      "Train Epoch: 1426 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000004 both: 0.000009\n",
      "Train Epoch: 1426 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000008 both: 0.000010\n",
      "Train Epoch: 1426 [25000/25000 (100%)]\tLosses default: 0.000009 bn: 0.000004 drop: 0.000001 both: 0.000018\n",
      "Test set:\n",
      "default: Loss: 1.2303\tAccuracy: 4416.0/5000 (88%)\n",
      "bn: Loss: 1.0943\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.2594\tAccuracy: 4373.0/5000 (87%)\n",
      "both: Loss: 1.1234\tAccuracy: 4385.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1427 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000009\n",
      "Train Epoch: 1427 [10000/25000 (40%)]\tLosses default: 0.000003 bn: 0.000009 drop: 0.000014 both: 0.000009\n",
      "Train Epoch: 1427 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000073 drop: 0.000030 both: 0.000016\n",
      "Train Epoch: 1427 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000004 both: 0.000031\n",
      "Test set:\n",
      "default: Loss: 1.2369\tAccuracy: 4417.0/5000 (88%)\n",
      "bn: Loss: 1.1220\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2458\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.1547\tAccuracy: 4365.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1428 [0/25000 (0%)]\tLosses default: 0.000003 bn: 0.000043 drop: 0.000058 both: 0.000241\n",
      "Train Epoch: 1428 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000233 both: 0.000001\n",
      "Train Epoch: 1428 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000128 drop: 0.000002 both: 0.000025\n",
      "Train Epoch: 1428 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000849 drop: 0.000004 both: 0.000087\n",
      "Test set:\n",
      "default: Loss: 1.2427\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.1694\tAccuracy: 4397.0/5000 (88%)\n",
      "drop: Loss: 1.2608\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.1433\tAccuracy: 4375.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1429 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000084 drop: 0.000001 both: 0.000013\n",
      "Train Epoch: 1429 [10000/25000 (40%)]\tLosses default: 0.000004 bn: 0.000289 drop: 0.000002 both: 0.013482\n",
      "Train Epoch: 1429 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000031 drop: 0.000005 both: 0.000024\n",
      "Train Epoch: 1429 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000004 drop: 0.000007 both: 0.000282\n",
      "Test set:\n",
      "default: Loss: 1.2491\tAccuracy: 4418.0/5000 (88%)\n",
      "bn: Loss: 1.1112\tAccuracy: 4424.0/5000 (88%)\n",
      "drop: Loss: 1.2770\tAccuracy: 4389.0/5000 (88%)\n",
      "both: Loss: 1.0983\tAccuracy: 4379.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1430 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000001 both: 0.000024\n",
      "Train Epoch: 1430 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000200 drop: 0.000006 both: 0.000023\n",
      "Train Epoch: 1430 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000023 drop: 0.000002 both: 0.000053\n",
      "Train Epoch: 1430 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000008 both: 0.000016\n",
      "Test set:\n",
      "default: Loss: 1.2554\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.1049\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.2419\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.1512\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1431 [0/25000 (0%)]\tLosses default: 0.000002 bn: 0.000009 drop: 0.000000 both: 0.000085\n",
      "Train Epoch: 1431 [10000/25000 (40%)]\tLosses default: 0.000002 bn: 0.000001 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 1431 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000047 drop: 0.000000 both: 0.000063\n",
      "Train Epoch: 1431 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000007 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 1.2613\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.1211\tAccuracy: 4433.0/5000 (89%)\n",
      "drop: Loss: 1.2789\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1374\tAccuracy: 4393.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1432 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000137 drop: 0.000008 both: 0.002145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1432 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000001 both: 0.000008\n",
      "Train Epoch: 1432 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000008 both: 0.000223\n",
      "Train Epoch: 1432 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000001\n",
      "Test set:\n",
      "default: Loss: 1.2685\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.1137\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.2645\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.1019\tAccuracy: 4414.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1433 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000283 drop: 0.000000 both: 0.000001\n",
      "Train Epoch: 1433 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000001 both: 0.000013\n",
      "Train Epoch: 1433 [20000/25000 (80%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.000002 both: 0.000009\n",
      "Train Epoch: 1433 [25000/25000 (100%)]\tLosses default: 0.000001 bn: 0.000188 drop: 0.000007 both: 0.000106\n",
      "Test set:\n",
      "default: Loss: 1.2743\tAccuracy: 4422.0/5000 (88%)\n",
      "bn: Loss: 1.0976\tAccuracy: 4422.0/5000 (88%)\n",
      "drop: Loss: 1.2662\tAccuracy: 4392.0/5000 (88%)\n",
      "both: Loss: 1.0918\tAccuracy: 4405.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1434 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.003711 drop: 0.000000 both: 0.000004\n",
      "Train Epoch: 1434 [10000/25000 (40%)]\tLosses default: 0.000001 bn: 0.000092 drop: 0.000003 both: 0.000011\n",
      "Train Epoch: 1434 [20000/25000 (80%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000003 both: 0.003329\n",
      "Train Epoch: 1434 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000026 both: 0.000242\n",
      "Test set:\n",
      "default: Loss: 1.2813\tAccuracy: 4419.0/5000 (88%)\n",
      "bn: Loss: 1.1672\tAccuracy: 4409.0/5000 (88%)\n",
      "drop: Loss: 1.2752\tAccuracy: 4383.0/5000 (88%)\n",
      "both: Loss: 1.1185\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1435 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000009 drop: 0.000000 both: 0.000061\n",
      "Train Epoch: 1435 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000001 both: 0.000912\n",
      "Train Epoch: 1435 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000058 drop: 0.000002 both: 0.000170\n",
      "Train Epoch: 1435 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000005 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.2878\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.1484\tAccuracy: 4429.0/5000 (89%)\n",
      "drop: Loss: 1.2761\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.1479\tAccuracy: 4404.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1436 [0/25000 (0%)]\tLosses default: 0.000001 bn: 0.000019 drop: 0.000001 both: 0.000690\n",
      "Train Epoch: 1436 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000005\n",
      "Train Epoch: 1436 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000012 both: 0.000016\n",
      "Train Epoch: 1436 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000043 drop: 0.000001 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.2937\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.1309\tAccuracy: 4418.0/5000 (88%)\n",
      "drop: Loss: 1.2891\tAccuracy: 4380.0/5000 (88%)\n",
      "both: Loss: 1.1642\tAccuracy: 4377.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1437 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000080 drop: 0.000024 both: 0.002414\n",
      "Train Epoch: 1437 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000007 both: 0.000004\n",
      "Train Epoch: 1437 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000003 drop: 0.000003 both: 0.000024\n",
      "Train Epoch: 1437 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000002 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3009\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0916\tAccuracy: 4419.0/5000 (88%)\n",
      "drop: Loss: 1.2772\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1679\tAccuracy: 4373.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1438 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000025 drop: 0.000002 both: 0.000005\n",
      "Train Epoch: 1438 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000000 both: 0.000009\n",
      "Train Epoch: 1438 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000058 drop: 0.000000 both: 0.000264\n",
      "Train Epoch: 1438 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000000 both: 0.000002\n",
      "Test set:\n",
      "default: Loss: 1.3066\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.0850\tAccuracy: 4430.0/5000 (89%)\n",
      "drop: Loss: 1.2838\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.1414\tAccuracy: 4370.0/5000 (87%)\n",
      "\n",
      "Train Epoch: 1439 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000016\n",
      "Train Epoch: 1439 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000000 both: 0.008110\n",
      "Train Epoch: 1439 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000269 drop: 0.005634 both: 0.000013\n",
      "Train Epoch: 1439 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000513 both: 0.000013\n",
      "Test set:\n",
      "default: Loss: 1.3126\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0962\tAccuracy: 4426.0/5000 (89%)\n",
      "drop: Loss: 1.2582\tAccuracy: 4367.0/5000 (87%)\n",
      "both: Loss: 1.1055\tAccuracy: 4399.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1440 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.005372 both: 0.000006\n",
      "Train Epoch: 1440 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000112 both: 0.000121\n",
      "Train Epoch: 1440 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000010 both: 0.000011\n",
      "Train Epoch: 1440 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000219 drop: 0.001436 both: 0.000327\n",
      "Test set:\n",
      "default: Loss: 1.3193\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.1195\tAccuracy: 4414.0/5000 (88%)\n",
      "drop: Loss: 1.2485\tAccuracy: 4365.0/5000 (87%)\n",
      "both: Loss: 1.1063\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1441 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000027 drop: 0.000005 both: 0.000006\n",
      "Train Epoch: 1441 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000015 drop: 0.000015 both: 0.000006\n",
      "Train Epoch: 1441 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.015950 drop: 0.000013 both: 0.000473\n",
      "Train Epoch: 1441 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000346 drop: 0.000003 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 1.3259\tAccuracy: 4424.0/5000 (88%)\n",
      "bn: Loss: 1.1363\tAccuracy: 4428.0/5000 (89%)\n",
      "drop: Loss: 1.2671\tAccuracy: 4360.0/5000 (87%)\n",
      "both: Loss: 1.1134\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1442 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000002 both: 0.000004\n",
      "Train Epoch: 1442 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000010 both: 0.000010\n",
      "Train Epoch: 1442 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000265 both: 0.000002\n",
      "Train Epoch: 1442 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000005 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.3310\tAccuracy: 4420.0/5000 (88%)\n",
      "bn: Loss: 1.1133\tAccuracy: 4431.0/5000 (89%)\n",
      "drop: Loss: 1.2490\tAccuracy: 4377.0/5000 (88%)\n",
      "both: Loss: 1.1036\tAccuracy: 4392.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1443 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000750 both: 0.000008\n",
      "Train Epoch: 1443 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1443 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000379 drop: 0.000112 both: 0.000004\n",
      "Train Epoch: 1443 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000029 drop: 0.000072 both: 0.000036\n",
      "Test set:\n",
      "default: Loss: 1.3373\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.1001\tAccuracy: 4438.0/5000 (89%)\n",
      "drop: Loss: 1.2333\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1320\tAccuracy: 4391.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1444 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000008 drop: 0.000002 both: 0.000038\n",
      "Train Epoch: 1444 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000108 drop: 0.000006 both: 0.000001\n",
      "Train Epoch: 1444 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.039935 drop: 0.000010 both: 0.000004\n",
      "Train Epoch: 1444 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.004844 drop: 0.000018 both: 0.000039\n",
      "Test set:\n",
      "default: Loss: 1.3434\tAccuracy: 4426.0/5000 (89%)\n",
      "bn: Loss: 1.0911\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.2538\tAccuracy: 4385.0/5000 (88%)\n",
      "both: Loss: 1.1049\tAccuracy: 4403.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1445 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000007 both: 0.000007\n",
      "Train Epoch: 1445 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000060 drop: 0.000009 both: 0.026939\n",
      "Train Epoch: 1445 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.001255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1445 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000122 drop: 0.000016 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 1.3484\tAccuracy: 4425.0/5000 (88%)\n",
      "bn: Loss: 1.0999\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.2394\tAccuracy: 4375.0/5000 (88%)\n",
      "both: Loss: 1.1003\tAccuracy: 4387.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1446 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000023\n",
      "Train Epoch: 1446 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000008 both: 0.000151\n",
      "Train Epoch: 1446 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000001 both: 0.000004\n",
      "Train Epoch: 1446 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000003 both: 0.000012\n",
      "Test set:\n",
      "default: Loss: 1.3527\tAccuracy: 4430.0/5000 (89%)\n",
      "bn: Loss: 1.1177\tAccuracy: 4415.0/5000 (88%)\n",
      "drop: Loss: 1.2556\tAccuracy: 4390.0/5000 (88%)\n",
      "both: Loss: 1.1158\tAccuracy: 4381.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1447 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000005 both: 0.000005\n",
      "Train Epoch: 1447 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.056573 drop: 0.000002 both: 0.006659\n",
      "Train Epoch: 1447 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000014 drop: 0.000007 both: 0.000194\n",
      "Train Epoch: 1447 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000000 both: 0.000109\n",
      "Test set:\n",
      "default: Loss: 1.3583\tAccuracy: 4427.0/5000 (89%)\n",
      "bn: Loss: 1.1161\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.2555\tAccuracy: 4384.0/5000 (88%)\n",
      "both: Loss: 1.1362\tAccuracy: 4400.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1448 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000006 both: 0.000011\n",
      "Train Epoch: 1448 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000002 both: 0.000011\n",
      "Train Epoch: 1448 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000023 drop: 0.000007 both: 0.000007\n",
      "Train Epoch: 1448 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000006 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 1.3620\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1102\tAccuracy: 4427.0/5000 (89%)\n",
      "drop: Loss: 1.2757\tAccuracy: 4381.0/5000 (88%)\n",
      "both: Loss: 1.1386\tAccuracy: 4398.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1449 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000051 both: 0.000008\n",
      "Train Epoch: 1449 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000098 drop: 0.000001 both: 0.000006\n",
      "Train Epoch: 1449 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.005587 drop: 0.000002 both: 0.000003\n",
      "Train Epoch: 1449 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000051 drop: 0.000001 both: 0.054277\n",
      "Test set:\n",
      "default: Loss: 1.3657\tAccuracy: 4433.0/5000 (89%)\n",
      "bn: Loss: 1.1248\tAccuracy: 4425.0/5000 (88%)\n",
      "drop: Loss: 1.2817\tAccuracy: 4387.0/5000 (88%)\n",
      "both: Loss: 1.1405\tAccuracy: 4388.0/5000 (88%)\n",
      "\n",
      "Train Epoch: 1450 [0/25000 (0%)]\tLosses default: 0.000000 bn: 0.000333 drop: 0.000007 both: 0.000021\n",
      "Train Epoch: 1450 [10000/25000 (40%)]\tLosses default: 0.000000 bn: 0.000011 drop: 0.000003 both: 0.000007\n",
      "Train Epoch: 1450 [20000/25000 (80%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000021 both: 0.000165\n",
      "Train Epoch: 1450 [25000/25000 (100%)]\tLosses default: 0.000000 bn: 0.000068 drop: 0.000002 both: 0.000007\n",
      "Test set:\n",
      "default: Loss: 1.3685\tAccuracy: 4429.0/5000 (89%)\n",
      "bn: Loss: 1.1866\tAccuracy: 4412.0/5000 (88%)\n",
      "drop: Loss: 1.2469\tAccuracy: 4396.0/5000 (88%)\n",
      "both: Loss: 1.1490\tAccuracy: 4380.0/5000 (88%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1451):\n",
    "    for model in models.values():\n",
    "        model.train()\n",
    "    train(epoch, models, train_log)\n",
    "    for model in models.values():\n",
    "        model.eval()\n",
    "    test(models, valid_loader, test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_logs(test_log, train_log):\n",
    "    keys = test_log.keys()\n",
    "    test_logs = {k:[z for z in zip(*test_log[k])] for k in keys}\n",
    "    train_logs = {k:[z for z in zip(*train_log[k])] for k in keys}\n",
    "    epochs = {k:range(len(test_log[k])) for k in keys}\n",
    "    \n",
    "    g_counter = 0\n",
    "    for k in keys:        \n",
    "        plt.subplot(4, 2, g_counter+1)\n",
    "        plt.plot(epochs[k], test_logs[k][0], label='test loss')\n",
    "        plt.plot(epochs[k], train_logs[k][0], label='train loss')\n",
    "        plt.title(k + ' errors')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('error')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        \n",
    "        plt.subplot(4, 2, g_counter+2)\n",
    "        plt.plot(epochs[k], test_logs[k][1], label='test accuracy')\n",
    "        plt.plot(epochs[k], train_logs[k][1], label='train accuracy')\n",
    "        plt.title(k + ' accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('error')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        \n",
    "        g_counter += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x2880 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [40, 40]\n",
    "plot_compare_logs(test_log, train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
